\documentclass[12pt,notitlepage,a4paper]{article}

\usepackage[left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage{amssymb,mathtools, amsmath, amsfonts, amsthm}
%\usepackage{color}
\usepackage{float}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{chngcntr}
\usepackage{cleveref}
\usepackage{pdfpages}

\usepackage{mathptmx}

\counterwithout{equation}{section}

\newlength{\margen}
\setlength{\margen}{\paperwidth}
\addtolength{\margen}{-\textwidth}
\addtolength{\skip\footins}{0.7 cm}
\setlength{\margen}{0.5\margen}
\addtolength{\margen}{-1in}
\setlength{\oddsidemargin}{\margen}
\setlength{\evensidemargin}{\margen}
\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}
%%%% Small setup %%%%
\hypersetup{
	colorlinks=false,
	pdfborder={1 1 0.0005},
}
\setlength{\parskip}{0.2cm}
%%%%%%%%%%%%%%%
\usepackage{tikz-cd}
\usetikzlibrary{cd}
\usepackage[english]{babel}
\usepackage{todonotes}
\usepackage{cleveref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{bbding}
\usepackage{tcolorbox}
\usepackage{natbib}


\newtheorem{proposition}{Proposition}[section]
\newtheorem{fact}{Fact}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{obs}{Observation}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}{Corollary}[section]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{propdef}{Proposition / Definition}[section]
\newtheorem{remark}{Remark}[section]


\newcommand{\cc}{\mathfrak{c}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Hc}{\mathcal{H}}
\newcommand{\Lan}{\mathcal{L}}
\newcommand{\Ln}{\lim\limits_{n\to \infty}}
\newcommand{\clist}{\mathfrak{c}_{1}, \cdots, \mathfrak{c}_m}
\newcommand{\morph}[1]{\simeq_#1}
\newcommand{\vlst}[2]{#1_1,\dots, #1_{#2}}
\newcommand{\gnp}{G(n,\beta_1/n^{a_1-1}, \dots,\beta_l/n^{a_l-1})}
\newcommand{\overbar}[1]{\mkern 1.5mu\overline{\mkern-1.5mu#1\mkern-1.5mu}\mkern 1.5mu}
\newcommand{\ehr}{\textsc{Ehr}}
\newcommand{\PR}[1]{\mathrm{Pr}\big(#1\big)}
\newcommand{\Tr}{\mathrm{Tr}}
\newcommand{\InR}[1]{\left\{ #1_R \right\}_{R\in \sigma}}

\begin{document}
\begin{abstract}
	We consider a finite relational vocabulary $\sigma$
	and a first order theory $T$ for $\sigma$ 
    composed of symmetry and 
    anti-reflexivity axioms. We define a binomial random model of finite 
    $\sigma$-structures that satisfy $T$ and show that first order properties have 
    well defined asymptotic probabilities in the sparse 
    case. It is also shown that those limit probabilities are well-behaved with
    respect to some parameters that represent edge densities. 
    An application of these results to the problem of random Boolean 
    satisfiability is presented afterwards. 
    We show that there is no first order property of $k$-CNF formulas
    that implies unsatisfiability and holds for almost all typical 
    unsatisfiable formulas when the number of clauses is linear. 
   
\end{abstract}
\clearpage

\section*{Introduction}

Since the work of Erd\"os and R\`enyi on the evolution of random graphs
\cite{erdHos1960evolution} the study of the asymptotic properties of random
structures has played a relevant role in combinatorics and computer science.
A central theme in this topic is, given a succession $(G_n)_n$ of random
structures of some sort and a property $P$, to determine the limit probability
that $G_n$ satisfies $P$ or to determine whether that limit exists. \par
One approach that has proven to be useful is to classify the properties $P$
according to the logical languages they can be defined in. We say that the 
succession $(G_n)_n$ obeys a convergence law with respect to some logical language
$\mathcal{L}$ if for any given property $P$ expressible in $\mathcal{L}$ the 
probability that $G_n$ satisfies $P$ tends to some limit as $n$ grows to infinity.
We say that $(G_n)_n$ obeys a zero-one law with respect to $\mathcal{L}$ if
that limit is always either zero or one. 
The seminal theorem on this topic, due to Fagin \cite{fagin1976probabilities}
and Glebskii et al. 
\cite{glebskii1969range} independently, states that if $G_n$ denotes a labeled
graph with $n$ vertices picked uniformly at random among all $2^{\binom{n}{2}}$ 
possible then $(G_n)_n$ satisfies a zero-one law with respect to the first order
(FO) language of graphs. \par
Originally this result was proven in the broader context of relational
structures but it was in the theory of random graphs were the study of 
other zero-one and convergence laws became more prominent. In particular,
the asymptotic behavior of FO logic in the binomial model of random graphs 
$G(n,p)$ has been extensively studied. In this model, introduced by Gilbert 
\cite{gilbert1959random}, a random graph is obtained from $n$ labeled vertices
by adding each possible edge with probability $p$ independently. When $p=1/2$
this distribution of random graphs coincides with the uniform one, mentioned 
above. In general, for the case where $p$ is a constant probability a slight 
generalization of the proofs in \cite{fagin1976probabilities} and 
\cite{glebskii1969range} works and $G(n,p)$ satisfies a zero-one law 
for FO logic. If we consider $p(n)$ a decreasing function of the form
$n^{-\alpha}$ we can ask the question of what are the values of $\alpha$
for which $G(n,p(n))$ obeys a zero-one or a convergence law for FO logic. 
In \cite{shelah1988zero} Shelah and Spencer gave a complete answer 
for the range $\alpha\in (0,1)$. Among other results, they proved that
if $\alpha$ is an irrational number in this interval then
$G(n,p(n))$ obeys a zero-one law for FO logic, while if $\alpha$
is a rational number in the same range then $G(n,p(n))$ does not
even satisfy a convergence law for FO logic. The case $\alpha=1$
was later solved by Lynch in \cite{lynch1992probabilities}. A weaker
form of the main theorem in that article states the following:
\begin{theorem} 
	For any FO sentence $\phi$, the function
	$F_\phi: (0,\infty)\rightarrow [0,1]$ given by 
	\[ F_\phi(\beta) = \Ln \mathrm{Pr}\big( \mathrm{G}(n,\beta/n)
	\text{ satisfies } \phi   \big) \]
	is well defined and analytic. In particular, for any
	$\beta \geq 0$ the model $\mathrm{G}(n,\beta/n)$
	obeys a convergence law for FO logic. 
\end{theorem}

The analyticity of these asymptotic probabilities with respect to 
the parameter $\beta$ implies that FO properties cannot "capture" sudden
changes that occur in the random graph $\mathrm{G}(n,\beta/n)$
as $\beta$ changes. Given $p(n)$ a probability, $P$ a property of graphs,
and $Q$ a sufficient condition for $P$ - i.e., a property that 
implies $P$ -, we say that $Q$ explains $P$ if $\mathrm{G}(n,p(n))$ satisfies 
the converse implication $P \implies Q$ asymptotically almost surely
(a.a.s.). A notable example of this phenomenon happens in the range 
$p(n)= \log(n)/n + \beta/n$ with $\beta$ constant. Erd\"os and R\`enyi
\cite{erdHos1960evolution} 
showed that for probabilities of this form $\mathrm{G}(n,p(n))$ 
a.a.s. is disconnected only if it contains an isolated vertex. 
An observation by Albert Atserias is the following:

\begin{theorem}
Let $c$ be a real constant such that 
$\Ln \mathrm{Pr}\big( G(n, c/n) 
\text{ is not }	3\text{-colorable }\big)> 0$.  
Then there is no FO graph property that explains 
non-$3$-colorability for $G(n, c/n)$.
\end{theorem}

The short proof of this theorem is as follows: 
It is a known fact that there are positive constants
$c_0\leq c_1$ such that $G(n, c/n)$ is a.a.s $3$-colorable
if $c<c_0$ and it is a.a.s non $3$-colorable if $c>c_1$ 
REFERENCES NEEDED.
Suppose that $P$ is a FO graph property that implies
non-$3$-colorability. Then, because of this implication,
for all values of $c$
\[\Ln \mathrm{Pr}\big( G(n, c/n) 
\text{ satisfies } P \big) \leq \Ln \mathrm{Pr}\big( G(n, c/n) 
\text{ is not }	3\text{-colorable}\big).\]
In consequence the asymptotic probability that $G(n,c/n)$ 
satisfies $P$ is zero when $c<c_0$. By Lynch's theorem, if 
$P$ is definable in FO logic then this asymptotic probability
varies analytically with $c$. Using the fact that any analytic 
function that takes value zero in a non-empty interval must 
equal zero everywhere, we obtain that $G(n,c/n)$ a.a.s does 
not satisfy $P$ for any value of $c$. 
As a consequence the theorem follows.  \par

The aim of this work is to extend Lynch's result to arbitrary 
relational structures were the relations are subject to some
predetermined symmetry and anti-reflexivity axioms. This was 
originally motivated by an application to the study of random
$k$-CNF formulas. Since \cite{chvatal1992mick} it is known that 
for each $k$ there are constants $c_0,c_1$ such that a random 
$k$-CNF formula with $cn$ clauses over $n$ variables 

%Besides this 
% 
%This question was originally posed in \cite{atserias2005definability}
%by Albert Atserias where the answer was given for various probability





\setcounter{section}{0}

\section{Preliminaries}

\subsection{General notation}\label{subsect:notation}

Given a positive natural number $n$, we will write
$[n]$ to denote the set ${1,2,\dots,n}$.\par
Given a set $S$ and a natural number $k\in \N$
we will use $\binom{S}{k}$ to denote the set of 
subsets of $S$ whose size is $k$. \par
Given numbers, $n,m\in \N$ with $m\leq n$ we define
$(n)_m:=n\cdot (n-1)\cdots (n-m+1)$. Given a set
$S$ and a number $n\in \N$ with $n\leq |S|$ we define
$(S)_n$ as the subset of $S^n$ consisting of the $n$-tuples
whose coordinates are all different. 
We also define $S^*:=\bigcup_{n=0}^\infty S^n$ and
$(S)_*=\bigcup_{n\leq |S|} (S)_n$. Given a tuple 
$\overline{x}\in S^*$ and an element $x\in S$ the expression
$x\in \overline{x}$ will mean that $x$ appears as some coordinate
in $\overline{x}$. We will at times make an abuse of notation and
treat the tuple $\overline{x}$
as the set of elements $x\in \overline{x}$. \par
We will use the convention that over-lined variables
, like $\overline{x}$, denote ordered tuples of arbitrary length. 
For example, given a set $S$, if we write $\overline{x}\in S^*$
then $\overline{x}=(x_1,\dots, x_a)$ for some $a\in \N$ and 
some $x_1,\dots, x_a\in S$. Given an ordered tuple $\overline{x}$
we define the number $len(\overline{x})$ as its length. 
Given a map $f:X\rightarrow Y$ between two sets $X, Y$ and 
an ordered tuple $\overline{x}:=(x_1,\dots,x_a)\in X^*$ 
we define $f(\overline{x})\in Y^*$ as the tuple 
$(f(x_1),\dots,f(x_a))$.
\par

Let $S$ be a set, $a$ a positive natural number, 
and $\Phi$ a group of permutations over 
$[a]$. Then $\Phi$ acts naturally over
$S^a$ in the following way: Given $g\in \Phi$ and
$\overline{x}=(x_1,\dots,x_a)\in S^a$ we define 
$g\cdot(x_1,\dots,x_a)$ and $g\cdot \overline{x}$ 
as the tuple $(x_{g(1)},\dots,x_{g(a)})$. 
We will denote by $S^a/\Phi$ to the quotient
of the set $S^a$ by this action. Given an element
$\overline{x}:=(x_1,\dots, x_a)\in S^a$ we will denote its equivalence
class in $S^a/\Phi$ by $[x_1,\dots,x_a]$ or $[\overline{x}]$.
Thus, for any
$g\in \Phi$, by definition $[x_1,\dots,x_a]=[x_{g(1)}
,\dots,x_{g(a)}]$. The notations $\overline{x}$ and
$(x_1,\dots, x_a)$ 
will be reserved 
to ordered tuples while 
$[\overline{x}]$ and
$[x_1,\dots,x_a]$ will denote ordered tuples modulo the
action of some arbitrary group of permutations. Which group is
this will depend on the ambient set where $[x_1,\dots,x_a]$ belongs
and it should either be clear from context or not be relevant.\par
\par
Given two real functions over the natural numbers 
$f,g:\N \rightarrow \R$ we will write $f=O(g)$ to 
mean that there exists some constant $C\in \R$
such that $f(n)\leq Cg(n)$ for $n$ sufficiently large, 
as usual.
If $g(n)\neq 0$ for $n$ large enough then
we will write $f\sim g$ when $\Ln \frac{f(n)}{g(n)}=1$.\par





\subsection{Logical preliminaries}
We will assume a certain degree of familiarity with the 
concepts. For a more complete exposition of the topics 
presented here one can consult \cite{ebbinghaus2013mathematical}.

A relational vocabulary $\sigma$ is a collection of
relation symbols $\{R_1,\dots, R_m,\dots\}$
where each relation symbol $R_i$ has associated a natural
number $ar(R_i)$ called its arity.
A $\sigma$-structure $\mathfrak{A}$ is composed of
a set $A$, called the universe of $\mathfrak{A}$, equipped with
relations $R_1^{\mathfrak{A}}\subseteq A^{a_1},
\dots, R_m^{\mathfrak{A}}\subseteq A^{a_m}$. When $\sigma$
is understood we may refer to $\sigma$-structures as relational
structures or simply as structures.
A structure is called finite if its universe is a finite set. \par

In the first order language $FO[\sigma]$ with signature $\sigma$ 
formulas are formed by variables $x_1,\dots,$ $x_i,\dots$,
the relation symbols in $\sigma$, the equal symbol $=$,
the usual Boolean connectives $\neg, \wedge, \vee, \dots$, 
the existential and universal quantifiers $\exists, \forall$, and
the parentheses $),($. Then formulas in $FO[\sigma]$ are defined as 
follows.
\vspace*{-0.2em}
\begin{itemize}[topsep=1pt, itemsep=1pt]
	\item The expression $R(y_1,\dots,y_a)$, where the $y_i$'s are variables and $R$
	is a relation symbol in $\sigma$ such that $ar(R)=a$,
	belongs to $FO[\sigma]$.
	\item The expression $y_1=y_2$, where $y_1, y_2$ are variables, 
	belongs to $FO[\sigma]$.
	\item Given formulas $\phi, \psi \in FO[\sigma]$, any Boolean combination of them
	$\neg(\phi), (\phi \wedge \psi), (\phi \vee \psi), \dots$ belongs to $FO[\sigma]$ as well.
	\item Given a formula $\phi \in FO[\sigma]$ and $x$ a variable that 
	does not appear bounded
	by a quantifier in $\phi$, the expressions $\forall x (\phi)$ and 
	$\exists x (\phi)$ belong both to $FO[\sigma]$. 
\end{itemize}  
We will write $\forall y_1, y_2,\dots, y_m$ or simply $\forall \overline{y}$
instead of  
$\forall y_1, \forall y_2,\dots, \forall y_m$ and likewise for
the quantifier $\exists$. Also, if $\overline{y}:=(y_1,\dots,y_a)$ is a
tuple of variables we may write simply $R(\overline{y})$ instead
of $R(y_1\dots,y_a)$.\par
For the remaining of this article we will reserve the names $x,y,z$
for the variables in our first order formulas.\par
We define the set of free variables of a formula as usual. 
Given a formula $\phi\in FO[\sigma]$ we will use the notation $\phi(\overline{y})$ 
to denote that $\overline{y}$ is a tuple of 
(different) variables that contains all free variables in $\phi$ and
none of its bounded variables, although it may contain variables
which not appear in $\phi$. \par
Formulas with no free variables are called sentences and 
formulas with no quantifiers are called open formulas. \par
The quantifier rank of a formula $\phi$, denoted by $qr(\phi)$, 
is defined as the maximum number of nested quantifiers in $\phi$. \par
Sentences in $FO[\sigma]$ are interpreted over $\sigma$-structures
in the natural way. Given an structure $\mathcal{A}$, and a sentence
$\phi\in FO[\sigma]$ we write $\mathcal{A} \models \phi$ to denote 
that $\mathcal{A}$ satisfies $\phi$. If $\psi(\overline{y})$ is a
formula, $\overline{a}$ are elements in the universe of 
$\mathcal{A}$, and $\overline{y}$ and $\overline{a}$ are lists of the same size,
then we write $\mathcal{A} \models 
\psi(\overline{a})$
to mean that $\mathcal{A}$ satisfies $\psi$ when the free variables in
$\overline{y}$ are interpreted as the elements in $\overline{a}$ (i.e., 
the $i$-th element of $\overline{y}$ is interpreted as the $i$-th
element of $\overline{a}$).
\todo[inline]{Deber\'a al menos mencionar un par de trabajos que estudien random k-SAT y propiedades a.a.s suficientes para no-satisfacibilidad}


\subsection{Structures as multi-hypergraphs}

For the rest of the article consider fixed:
\begin{itemize}
	\item A relational vocabulary $\sigma$ such that all the relations $R\in\sigma$ satisfy $ar(R)\geq 2$. 
	\item 
	Groups $\overline{\Phi}=\{ \Phi_R \}_{R\in \sigma}$
	such that each $\Phi_R$ is consists of 
	permutations on $[ar(R)]$ with the usual 
	composition as its operation.	
	\item 
	Sets $\{P_R\}_{R\in \sigma}$ satisfying that for 
	all $R\in \sigma$, 
	$P_R\subseteq \binom{[ar(R)]}{2}$
	
	
\end{itemize}

We will only consider relational structures where the relations
are of arity at least two. This restriction is not necessary, but 
it makes notation easier. 
\todo[inline]{Quiz\'as deber\'ia a\~nadir un anexo dando alguna indicaci\'on sobre c\'omo tratar las relaciones unarias?}



%We will denote by $t_u$ the, possibly zero,
%amount of unary
%relation symbols in $\sigma$. 
%For the sake of convenience we may assume that $R_i$'s are
%ordered in such a way that the unary relation symbols, if any, 
%are the first ones $R_1,\dots, R_{t_u}$. This will
%become relevant later. \par 


We define the class $\mathcal{C}$ as the 
class of $\sigma$-structures that
satisfy the 
following axioms: 
\begin{itemize}
	\item \textit{Symmetry axioms}: For each $R\in \sigma$ and
	each $g\in \Phi_R$:
	\[ \forall \overline{x}:=x_1,\dots, x_{ar(R)} \big(  R(\overline{x})
	\iff R(g\cdot\overline{x}) \big)    \]
	\item \textit{Anti-reflexivity axioms}: For each 
	$R\in \sigma$ and $\{i,j\}\in P_R$
	\[ \forall x_1,\dots, x_{ar(R)} 
	\big( (x_i=x_j) \implies \neg R(x_1,\dots, x_{a_s})
	\big)\]
	\end{itemize}

We can think any structure $G$ in $\mathcal{C}$
as a "multi-hypergraph" whose vertices are the elements
of the universe of $G$. Each relation $R\in \sigma$, can be 
represented over $G$ as an "edge set" formed by tuples vertices
of size $ar(R)$ modulo the action of $\Phi_R$. Furthermore, 
repetitions of vertices in the positions given by
$P_R$ are not allowed in these tuples.\par
The following definitions make this ideas formal. They 
depend on our choices of $\sigma$, $\{\phi_R\}_{R\in \sigma}$
and $\{P_R\}_{R\in \sigma}$ but as those are fixed we can
allow ourselves to omit those dependencies for the sake of readability. 

\begin{definition} 
	Let $V$ be a set, and let $R\in \sigma$.
	We define the \textbf{total edge set over $V$
	given by $R$} as
	\[ E_R[V]= (V^{ar(R)}/\Phi_R) \quad \setminus 
	\quad X, \]
	where
	\[
	X=
	\Big\{ [x_1,\dots,x_{ar(R)}]  
	\quad \Big| \quad
	x_1,\dots,x_{ar(R)}\in V, \,
	\text{ and } 
	 \, x_i=x_j \text{ for some } 
	\{i,j\}\in P_R \Big\}.
	\]
	Also, we will say that the \textbf{sort} of the elements $e\in E_R[V]$
	is $R$. 
\end{definition}

That is, $E_R[V]$ contains all the ``$ar(R)$-tuples of elements
in $V$ modulo the permutations
in $\phi_R$" 
excluding those that contain some repetition of elements in
the positions given by $P_R$.\par
The fact that the elements $e\in E_R(V)$ are of sort $R$ 
is a technical detail
introduced so that for any different relation symbols $R_1$ and
$R_2$ it holds $E_{R_1}(V)\cap E_{R_2}(V)=\emptyset$ even in the case
that $ar(R_1)=ar(R_2)$, $\Phi_{R_1}=\Phi_{R_2}$ and $P_{R_1}=P_{R_2}$.\par

In the case where $V=[n]$ we will write simply $E_R[n]$ instead
of $E_R[[n]]$.

\begin{definition} 
We call $\mathcal{C}$-\textbf{hypergraph}, or simply hypergraph, 
to a pair $G=\Big(V(G),\{E_R(G)\}_{R\in\sigma}\Big)$,
where for each $R$, $E_R(G) \subseteq E_R[V]$.
\end{definition}

Hypergraphs, as we have defined them, 
can be naturally interpreted as
structures from $\mathcal{C}$ 
in the following way: 
given $G=(V,\{E_R\}_{R\in \sigma})$,
we consider $V$ to be the universe of
 $G$, and for any $R\in \sigma$ we define
$R^G\subseteq V^{ar(R)}$ as the set of tuples
$\overline{x}\in V^{ar(R)}$ such that
$[\overline{x}]\in E_R$. Under 
this interpretation hypergraphs
satisfy by definition the 
symmetry and anti-reflexivity
axioms given at the beginning of this section. It is also easy to
see that this interpretation induces
a one-to-one identification between 
structures in $\mathcal{C}$ and hypergraphs. \par

\subsection{Hypergraph notation and nomenclature}

We will use standard nomenclature and notation
from graph theory with some additions. Given an 
hypergraph $G$ we will call its \textbf{vertex set} to $V(G)$ 
and \textbf{vertices} 
to the elements $v\in V(G)$. Likewise, each of 
the $E_R(G)$'s will be called an \textbf{edge set} and its elements, 
\textbf{edges}. Given an edge set $E_R(G)$, 
the index $R$ will be called its \textbf{relation}. 

\par
Given an hypergraph $G$ we define the set $E(G)$ as the
union $\cup_{R\in \sigma}E_R(G)$. Notice that this union 
is disjoint because elements from different $E_R(G)$'s 
are of different sorts. Thus, $|E(G)|=\sum_{R\in \sigma} 
|E_R(G)|$. Analogously, given a set $V$, we define
$E[V]:=\cup_{R\in \sigma} E_R[V]$.
Given an edge $e\in E[V]$ we define $R(e)$
as the sort of $e$, i.e.,
the unique relation symbol $R(e)\in \sigma$
such that $e\in E_{R(e)}[V]$.

Given two hypergraphs $H$ and $G$ we say that $H$
is a \textbf{sub-hypergraph} of $G$, which we write as $H\subset G$,
if $V(H)\subset V(G)$ and $E(H)\subset E(G)$ (notice 
that this is equivalent to $E_R(H)\subset E_R(G)$ for all
$R\in \sigma$, since the edges are sorted).\par


Given a set of vertices $U\subseteq V(G)$, 
we will denote by $G[U]$ the \textbf{hypergraph induced
by $G$ on $U$}. That is, $G[U]$ is an hypergraph
$H=(V(H),\{E(H)_R\}_{R\in \sigma})$ such that 
$V(H)=U$ and for any $R\in \sigma$ 
each edge $e\in E_R(G)$ belongs 
to $E_R(H)$ as well if and only if the vertices
involved in $e$ are in $U$ (i.e. $e\in E_R[U]$).
\par
%
%An homomorphism between two hypergraphs $G$ and $H$ 
%a map $f:V(G)\rightarrow V(H)$ that sends edges 
%from $G$ to edges in $H$ of the same color. That is,
%if vertices $v_1,\dots, v_{a_i}$ form an edge 
%$[v_1,\dots,v_{a_i}]\in E_i(G)$, then
%$[f(v_1),\dots,f(v_{a_i})]\in E_i(H)$.
%If $f$ is injective then it is called a monomorphism. 
%If $f$ is bijective and its inverse is also an homomorphism 
%between $H$ and $G$ then $f$ is called an isomorphism.\par
%
%The group of automorphisms $Aut(G)$ of an hypergraph $G$ is the group
%of isomorphisms between $G$ and itself. 

%
%Given two hypergraphs $G$ and $H$, a copy of $H$ in $G$ is
%a sub-hypergraph $H_2\subseteq G$ isomorphic to $H$. The copy
%is called induced if $H_2$ is an induced sub-hypergraph.
%We will call a labeled copy
%of $H$ in $G$ to a monomorphism $f:H\rightarrow G$. 
%It is satisfied that the number
%of labeled copies of $H$ in $G$ is $|Aut(H)|$ times the number
%of copies of $H$ in $G$.


We define the \textbf{excess} $ex(G)$ of an hypergraph $G$ as the number
\[
ex(G):= \big(\sum_{R\in \sigma} (ar(R)-1)|E_R(G)|\big) - |V(G)|.  
\] 
That is, the excess of $G$ is its "weighted number of edges"
minus its number of vertices. \par

Given an hypergraph $G$ we define the following metric, $d$, over $V(G)$:
\[ d^G(u,v)= \min_{\substack{H \subset G\\ 
		H \text{ connected }\\
		u,v\in V(H)}} |E(H)| .\]
That is, the distance between $v$ and $u$ is the minimum number of
edges necessary to connect $v$ and $u$. 
If such number does not exist we define $d^G(u,v)=\infty$. \par
As usual, define $d^{G}(X,Y)$ for sets $X,Y\subset V(G)$ as the minimum
distance $d(u,v)$ where $u\in X$ and $v\in Y$. 
When $X=\{x\}$ we will omit the brackets and write
$d^G(x,Y)$ instead of $d^G(\{x\},Y)$, for example.
When $G$ 
is understood or not relevant we will usually simply denote the 
distance by $d$ instead of $d^G$. \par

Given set of vertices vertex, $X\subseteq V(G)$, 
we denote by $N^G(X;r)$ the $r$-\textbf{neighborhood} of $X$ in 
$G$. That is,  $N^G(X;r)= G[Y]$, where $Y\subseteq V(G)$ is 
the set:
\[ Y:= \{ u \in V(G) \ | \ d(X,u)\leq r   \}. \]
In particular, when $X$ is a singleton $\{v\}$, we
will write $N^G(v;r)$ instead of $N^G(\{v\};r)$.
As before, we will usually drop the ``$G$'' from our 
notation when $G$ is understood or not relevant.  \par

We will often write tuples of vertices instead of sets
inside of $d(\cdot\, , \cdot)$ and $N(\cdot\, ;r)$. In those cases
we are treating those tuples as sets as specified in
\cref{subsect:notation}. 

\subsection{The random model}

For each $R\in \sigma$ let
$p_R$ be a real number between zero and one.
Let $\overline{p}:=\InR{p}$.
The random model $G^{\mathcal{C}}(n,\overline{p})$ 
is the discrete probability space that
assigns to each hypergraph $G$ whose vertex
set $V(G)$ is $[n]$ the following probability:

\[ \mathrm{Pr}(G)=\prod_{R\in \sigma} p_R^{|E_R(G)|}
(1-p_R)^{ \big|E_R[n]\big|-\big|E_R(G)\big|}.	
\]
Equivalently, this is the probability space obtained by 
assigning to each edge $e\in E_R[n]$ probability 
$p_R$ independently. \par

%Let $G_n$ denote a random hypergraph in 
%$G^\mathcal{C}(n,\overline{p})$, where 
%$\bar{p}:=p_1,\dots,p_t$, and 
%we allow each $p_i$ to depend on $n$. 
As in the case of Lynch's theorem, we are interested in the
"sparse regime" of $G^\mathcal{C}(n,\overline{p})$, were the 
expected number of edges each color is linear. 
%In other words, we want that
%$\mathrm{E}[m_i(G_n)]=\Theta(n)$ for all $i$'s.
This is achieved when each of the $p_R$'s are 
of the form $\beta_R/n^{ar(R)-1}$ for some 
non-negative real numbers $\InR{\beta}$.
From now on we will write $G_n\left(\InR{\beta}\right)$
to denote a random sample of 
$G^\mathcal{C}\left(n,\left\{ \frac{
\beta_R}{n^{ar(R)-1}}\right\}_{R\in\sigma}\right)$.
When the choice of $\InR{\beta}$ is not relevant
we will write $G_n$ instead of 
$G_n\left(\InR{\beta}\right)$.\par

Our goal is to prove the following theorem:
%is to prove that for any sentence $\phi\in FO[\sigma]$,
%the limit 
%\[\Ln \mathrm{Pr}(G^\mathcal{C}(n,\overline{p}
%(n,\overline{\beta})) \models \phi)\] 
%is well defined and varies 
%analytically with $\overline{\beta}$.
% Some care is needed
%in order to formulate this precisely, as there are some values
%of $\overline{\beta}$ for which $\overline{p}
%(n,\overline{\beta})$ asymptotically does not 
%define a list of 
%proper probabilities. 
%Indeed, suppose that some relation
%symbol $R_i$ in $\sigma$ is unary. 
%Then, by definition $a_i=1$ and
%the expression $\beta_i/n^{a_i-1}$ 
%equals $\beta_i$. 
%In consequence, if we assign 
%values to $\overline{\beta}$ and let
%$\beta_i>1$ then the random 
%model $G^\mathcal{C}(n,\overline{p}
%(n,\overline{\beta})$ will not be well defined. 
%To avoid this we need to impose $\beta_i\in [0,1]$ 
%for all the $i$'s such that $a_i=1$. \par
%For the sake of convenience we will adopt the convention
%that the unary relation symbols among $R_1,\dots,R_t$ 
%are the first ones, and we will denote by $t_u$ the 
%(possibly zero) number of such relations. 
%Thus $a_1= a_2 =\dots= a_{t_0}=1$, and $a_i>1$ 
%for $i>t_0$. Now we are in conditions of stating our main 
%theorem: 

\begin{theorem} \label{thm:main}
	Let $\phi$ be a sentence in $FO[\sigma]$. Then
	the function
	%$F_\phi: [0,1]^{t_u}\times [0,\infty)^{t-t_u}
	$F_\phi: [0,\infty)^{|\sigma|}
	\rightarrow \R$ given by 
	\[
	\InR{\beta} \mapsto \Ln Pr\big( G_n\left(
	\InR{\beta}\right) \models \phi\big)
	\]
	is well defined and analytic. 
\end{theorem}



\subsection{Ehrenfeucht-Fraisse Games}

Let $G^1$ and $G^2$ be hypergraphs. We define the $k$ round 
Ehrenfeucht-Fraisse game on $G^1$ and $G^2$, denoted by
$\ehr_k(G^1;G^2)$, as follows:
The game is played between two players, Spoiler and Duplicator, and
the number of rounds, $k$, is known for both from the start.
At the beginning of each round Spoiler chooses a vertex from either
$V(G^1)$ or $V(G^2)$ and Duplicator responds by choosing a vertex
from the other set.
Let us denote by 
$v_i$, resp. $u_i$ the vertex from $G^1$, resp. from $G^2$, 
chosen in the $i$-th round,
for $i\in [k]$. At the end of the $k$-th round 
Duplicator wins if the following holds:
\begin{itemize}
	\item For any $i,j\in [k]$, $v_i=v_j \iff u_i=u_j$.
	\item Given a relation symbol $R\in \sigma$ 
	and indices $i_1,\dots, i_{ar(R)} \in [k]$, 
	$[v_{i_1},\dots,v_{i_{ar(R)}}] \in E_R(G^1) \iff 
	[u_{i_1},\dots,u_{i_{ar(R)}}]
	\in E_R(G^2)$.
	
\end{itemize}


We define the equivalence relation $=_k$ between hypergraphs as follows:
We say that $G^1=_k G^2$ if for any sentence $\phi\in 
FO[\sigma]$ with $qr(\phi)\leq k$ then ``$G^1\models\phi$ if and 
only if $G^2\models\phi$". 
\par

The following is satisfied:

\begin{theorem}
	[Ehrenfeut, \citealp{ehrenfeucht1961application}] Let
	$G^1$ and $G^2$ be hypergraphs.
	Then Duplicator wins $\ehr_k(G^1;G^2)$
	if and only if $G^1=_k G^2$.	
\end{theorem}

Let $\overline{v}\in V(G^1)^*$, and 
$\overline{u}\in V(G^2)^*$ be lists of vertices of the same length, 
$l=len(\overline{v})=len(\overline{u})$. We define the $k$ round 
Ehrenfeucht-Fraisse game on $G^1$ and $G^2$ with initial position given
by $\overline{v}$ and $\overline{u}$, denoted by $\ehr_k(G^1,\overline{v};G^2,\overline{u})$,
the same way as $\ehr_k(G^1;G^2)$, but in this case the game has $l$ extra 
rounds at the beginning where the vertices in $\overline{v}$ and $\overline{u}$ are 
played successively. After this, $k$ more rounds are played normally. \par

We also define the $k$-round distance Ehrenfeucht-Fraisse game on 
$G^1$ and $G^2$, denoted by $d\ehr_k(G^1;G^2)$, the same way as
$\ehr_k(G^1;G^2)$, but now, in order for Duplicator to win the
game, the following additional condition has to be satisfied 
at the end of the game:
\begin{itemize}
	\item For any $i,j\in [k]$, $d^{G^1}(v_i,v_j)=d^{G^2}(u_i,u_j)$.
\end{itemize}

Given $\overline{v}\in V(G^1)^*$, and $\overline{u}\in V(G^2)^*$
lists of vertices of the same length,
we define the game 
$d\ehr_k(G^1,\overline{v};G^2,\overline{u})$ analogously to 
$\ehr_k(G^1,\overline{v};G^2,\overline{u})$.



\subsection{Outline of the proof}

We show now an outline of the proof. \par 
We show that for any quantifier rank $k$ there are some classes of
hypergraphs 
$C^k_1,\dots, C^k_{n_k}$ such that
\begin{itemize}[noitemsep, topsep=0pt]
	\item[(1)] a.a.s the rank $k$ type of any two graphs in the same class coincide, 
	\item[(2)] a.a.s. any random graph belongs to some of them, and
	\item[(3)] the limit probability of random graph belonging to 
	any of them is an analytic expression on the parameters $\overline{\beta}$. 
\end{itemize}

After this is archived the theorem follows easily. 

The objective of next sections will be to define the classes 
$C_1,\dots, C_{n_k}$ and to show that they satisfy properties (1), (2) and (3).

\todo[inline]{Explicar esto mejor}

\section{Some winning strategies for Duplicator}

The aim of this section is to show the winning strategy
for Duplicator that is going to be used in our proofs. \par

Let $G^1$ and $G^2$ be hypergraphs, and let
$V_1:=V(G^1), V_2:=V(G^2)$.
Let $\overline{v} \in V_1^*, 
\overline{u} \in V_2^*$ be tuples of the same length.
We say that $\overline{v}$ and $\overline{u}$ have
$k$-\textbf{similar} $r$-neighborhoods, written as
$(G^1,\overline{v})\simeq_{k,r}(G^2 \overline{u})$, if Duplicator wins
$d\ehr_k\big(N(\overline{v};r),
\overline{v};\, N(\overline{u};r),\overline{u}\big)$.\par
Given sets of vertices $X\subseteq V_1$ and $Y\subseteq V_2$
we say that $X$ and $Y$ have $k$-\textbf{similar}
$r$-neighborhoods, written as
$X\simeq_{k,r} Y$, if we can order their elements to form
lists $\overline{v}$, resp. $\overline{u}$ such that 
$(G^1,\overline{v})\simeq_{k,r}(G^2,\overline{u})$.
\par
Fix $r\in \N$. Suppose that $X\subseteq V_1$ and 
$Y\subseteq V_2$ can
be partitioned into sets $X=X_1\cup \dots \cup X_a$
and $Y=Y_1\cup \dots \cup Y_b$ 
such that $N(X_i;r)$'s, and the
$N(Y_i;r)$'s, are connected and disjoint. 
We say that $X$ and
$Y$ have $k$-\textbf{agreeable} $r$-neighborhoods,
written as $(G^1,X)\cong_{k,r} (G^2,Y)$, 
if for any set $Z\subset V_\delta$, with $\delta\in \{1,2\}$,
among the $X_i$'s or the $Y_i$'s
it is satisfied that ``the number of $X_i$'s  
such that $(G^\delta, Z) \simeq_{k,r} (G^1,X_i)$ 
and the number of $Y_i$'s such that
$(G^\delta,Z)\simeq_{k,r} (G^2,Y_i)$
are both equal or are both greater 
or equal than $k$" .

The main theorem of this section,which
is a slight strengthening of Theorem 
2.6.7 from \cite{spencer2013strange}, is the following:

\begin{theorem}\label{ThmDuplicator}
	Set $r=(3^k-1)/2$.
	Let $G^1,G^2$ be hypergraphs and let $V_1:=V(G^1)$, $V_2:=
	V(G^2)$.
	Suppose there exist
	sets $X\subseteq V_1$, $Y\subseteq V_2$ with the 
	following properties:
	\begin{enumerate}
		\item[(1)] $(G^1,X)\cong_{k,r} (G^2,Y)$.
		\item[(2)] Let $r^\prime\leq r$. Let $v\in V_1$ be
		a vertex such that $d(X,v)> 2r^\prime + 1$. Let 
		$\overline{u}\in (V_2)^{k-1}$ be a tuple of vertices. 
		Then there exists $u\in V_2$ such that 
		$d(u,\overline{u})>2r^\prime+1$,
		$d(Y,u)>2r^\prime +1$ and
		$(G^1,v)\simeq_{k,r^\prime} (G^2,u)$.	
		\item[(3)] Let $r^\prime\leq r$. Let $u\in V_2$ be
		a vertex such that $d(Y,u)> 2r^\prime + 1$. Let 
		$\overline{v}\in (V_1)^{k-1}$ be a tuple of vertices. 
		Then there exists $v\in V_1$ such that 
		$d(v,\overline{v})>2r^\prime+1$,
		$d(X,v)>2r^\prime +1$ and
		$(G^1,v)\simeq_{k,r^\prime} (G^2,u)$
	\end{enumerate}
	Then Duplicator wins $\ehr_k\big(G^1;G^2\big)$.
\end{theorem}

In order to prove this theorem we need to make two observations
and prove a previous lemma. 

\begin{obs} \label{obs1}
	Let $H^1$, $H^2$ be hypergraphs and 
	$\overline{v}\in V(H^1)^*$, $\overline{u}\in V(H^2)^*$,
	be lists of vertices. Suppose that
	Duplicator wins $d\ehr_k(H^1,\overline{v}; \, H^2,\overline{u})$.
	Then, for any $r\in \N$, $(H^1, \overline{v})\simeq_{k,r} 
	(H^2,\overline{u})$. A direct consequence of this fact 
	is that 
	given hypergraphs $G^1, G^2$ and sets
	$X\subseteq V(G^1)$, $Y\subseteq V(G^2)$ such that
	$(G^1,X)\simeq_{k,r} (G^2,Y)$ for some $r\in \N$, 
	then for any $r^\prime \leq r$ it also holds 
	$(G^1,X)\simeq_{k,r^\prime} (G^2,Y)$
\end{obs}

Given a set $S$ and tuples $\overline{s},\overline{t}\in S^*$
we write $\overline{s}^\frown \overline{t}$ to denote their 
concatenation.  

\begin{obs} \label{obs2}
	Let $H_1$, $H_2$ be hypergraphs and 
	$\overline{v}$, $\overline{u}$, be lists of vertices
	from $V(H_1)$ and $V(H_2)$ respectively. Suppose 
	Duplicator wins $d\ehr_k(H_1,\overline{v};\,H_2,\overline{u})$. 
	Let $v\in V(H_1),u\in V(H_2)$ be vertices
	played in the first round of an instance of the game 
	where Duplicator is following a winning strategy. Then 
	Duplicator also wins $d\ehr_{k-1}(H_1,\overline{v_2}; \,
	H_2,\overline{u_2})$, where $\overline{v_2}:=\overline{v}^\frown v$
	and $\overline{u_2}:=\overline{u}^\frown u$.
\end{obs}

\begin{lemma} \label{lemm:Duplicator}
	Let $G^1$, $G^2$ be hypergraphs and let $V_1:=V(G^1),
	V_2:=V(G^2)$. Let $\overline{v}\in V_1^*$ and
	$\overline{u} \in V_2^*$ be lists of vertices. Let
	$r\in \N$ be greater than zero. Suppose that
	$(G^1,\overline{v})\simeq_{k,3r+1} (G^2,\overline{u})$.
	Let $v \in V_1$ and $u\in V_2$
	be vertices played in the first round of an instance of 
	\[
	d\ehr_k\big(\, N(\overline{v};3r+1),
	\overline{v}; \quad N(\overline{u};3r+1),\overline{u}\, \big)
	\]
	where Duplicator is following a winning strategy. Further suppose
	that $d(\overline{v},v)\leq 2r+1$ (and in consequence
	$d(\overline{u},u)\leq 2r+1$ as well). 
	Let $\overline{v_2}:=\overline{v}^\frown v$
	and $\overline{u_2}:=\overline{u}\frown u$.
	Then $(G^1,\overline{v_2})\simeq_{k-1,r}
	(G^2,\overline{u_2})$.
\end{lemma}

\begin{proof}
	Using \cref{obs2} we get that Duplicator wins 
	\[
	d\ehr_{k-1}\big(\, N(\overline{v};3r+1),
	\overline{v_2}; \quad N(\overline{u};3r+1)
	,\overline{u_2} \, \big)\]
	as well. Call $H_1=N(\overline{v};3r+1)$,
	$H_2=N(\overline{u};3r+1)$. Then by \cref{obs2}
	Duplicator wins
	\[
	d\ehr_{k-1}\big(\, N^{H_1}(
	\overline{v_2};r),\overline{v_2};\quad
	N^{H_2}(\overline{u_2};r),\overline{u_2}\, \big).
	\]
	Because of this if we prove $N^{G^1}(\overline{v_2};r)
	=N^{H_1}(\overline{v_2};r)$ and $N^{G^2}(\overline{u_2};r)
	=N^{H_2}(\overline{u_2};r)$, then we are finished. 
	Let $z\in N^{G^1}(v^\prime;r)$. Then
	$d(z,\overline{v})\leq d(z,v^\prime)+d(v^\prime,\overline{v})=3r+1$.
	In consequence, $N^{G^1}(v;r)\subset H_1$. Thus,
	$N^{G^1}(\overline{v_2};r)\subseteq H_1$, and $N^{G^1}(\overline{v_2};r)
	=N^{H_1}(\overline{v_2};r)$. Analogously we obtain 
	$N^{G^2}(\overline{u_2};r)=N^{H_2}(\overline{u_2};r)$, as we wanted. 
\end{proof}
\noindent\rule{2cm}{0.4pt}\par

Now we are in conditions to prove \cref{ThmDuplicator}.





\begin{proof}[Proof of \cref{ThmDuplicator}]
	Define $r_0=0$ and $r_i=3r_{i-1}+1$ for $i>0$.
	Let us denote by $w_i$ and $z_i$ the vertices played
	in $G^1$ and $G^2$ respectively during the $i$-th
	round of $\ehr_k(G^1,G^2)$. 
	%Set 
	%$\overline{v}[i]:=v_1,\dots,v_i$ and
	%$\overline{u}[i]:=u_1,\dots,u_i$
	%We say that Duplicator can play following the strategy $S$
	%if they can play in a way that
	%at the end of the $s$-th round, $\overline{w}[s]$ and
	%$\overline{z}[s]$ have $(k-s)$-similar $r_{k-s}$-neighborhoods.
	%In particular this means that at the end of the $k$-th
	%round Duplicator will have won $\ehr_k(G^1,G^2)$.
	\par
	
	Let $X_1,\dots,X_a$ and 
	$Y_1,\dots,Y_b$ be partitions of 
	$X$ and $Y$ respectively
	as in the definition of $k$-agreeability.
	We will show a winning strategy for Duplicator
	in $d\ehr_{k}\big(G^1;\, G^2\big)$.	
	Let $r_k=1$ and for each $i\in [k-1]$ 
	let $r_i=3r_{i+1}+1$. In particular, 
	$r_1=r=(3^k-1)/2$.
	
% During the game
%	Duplicator will track of sets of lists $L^1[i]$'s
%	and $L^2[i]$'s. At the end of the $i$-th round
%	Duplicator will obtain $L^1[i]$, resp $L^2[i]$
%	performing one of the following operations on 
%	$L^1[i-1]$, resp $L^2[i-1]$:
%	\begin{itemize}
%		\item Adding a list $\overline{v}\in (V_1)^*$
%		to $L^1[i-1]$ and marking it with the index $i$. 
%		\item Appending a new vertex $v\in V_1$ to an 
%		existing list $\overline{v}\in L^1[i-1]$.
%	\end{itemize}	
%	Let $r_k=1$ and for each $i\in [k-1]$ 
%	let $r_i=3r_{i+1}+1$.
%	We are going to show that Duplicator can 
%	play in a way such that
%	at the end of the $i$-th 
%	round the following conditions
%	are satisfied:
%	\begin{itemize}
%		\item[(1)] 
%		
%		
%		
%	\end{itemize}
%	
%	
%	\[\mathcal{X}[0]=\emptyset,
%	\quad \mathcal{Y}[0]=\emptyset.\]
%	At the end of the $s$-th round $\mathcal{X}[s-1]$,
%	resp. $\mathcal{Y}[s-1]$, will be updated into 
%	$\mathcal{X}[s]$,
%	resp. $\mathcal{Y}[s]$, by performing on it
%	some of the following operations: adding a new list
%	to it, appending one vertex to an existing list, and 
%	marking a list with the index $s$. Duplicator will
%	keep track of the sets $\mathcal{X}[s]$ and $\mathcal{Y}[s]$.\par
%	
%	We show first an strategy for Duplicator and will prove its
%	correctness afterwards. The strategy is as follows: At the 
%	beginning of the $s$-th round suppose Spoiler plays $w_s$ in
%	$G^1$. The case where they play $z_s$ in $G^2$ is symmetric.
%	Call $r=r_{k-s}$. There are three possibilities. 
%	\begin{itemize}
%		\item[Case 1:] The vertex $w_s$ satisfies
%		$d(w_s,\overline{v})>2r+1$ for all 
%		$\overline{v}\in \mathcal{X}[s-1]$. Then Duplicator 
%		can find a vertex $z_s$ in $G^2$ such that
%		$d(z_s,\overline{u})>2r+1$ for all 
%		$\overline{u}\in \mathcal{Y}[s-1]$ satisfying 
%		that $w_s$ and $z_s$ have $(k-s)$-similar
%		$r$-neighborhoods. To form $ \mathcal{X}[s]$
%		and $ \mathcal{Y}[s]$, add to $\mathcal{X}[s-1]$
%		and $ \mathcal{Y}[s-1]$ the lists consisting
%		of only $w_s$ and only $z_s$ respectively, and mark
%		them with the number $s$.
%		
%		\item[Case 2:] The vertex $w_s$ satisfies
%		$d(w_s,\overline{v})\leq 2r+1$ for a unique 
%		$\overline{v}\in \mathcal{X}[s-1]$,and
%		$\overline{v}$ is marked. In this case,
%		find the list $\overline{u}\in \mathcal{Y}[s-1]$
%		with the same mark. Duplicator 
%		then can chose $z_s\in N(\overline{u},2r+1)$
%		in response to $w_s$ according to a winning strategy
%		for
%		\[
%		d\ehr_{k-s}(N(\overline{v},3r+1),\overline{v},
%		N(\overline{u},3r+1),\overline{u}).
%		\]
%		To form $ \mathcal{X}[s]$
%		and $ \mathcal{Y}[s]$, append $w_s$ and $z_s$
%		to $\overline{v}$ and $\overline{u}$ respectively.
%		
%		\item[Case 3:] The vertex $w_s$ satisfies
%		$d(w_s,\overline{v})\leq 2r+1$ for a unique 
%		$\overline{v}\in \mathcal{X}[s-1]$,and
%		$\overline{v}$ is not marked. In this case we 
%		can	find a non-marked 
%		list $\overline{u}\in \mathcal{Y}[s-1]$
%		such that $\overline{v}$ and $\overline{u}$ 
%		have $(k-s)$-similar $(3r+1)$-neighborhoods. 
%		Duplicator then can chose $z_s\in N(\overline{u},2r+1)$
%		in response to $w_s$ according to a winning strategy
%		for
%		\[
%		d\ehr_{k-s}(N(\overline{v},3r+1),\overline{v},
%		N(\overline{u},3r+1),\overline{u}).
%		\]
%		To form $ \mathcal{X}[s]$
%		and $ \mathcal{Y}[s]$, append $w_s$ and $z_s$
%		to $\overline{v}$ and $\overline{u}$ respectively,
%		and mark those lists with the number $s$. 
%	\end{itemize}
%	
%	All that is left now is to prove the correctness of the
%	strategy. We show that at the end the $s$-th round, if 
%	two lists $\overline{v} \in \mathcal{X}[s]$ and 
%	$\overline{u} \in \mathcal{Z}[s]$ have the same mark then
%	$\overline{v}$ and $\overline{u}$ have $(k-s)$-similar
%	$r_{k-s}$-neighborhoods. This happens trivially at
%	the end of the zeroth round -i.e., the beginning 
%	of the game- as there are no marked lists. Assume the
%	statement holds up to the end of the $(s-1)$-th round, 
%	where $s>0$. 
%	
%	\begin{itemize}
%		\item[Case 1:] Notice that the lists
%		in $\mathcal{Y}[s-1]$ only contain the
%		vertices previously played in $G^2$ and 
%		the ones from $Y$. Thus, assumption $(3)$ 
%		of the theorem, (or assumption $(2)$ in the 
%		symmetric
%		case where Spoiler plays in $G^2$) assures us
%		that Duplicator can always find such $z_s$ 
%		sufficiently far away from all the other lists. 
%		In this case, the only new marked lists in $\mathcal{X}[s]$
%		and $\mathcal{Y}[s]$ are the ones
%		consisting of $w_s$ and $z_s$ respectively. By assumption
%		$w_s$ and $z_s$ have $(k-s)$-similar $r_{k-s}$-neighborhoods.
%		
%		\item[Case 2:] Notice that by the induction hypothesis 
%		$\overline{v}$ and $\overline{u}$ have $(k-s+1)$-similar
%		$r_{s-k+1}$-neighborhoods, and in consequence a winning strategy
%		for Duplicator exists. Using \cref{lemm:Duplicator} we obtain 
%		that the extended lists $\overline{v},w_s$ and $\overline{u},z_s$
%		have $(k-s)$-similar $r_{s-k}$-neighborhoods. 	
%		
%		\item[Case 3:] This case is analogous to the previous one.
%		The definition of $k$-agreeability implies that there is 
%		such an unmarked list $\overline{u}$ available. Using \cref{lemm:Duplicator} 
%		we obtain 
%		that the extended lists $\overline{v},w_s$ and $\overline{u},z_s$
%		have $(k-s)$-similar $r_{s-k}$-neighborhoods.	
%	\end{itemize} 
%	
%	In the three cases, if $\overline{v}$ and $\overline{v}$
%	are lists in $\mathcal{X}[s-1]$ and $\mathcal{Y}[s-1]$
%	respectively that share the same mark and remain unmodified
%	in $\mathcal{X}[s]$ and $\mathcal{Y}[s]$, then by the 
%	induction hypothesis $\overline{v}$ and $\overline{v}$
%	have $(k-s+1)$-similar $r_{k-s+1}$-neighborhoods. This
%	easily implies that they also have
%	$(k-s)$-similar $r_{k-s}$-neighborhoods.\par
%	At the end of the game, if $\overline{v}\in \mathcal{X}[k]$ and 
%	$\overline{u}\in \mathcal{Y}[k]$ are lists with the same mark
%	then the natural mapping between $\overline{v}$ and $\overline{u}$
%	defines an isomorphism between $G^1[\overline{v}]$ and $G^2[\overline{u}]$.
\end{proof}

\todo[inline]{Quiz\'as reordenando esta demostraci\'on se puede acortar o se entiende mejor.}


\subsection{Types of trees}

We define tree $T$ as a connected hypergraph such that
$ex(T)=-1$. We define a vertex-rooted tree $(T,v)$ 
as a tree $T$ with a 
distinguished vertex $v\in V(T)$ called its root. We will
usually omit the root when it is not relevant and 
write just $T$ instead of $(T,v)$. We define the set
of initial edges of a vertex-rooted tree $(T,v)$ as the
set of edges in $T$ that contain $v$. \par
%
%Similarly, we define an edge-rooted tree $(T,e,v)$
%as a tree $T$ with a distinguished edge $e\in E(T)$ and
%a distinguished vertex $v\in e$. \par
Given a rooted tree $(T, v)$, and a vertex $u\in V(T)$, 
we define $\tau_{(T,v)}(u)$ as the tree $T[X]$ induced on the
set $X:=\{ \, w\in V(T) \, | \, d(v,w)=d(v,u)+ d(u,w) \,  \}
$, to which we assign $u$ as the root.
That is, $\tau_{(T,v)}(u)$ is the tree consisting of those vertices
whose only path to $v$ contains $u$.
\par
We define the radius of a vertex-rooted, or edge-rooted,
tree as the maximum distance between its marked
vertex and any other one. \par


Fix a natural number $k$. We will define 
two equivalence relations, one between 
rooted trees and another between pairs
$(T,e)$ of rooted trees $T$ and initial edges
$e\in E(T)$. We will name both relations
$k$-equivalence relations and
denote them by $\morph{k}$. 
They are defined recursively as follows:

\begin{itemize}
	\item Any two trees with radius zero are $k$-equivalent.
	Notice that those trees
	consist only of one vertex: their respective roots.
	\item Suppose that the $k$-equivalence relation has been
	defined for rooted trees with radius at most $r$. Let $\Sigma_r$
	be the set consisting of the root symbol $\tau$ and
	the $k$-equivalence classes of trees with radius lesser than $r$.
	Given a rooted tree $(T,v)$ with whose radius is lesser than $r$
	we define its canonical $\Sigma_r$-coloring as the map 
	$\chi_{(T,v)}: V(T)\rightarrow \Sigma_r$ satisfying that
	$\chi_{(T,v)}(u)$ is the $k$-equivalence class of $\mathrm{Tr}(u,T;v)$
	for any $u\neq v$ and $\chi_{(T,v)}(v)=\tau$. \par
	Let $T_1$ and $T_2$ be rooted trees with radius
	at most $r+1$. We say that $(T_1,v_1)\simeq_k (T_2,v_2)$ 
	if given any $\Sigma_r$-pattern $(e,\chi)$ the 
	"quantity of initial edges $e_1\prime\in E(T_1)$ such that
	$(e,\chi)\simeq (e_1,\chi_{(T_1,v_1)})$" and the
	"quantity of initial edges $e_2\prime\in E(T_2)$ such that
	$(e,\chi)\simeq (e_2,\chi_{(T_2,v_2)})$" are the same or
	are both greater than $k-1$.
\end{itemize}

We want prove the following
\begin{theorem} \label{thm:equivalenttrees} 
	Let $(T_1,v_1)$ and $(T_2,v_2)$ be rooted trees.
	Then, if they are $k$-equivalent Duplicator wins
	$d\ehr_{k}(T_1,v_1,T_2,v_2)$.
\end{theorem}

Before proceeding with the proof that we need an auxiliary
result. Let $(T,v)$ be a rooted tree and $e$ an 
initial edge of $T$. We define $Tree_{(T_v)}(e)$ as
the induced tree $T[X]$ on the set
$X:=\{v\} \cup \{\, u\in V(T) \, | \, d(v,u) = |e| + d(e,v) \,\}$,
to which we assign $v$ as the root. In other words, 
$Tree_{(T_v)}(e)$ is the tree formed of $v$ and all the vertices
in $T$ whose only path to $v$ contain $e$. 
Now we can check the following:

\begin{lemma} \label{lem:equivalentedges}
	Fix $r>0$. Suppose that theorem \ref{thm:equivalenttrees}
	holds for rooted trees with radii at most $r$.
	Let $(T_1,v_1)$ and $(T_2,v_2)$ be rooted trees with radii
	at most $r+1$. Let $e_1$ and $e_2$ be initial edges 
	of $T_1$ and $T_2$ respectively satisfying 
	$(T_1,e_1)\simeq_k (T_2,e_2)$. Name 
	$T^\prime_1=Tree_{(T_1,v_1)}(e_1)$ and 
	$T^\prime_2=Tree_{(T_2,v_2)}(e_2)$. Then
	Duplicator wins $d\ehr{k}(T^\prime_1, v_1, T^\prime_2,v_2)$.
\end{lemma}
\begin{proof}
	We show a winning strategy for Duplicator. 
	Suppose that in the $i$-th round of the game Spoiler
	plays on $T^\prime_1$. The other case is symmetric. Let
	$f:e_1\rightarrow e_2$ be a bijection as in the definition
	of $(T_1,e_1)\simeq_k (T_2,e_2)$. There are two possibilities:
	\begin{itemize}
		\item If Spoiler plays a vertex $v$ on $e_1$ 
		then Duplicator can play $f(v)$ on $e_2$. 
		\item Otherwise, Spoiler plays a vertex $v$ that belongs
		to some $Tree_{(T^\prime_1,v_1)}(u)$ for a unique $u\in e_1$
		different from the root $v_1$.
		By the definition of $(T_1,e_1)\simeq_k (T_2,e_2)$,
		$Tree_{(T^\prime_1,v_1)}(u)\simeq_k 
		Tree_{(T^\prime_2,v_2)}(f(u))$. As both these trees
		have radii at most $r$, by assumption Duplicator has a winning 
		strategy between them and they can follow it.		
	\end{itemize}
\end{proof}

Now we can prove the main theorem of this section:

\begin{proof}[Proof of \cref{thm:equivalenttrees}]~ \par
	Notice that, as $T_1\morph{k} T_2$, both $T_1$ and
	$T_2$ have the same radius $r$.
	We prove the result by induction on $r$.
	If $r=0$ then both $T_1$ and $T_2$ consist
	of only one vertex and we are done. \par
	Now let $r>0$ and assume that the 
	statement is true for all lesser values of $r$.
	We will show that there is a winning strategy 
	for Duplicator in
	$d\ehr_k(T_1,v_1,T_2,v_2)$.
	At the start of the game, set all the initial edges
	in $T_1$ and $T_2$ as non-marked. 
	Suppose that in the $i$-th round Spoiler plays in 
	$T_1$. The other case is symmetric. 
	\begin{itemize}
		\item If Spoiler plays $v_1$ then Duplicator plays $v_2$.
		\item Otherwise, the vertex played by Spoiler belongs to
		$Tree_{(T_1,v_1)}(e_1)$
		for a unique initial edge $e_1$ of $T_1$. 
		There are two possibilities:
		\begin{itemize}
			\item If $e_1$ is not marked yet, mark it with
			the index $i$. In this case, there is a 
			non-marked initial
			edge $e_2$ in $T_2$ satisfying 
			$(T_1,e_1)\simeq_k (T_2,e_2)$.
			Mark $e_2$ with the index $i$ as well. 
			Because of
			\cref{lem:equivalentedges}, Duplicator
			has a winning strategy in
			\[d\ehr{k}(Tree_{T_1}(e_1), v_1, 
			Tree_{T_1}(e_2),v_2)\] and can play according to it.
			\item If $e_1$ is already marked then there is
			a unique initial edge $e_2$ in $T_2$ marked with 
			the same mark as $e_1$ and 	
			$(T_1,e_1)\simeq_k (T_2,e_2)$. Again, 
			Because of
			\cref{lem:equivalentedges}, Duplicator
			has a winning strategy in
			\[d\ehr{k}(Tree_{T_1}(e_1), v_1, 
			Tree_{T_1}(e_2),v_2)\] and can
			continue playing 
			according to it.
			
			
		\end{itemize}
		Then Duplicator can find an initial 
		edge $e_2$ of $T_2$ such that
		$(T_1,e_1)\simeq_k (T_2,e_2)$.
		Because of
		\cref{lem:equivalentedges}, Duplicator
		has a winning strategy in
		$d\ehr{k}(Tree_{T_1}(e_1), v_1, 
		Tree_{T_1}(e_2),v_2) $ and can play according to it.
	\end{itemize}
	
	
\end{proof}
\todo[inline]{probablemente con alg\'un dibujo sencillo esta demostraci\'on se entienda mejor}

\section{Probabilistic results}
\subsection{Convergence to Poisson variables}



Given a natural numbers $n$ and $l$ we will use 
$(n)_l$ to denote 
$n(n-1)\cdots (n-l+1)$ or $1$ if $l=0$. 

Our main tool for computing probabilities will be
the following multivariate version of Brun's Sieve (
Theorem 1.23, \cite{bollobas2001random}).


\begin{theorem} \label{thm:BrunSieve}
	Fix $k\in \N$. For each 
	$n\in \N$, let $X_{n,1},\dots, X_{n,k}$ be non-negative
	random integer variables over the same
	probability space. Let $\lambda_1,\dots,\lambda_l$ 
	be real numbers. Suppose that for any $r_1,\dots,r_l \in \N$
	\[ 
	\Ln \mathrm{E}\big[
	\prod_{i=1}^{k} \binom{X_{n,i}}{r_i} \big]
	= \prod_{i=1}^{k} \frac{\lambda_i}{r_i !}.	
	\]
	Then the $X_{n,1},\dots,X_{n,k}$ converge in distribution to
	independent Poisson variables with means $\lambda_1,\dots,\lambda_k$ 
	respectively. 
\end{theorem}



\subsection{Almost all hypergraphs are simple}


We say that a connected hypergraph $G$ is \textbf{dense} if
$ex(G)>0$. Given $r\in \N$, we say that $G$ is \textbf{$r$-simple}
if $G$ does not contain any dense subgraph $H$ such that 
$diam(H)\leq r$. The goal of this section is to show that, for any
fixed $r$, a.a.s $G_n$ is $r$-simple.\par

\begin{lemma}
	Let $H$ be an hypergraph. Then 
	$\mathrm{E}\big[\# \text{ copies of }H \text{ in } G_n\big]=
	\Theta(n^{-ex(H)})$ as $n$ tends to infinity.  
\end{lemma}
\begin{proof}
It holds
\[
 \mathrm{E}\big[\# \text{ copies of }H \text{ in } G_n\big]=
 \sum_{H^\prime \in Copies(H,[n])} \PR{H^\prime \subset G_n}.
\]	
We have that $|Copies(H,[n])|=\frac{(n)_{v(H)}}{|Aut(H)|}$. Also, 
for any $H^\prime \in Copies(H,[n])$ it is satisfied
\[
\PR{H^\prime \subset G_n}= \prod_{R\in \sigma} \left(\frac{\beta_R}{n^{ar(R)-1}} 
\right)^{e_R(H)}.
\]
Substituting in the first equation we get
\[
\mathrm{E}\big[\# \text{ copies of }H \text{ in } G_n\big]=
\frac{(n)_{v(H)}}{|Aut(H)|}\cdot
\prod_{R\in \sigma} \left(\frac{\beta_R}{n^{ar(R)-1}}\right)^{e_R(H)}
\underset{n \to \infty}{\sim}
n^{-ex(H)} \cdot \frac{\prod_{R\in \sigma} \beta_R^{
e_R{H} }}{|Aut(H)|}.
\]	



%Given any one-to-one map $f\in [n]_{V(H)}$, let $X^H_{n,f}$ be 
%the indicator variable
%that takes value one when $f$ defines an monomorphism 
%between $H$ and $G_n$ and zero otherwise. 
%The probability that $X^H_{n,f}=1$ is exactly
%$\prod_{i=1}^t \left(\frac{\beta_i}{n^{a_i-1}}\right)^{e_i(H)}$ which can
%be written as $C\cdot n^{-ex(H)-v(H)}$ for some constant
%$C$ that does not depend on $f$ nor $n$. Define 
%$X^H_n=\sum_{f\in [n]_{V(H)}} X^H_{n,f}$. Then, by definition, the number of 
%copies of $H$ in $G_n$ is exactly $X^H_n/|Aut(H)|$.
%Taking into account that 
%\[
%\mathrm{E}[X^H_n]=(n)_{v(H)} \cdot C\cdot n^{-\sum_{i=1}^t (a_i-1)\cdot e_i(H)}= \Theta(n^{-ex(H)}),
%\]
%the result follows. 
%Indeed, let $n\in \N$ and let $G_n$ be a random hypergraph sampled from
% $\mathrm{G}^\mathcal{C}(n,\overline{p})$. Let
% $\overline{h}$ be an ordering of the vertices
%in $V(H)$. For any list 
% $\overline{v}\in [n]_{|V(H)|}$ (recall that $[n]=V(G)$), 
%let $X_{\overline{v}}$ be the random indicator variable
%that takes value $1$ if the natural map 
% $f:\overline{h}\rightarrow \overline{v}$ defines an homomorphism 
%between $H$ and $G$. That is, $X_{\overline{v}}$ takes value $1$
%with probability
% $ \prod_{i=1}^{t} \big(\beta_i n^{1-a_i} \big)^{|E_i(H)|},
% $
%and zero otherwise. The sum of all $X_{\overline{v}}$'s for 
%all $\overline{v}\in [n]_{|V(H)|}$ counts how many labelled 
%copies of $H$ are in $G_n$. Thus, 
%\[ \mathrm{E}\big[\# \text{labelled copies of }H \text{ in } G_n\big] 
%= \sum_{\overline{v}\in [n]_{|V(G)|}} 
%\prod_{i=1}^{t} \big(\beta_i n^{1-a_i} \big)^{|E_i(H)|}
%= (n)_{|V(H)|} \prod_{i=1}^{t} \big(\beta_i n^{1-a_i} \big)^{|E_i(H)|}.
%\]
%The expected number of copies of $H$ in $G_n$ is then this last
%expectation divided by the number of automorphisms of $H$, $|Aut(H)|$.
%In consequence,
%\begin{align*}
% &\Ln \mathrm{E}\big[\# \text{copies of }H \text{ in } G_n\big] 
%=\Ln \frac{(n)_{|V(H)|}}{|Aut(H)|} \prod_{i=1}^{t} 
%\big(\beta_i n^{1-a_i} \big)^{|E_i(H)|}
%=\\ &\Ln \Big[(n)_{|V(H)|}\prod_{i=1}^{t}n^{(1-a_i)|E_i(H)|}\Big]
%\frac{\prod_{i=1}^{t} \beta_i^{|E_i(H)|}}{|Aut(H)|} \simeq \Ln
%n^{-ex(H)}\frac{\prod_{i=1}^{t} \beta_i^{|E_i(H)|}}{|Aut(H)|},
%\end{align*}
%and last expression belongs to $\theta(n^{-ex(H)})$, as desired.\par
\end{proof}

As a corollary of last result we get the following:  
\begin{lemma} \label{lem:nocopiesdense}
	Let $H$ be an hypergraph such that $ex(H)>0$. Then
	a.a.s there are no copies of $H$ in $G_n$. 
\end{lemma}  
\begin{proof}
	Because of the previous fact, 
	$\mathrm{E}\big[\# \text{ copies of }H \text{ in } G_n\big] 
	\xrightarrow[]{n\to \infty} 0$ . An application of the first moment
	method yields the desired result. 
\end{proof} 



A similar result that will be useful later is the following:

\subsubsection{Rooted hypergraphs}

A rooted hypergraph $(G,\overline{u})$ is an hypergraph $H$ together with 
an ordered sequence of distinguished vertices $\overline{u}\in (V(H))_*$.
An isomorphism between two rooted hypergraphs $(G,\overline{u})$ and
$(H,\overline{v})$ is a map $f: V(G)\rightarrow V(H)$ such that $f$
is an isomorphism between $G$ and $H$ that satisfies the additional condition
$f(\overline{u})=\overline{v}$. An automorphism of $(G,\overline{u})$  is 
an isomorphism from $(G,\overline{u})$  to itself. 
We write $Aut(G,\overline{u})$ to denote the group
of automorphisms of $(G,\overline{u})$. \par

Given a rooted hypergraph $(G,\overline{u})$, a set of vertices
$V$ and a list $\overline{v}\in (V)_*$ such that $len(\overline{u})
= len(\overline{v})$ we define the set $Copies((G,\overline{u}),
(V,\overline{v}))$ as the set of rooted hypergraphs 
$(H,\overline{v})$ isomorphic to $(G,\overline{u})$ such that
$V(H)\subset V$. \par

\begin{lemma}\label{lem:nocopiesfixed}
	Let $(H,\overline{u})$ be a rooted hypergraph. Let
	$\overline{v}\in (\N)_*$ be a list of vertices satisfying
	$len(\overline{u})=len(\overline{v})$. For each $n\in \N$ 
	let $X_n$ be the random variable that
	counts the copies $(H^\prime,\overline{v})\in
	Copies((H,\overline{u}),
	([n],\overline{v}))$ that are contained in $G_n$. Then
	$\mathrm{E}\big[ X_n \big]=\Theta(n^{-ex(H)-len(\overline{u})})$.	
\end{lemma}
\begin{proof}
	It holds
	\[
	\mathrm{E}\big[ X_n \big]=\sum_{H^\prime\in (H^\prime,\overline{v})\in
		Copies((H,\overline{u})} \PR{H^\prime \subset G_n}
	= \frac{(n)_{(v(H)-len(\overline{u}))}}{|Aut(H,\overline{u})|} 
	\cdot\prod_{R\in\tau} \left( \frac{\beta_R}{n^{ar(R)-1}}\right)^{e_R(H)}
	\]
\end{proof}


%
%\begin{lemma}
%	Let $\overline{v}:=(v_1,\dots,v_j)\in \N*$.
%	Let $H$ be an hypergraph such that $ex(H)>-j$. 
%	Then a.a.s there is no copy of $H$ in $G_n$ that
%	contains all $v_1,\dots,v_j$. 
%\end{lemma} 
%\begin{proof}
%It is sufficient to show that
%\begin{equation}\label{eqn:aux}
%\mathrm{E}\big[\# \text{ copies of }H \text{ in } G_n \text{ containing }
%\overline{v} \big]\xrightarrow[]{n\to \infty} 0.
%\end{equation}
%Then, because of a first moment argument the result follows.\par
%Suppose that $v(H)\geq j$. Otherwise the statement is trivial. 
%As before, given any $f\in [n]_{V(H)}$, let $X^H_{n,f}$ be the random
%variable that takes value one if $f$ is a monomorphism from $H$ to $G_n$
%and zero otherwise. The probability that $X^H_{n,f}$ takes value one is
%$C\cdot n^{-ex(H)-v(H)}$ for some constant $C$ independent from $f$ and $n$. 
%Let 
%\[ Y^H_{n,\overline{x}}= \sum_{\substack{f\in [n]_{V(H)}\\ 
%\overline{x}\subset Im(f)}} X^H_{n,f}.\]
%The number of functions $f\in [n]_{V(H)}$ such that $v_1,\dots,v_j\in Im(f)$
%is $\Theta(n^{v(H)-j})$. In consequence 
%$
%\mathrm{E}\big[Y^H_{n,\overline{v}}\big]=\Theta(n^{-ex(H)-j})
%$, and 
%\[\mathrm{E}\big[\# \text{ copies of }H \text{ in } G_n \text{ containing }
%\overline{v} \big]=\Theta(n^{-ex(H)-j}).
%\]
%This, together with $ex(H)>-j$, proves \cref{eqn:aux}. 
%\end{proof}

The main theorem of this section is the following
\begin{theorem} \label{thm:simple}
	Let $r\in \N$. Then a.a.s $G_n$ is $r$-simple. 
\end{theorem}
	The first moment method alone is not sufficient
	to prove our claim because the amount of dense 
	hypergraphs	$H$ such that $diam(H)\leq r$ is not finite
	in general. Thus, we need to prove that it suffices to
	prohibit a finite amount of dense sub-hypergraphs in order
	to guarantee that $G_n$ is $r$-simple.
\begin{lemma}
	Let $H$ be a dense hypergraph of radius $r$.
	Then $H$ contains a dense sub-hypergraph $H^\prime$ 
	with size no greater than
	$(a+2)(r+1)+2a$, where $a$ is the largest edge size in $H$. 
\end{lemma}
\begin{proof}
	Choose $x\in V(H)$. Successively remove from $G$ edges $e$
	such that $d(x, e)$ is maximum until the resulting graph 
	$H^\prime$ has excess no greater than $0$. We have two cases:
	\begin{itemize}[leftmargin=*]
		\item $ex(H^\prime)=-1$. Let $e=[x_1, \dots, x_b]$ be
		the last removed edge and
		$e\cap H^\prime=\{ x_{i_1}, \dots, x_{i_d}\}$.
		For any $j=1,\dots, d$ choose 
		$P_j$ a path of size no greater than $r+1$ joining
		$x$ and $x_{i_j}$ in $H^\prime$.   
		Then $P_1\cup \dots P_d \cup e$ is a dense sub-hypergraph of $H$
		of size less than $a(r+1) + a< (a+2)(r+1) + 2a$.
		\item $ex(H^\prime)=0$. Let $e_1=[x_1, \dots, x_{b_1}]$ be the
		last removed edge. Continue removing the edges of $G^\prime$ 
		that are at maximum distance from $x$ until you obtain 
		$H^{\prime \prime}$ with $ex(H^{\prime\prime})=-1$. Let 
		$e_2=[y_1, \dots, y_{b_2}]$ be the last removed edge this time.
		As before, let $e_1\cap H^\prime=\{ x_{i_1}, \dots, x_{i_d}\}$
		and for $j=1,\dots, d$ let $P_j$ a path of size no greater than $r+1$ 
		joining	$x$ and $x_{i_j}$ in $H^\prime$
		Then $e_2 \cup H^{\prime \prime}=\{ y_{i_1}, y_{i_2}  \}$.
		Let $Q_1, Q_2$ be paths size no greater than $r+1$ from
		$x$ to $y_{i_1}$ and $y_{i_2}$ in $H^{\prime \prime}$.
		Then $Q_1 \cup Q_2 \cup e_2$ is a graph of likelihood $0$ 
		and size less than $2r+2 + a$,
		and $Q_1\cup Q_2\cup P_1 \cup \dots \cup P_d \cup e_1 \cup e_2$ 
		is a critical graph	with size less than $(2+a)(r+1) + 2a$	
	\end{itemize} 
\end{proof}

Now we are in conditions to prove \cref{thm:simple}.

\begin{proof}
	Because of last lemma there is a constant $R$ such that 
	``$G$ does not contain dense hypergraphs of size bounded by $R$" implies
	that ``$G$ is $r$-simple". Thus,
	\[ \Ln \mathrm{Pr}\big( G_n \text{ is } r \text{-simple}  \big)
	\geq \Ln \mathrm{Pr} \big( G_n \text{ does not contain dense 
	hypergraphs of size bounded by } R\big).\] 
	Because of	\cref{lem:nocopiesdense}, given any individual dense hypergraph,
	the probability that there are no copies
	of it in $G_n$ tends to $1$ as $n$ goes to infinity. Using that
	there are a finite number of dense hypergraphs of size bounded by
	$R$ we deduce that the RHS of last inequality tends to $1$. 
\end{proof}

%\subsection{Counting colored sub-hypergraphs}
%
%
%\begin{definition} 
%	Given a set $\Sigma$, a $\Sigma$-hypergraph is a pair
%	$(G,\chi)$ consisting of an hypergraph $G$ and a map 
%	$\chi: V(G) \rightarrow \Sigma$.  
%	Given two $\Sigma$-hypergraphs $(H,\rho)$ and $(G,\chi)$,
%	an isomorphism between them is an hypergraph isomorphism 
%	$f:V(H)\rightarrow V(G)$ satisfying $\rho(v)=\chi(f(v))$
%	for any $v\in V(H)$. 
%	An automorphism of a $\Sigma$-hypergraph $(G,\chi)$ is an
%	isomorphism from $(G,\chi)$ to itself. As with the case of
%	hypergraphs we write $Aut(G,\chi)$ to denote the group of 
%	automorphisms of $(G,\chi)$.
%	\par
%	Let $(H,\rho), (G,\chi)$ be two $\Sigma$-hypergraphs. 
%	Then a copy of $H$ in $G$ is
%	a sub-hypergraph $H^\prime\subset G$ such that 
%	$(H,\rho)$ is isomorphic to 
%	$(H^\prime,\chi|_{_{H^\prime}})$.\par
%	Given a $\Sigma$-hypergraph $(G,\chi)$ and a set $V$ we
%	define the set $Copies(S,(G, \chi))$ as the one that contains all 
%	possible $\Sigma$-hypergraphs $(H,\rho)$ isomorphic to $(G,\chi)$ 
%	such that $V(H)\subset S$.	
%\end{definition}
%
%\begin{definition}
%	Given a set $\Sigma$, a random $\Sigma$-coloring of $G_n$ is 
%	a random function $\chi_n: [n]\rightarrow \Sigma$. We say that	
%	$\chi_n$ is symmetric if for any $s\in \Sigma$ the probability
%	$\mathrm{Pr}\big( \chi_n(v)=s \big)$ is the same for any vertex
%	$v\in [n]$. Notation $\mathrm{Pr}\big[\chi_n=s\big]$. \par
%	For each $n\in \N$ let $\chi_n$ be a random $\Sigma$-coloring of $G_n$.
%	We say that the succession $(\chi_n)_{n\in \N}$ is regular if
%	the $\chi_n$'s are symmetric and for any $s\in \Sigma$ the limit
%	$\Ln \mathrm{Pr}\big[ \chi_n = s \big]$ exists. 
%\end{definition}
%
%
%Remark: A random coloring $\chi$ of $G_n$ does not have to be independent from
%$G_n$. In fact, in the cases we are going to consider $\chi$ will be determined
%by $G_n$. 
%
%\begin{definition}
%	Let $\Sigma_1,\dots,\Sigma_k$ be a sets. For each $i\in [k]$
%	let $(\chi_{n,i})_{n \in \N}$ be a random regular sequence of
%	$\Sigma_i$-colorings.
%	Let $\mathcal{F}$ be a family of hypergraphs.
%	We say that the successions $(\chi_{n,1})_{n \in \N},\dots,
%	(\chi_{n,k})_{n \in \N}$ are $\mathcal{F}$-independent if
%	for any given
%	\begin{itemize}
%		\item fixed finite number of copies of hypergraphs from 
%		$\mathcal{F}$ in $\N$,
%		\[
%		S \subset \bigcup_{H\in \mathcal{F}} Copies(H,\N).
%		\]		
%		\item fixed disjoint sets of vertices 
%		$V_1, \dots, V_k \subset \bigcup_{H\in S} V(H).$
%		\item for each $i\in [k]$ and each $v\in V_i$, 
%		a fixed label $s(v)\in \Sigma_i$
%	\end{itemize}
%	it is satisfied
%	\[
%	\Ln \mathrm{Pr}\big(
%	\bigwedge_{i=1}^k \bigwedge_{v\in V_i} \chi_{n,i}(v)=s(v)
%	\, \big| \, \bigwedge_{H\in S} H\subset G_n \,
%	\big) = \prod_{i=1}^k \prod_{v\in V_i} \mathrm{Pr}\big[\chi_i=s(v)
%	\big]		
%	\]  
%\end{definition}
%
%\begin{definition}
%	Let $H_1,\dots, H_k$ be hypergraphs. Let $n,b_1,\dots,b_k\in \N$
%	A $b_1,\dots,b_k$-configuration of $H_1,\dots, H_k$ over $[n]$
%	is an ordered tuple $(O_1,\dots,O_k)$ where for each $i\in [k]$
%	$O_i$ is an ordered $b_i$-tuple of different $H_i$-hypergraphs 
%	over $[n]$. In other words, each $O_i$ is an element of
%	$\big( Copies(H,[n])\big)_{b_i}$, and the set of 
%	$b_1,\dots,b_k$-configurations of $H_1,\dots, H_k$ over $[n]$
%	is precisely $\prod_{i=1}^{k}\big( Copies(H,[n])\big)_{b_i}$.
%\end{definition}
%
%\begin{definition}
% 	The underlying set of a configuration $\omega
% 	=  (O_1, \dots, O_k)$ is the defined as
% 	$S_{\omega}:=\{ H\in O_i \, | \, i\in [k]\}$.
% 	A configuration $\omega$ is called disjoint
%	if all the hypergraphs belonging to its underlying set
%	$S_\omega$ have disjoint sets of vertices. 
%\end{definition}
%
%\begin{theorem}
%	Let $k\in \N$. For each $i\in [k]$ 
%	\begin{itemize}
%		\item Let $\Sigma_i$ be a set, let $H_i$ be a unicycle and 
%		let $\rho^i$ be a $\Sigma_i$-coloring of $H_i$.
%		\item Let $(\chi^i_n)_{n\in\N}$ be a succession of
%		random $\Sigma_i$-colorings of $(G_n)_{n\in \N}$
%		\item Let $X_{i,n}$ be the random variable that counts
%		the number of copies of $(H_i, \rho^i)$ in
%		$(G_n,\chi^i_n)$.				
%	\end{itemize}
%	Let $\mathcal{F}=\{H_1,\dots, H_n\}$. Suppose that the
%	successions $(\chi^1_n)_{n\in\N}, \dots, (\chi^k_n)_{n\in\N}$
%	are $\mathcal{F}$-independent. Then, for each $a_1,\dots,a_k\in \N$
%	\[
%	\Ln \mathrm{Pr}\big( \bigwedge_{i=1}^k X_{n,i}=a_i  \big)=
%	\prod_{i=1}^{k}e^{-\lambda_i}\frac{\lambda_i^{a_i}}{a_i!},
%	\]
%	where for each $i\in [k]$,
%	\[
%	\lambda_i:= \frac{\prod_{j\in \sigma} \beta_j^{e_j(H_i)}}{|Aut(H_i,\rho^i)|} 
%	\prod_{v\in V(H_i)} \mathrm{Pr}\big[\chi^i=\rho^i(v)\big].
%	\]
%\end{theorem}
%\begin{proof}
%	Because of \cref{thm:BrunSieve} we only need to show that for any 
%	fixed $b_1,\dots, b_k\in \N$ it is satisfied
%	\[
%	\Ln \mathrm{E}\big[ \prod_{i=1}^{k} (X_{n,i})_{b_i} \big]=
%	\prod_{i=1}^{k} \lambda_i^{b_i}.		
%	\]
%	For each $n\in \N$ let $\Omega_n$ be the set
%	of $b_1, \dots, b_k$-configurations of $(H_1,\rho^1)
%	,\dots, (H_k, \rho^k)$ over $[n]$. Then
%	\[
%	\Ln \mathrm{E}\big[ \prod_{i=1}^{k} (X_{n,i})_{b_i} \big]=
%	\Ln \sum_{(O_1,\dots, O_k)\in \Omega_n}
%	\mathrm{Pr}
%	\big(
%	(O_1,\dots, O_k) \subset G_n
%	\big).	
%	\]
%	Let $\Omega^{\times}_n\subset \Omega_n$ be the set of 
%	disjoint configurations in $\Omega_n$. Because of REF,
%	\[
%	\Ln \sum_{(O_1,\dots, O_k)\in \Omega_n}
%	\mathrm{Pr}
%	\big(
%	(O_1,\dots, O_k) \subset G_n
%	\big)=
%	\Ln \sum_{(O_1,\dots, O_k)\in \Omega^\times_n}
%	\mathrm{Pr}\big(
%	(O_1,\dots, O_k) \subset G_n
%	\big).
%	\]
%	Because of the symmetry of the random hypergraph $G_n$ and
%	the colorings $\chi^1_n, \dots, \chi^k_n$ the probability
%	$\mathrm{Pr}\big(
%	(O_1,\dots, O_k) \subset G_n
%	\big)$ is the same for all $(U_1,\dots, U_k)\in 
%	\Omega^\times_n$. Thus, if we fix
%	$(O_1, \dots, O_k)$ a 
%	disjoint $b_1,\dots,b_k$-configuration of
%	 $(H_1,\rho^1)
%	,\dots, (H_k, \rho^k)$ over $\N$, 
%	\[
%	\Ln \sum_{(O_1,\dots, O_k)\in \Omega^\times_n}
%	\mathrm{Pr}\big(
%	(O_1,\dots, O_k) \subset G_n
%	\big) =
%	\Ln |\Omega^{\times}_n|\cdot \mathrm{Pr}\big(
%	(U_1,\dots, U_k) \subset G_n
%	\big).
%	\]
%	Let $S$ be the underlying set of the configuration $(U_1,\dots,U_k)$.
%	Let $l= \sum_{H\in S} v(S)$. Then it is satisfied 
%	\[
%	|\Omega^{\times}_n|= \frac{(n)_l}{\prod_{i=1}^k |Aut(H_i,\rho^i)|^{b_i}}.
%	\]
%	Using the definition of $(U_1,\dots, U_k) \subset G_n$ and
%	substituting $|\Omega^{\times}_n|$ we get
%	\[
%	\Ln |\Omega^{\times}_n|\cdot \mathrm{Pr}\big(
%	(U_1,\dots, U_k) \subset G_n
%	\big) = \Ln
%	\frac{(n)_l}{\prod_{i=1}^k |Aut(H_i,\rho^i)|^{b_i}}\cdot
%	\PR{\bigwedge_{i=1}^k \bigwedge_{(H,\rho)\in U_i} 
%	(H,\rho)\subset (G_n, \chi_n^i)}.
%	\]
%	But the event $(H,\rho)\subset (G_n, \chi_n^i)$ is equivalent to $H\subset G_n$ and
%	$\chi_n^i(v)=\rho(v)$ for all $v\in V(H)$. Thus the LHS of last equation equals
%	\[
%	\Ln
%	\frac{(n)_l}{\prod_{i=1}^k |Aut(H_i,\rho^i)|^{b_i}}\cdot
%	\Pr\Big(\bigwedge_{i=1}^k \bigwedge_{(H,\rho)\in U_i} 
%	\big(H\subset G_n \bigwedge_{v\in V(H)} \chi_n^i(v)=\rho(v) \big) \Big).
%	\]
%	For each $n\in \N$ let $A_n$ the event
%	\[
%	A_n:=\bigwedge_{i=1}^k \bigwedge_{(H,\rho)\in U_i} 
%	H\subset G_n.
%	\]	
%	Then,
%	\begin{align*}
%	&\Pr\Big(\bigwedge_{i=1}^k \bigwedge_{(H,\rho)\in U_i} 
%	\big(H\subset G_n \bigwedge_{v\in V(H)} \chi_n^i(v)=\rho(v) \big) \Big)=\\
%	&\Pr\big(A_n\big)\cdot \Pr\big(\bigwedge_{i=1}^k \bigwedge_{(H,\rho)\in U_i} 
%	\bigwedge_{v\in V(H)} \chi^i_n(v)=\rho(v) \, \big| \, A \big).
%	\end{align*}
%	It holds that
%	\[
%	\PR{A_n}=\frac{1}{n^l} \prod_{i=1}^{k}\prod_{R\in \sigma} \beta_R^{e_R(H_i)\cdot b_i},
%	\]
%	and in consequence 
%	\[
%	\Ln \frac{(n)_l}{\prod_{i=1}^k |Aut(H_i,\rho^i)|^{b_i}}\cdot \PR{A_n}
%	= \frac{\prod_{i=1}^{k}\prod_{R\in \sigma} \beta_R^{e_R(H_i)\cdot b_i}}
%	{\prod_{i=1}^k |Aut(H_i,\rho^i)|^{b_i}}.
%	\]
%	Finally, using the hypothesis that 
%	$(\chi^1_n)_{n\in\N}, \dots, (\chi^k_n)_{n\in\N}$
%	are $\mathcal{F}$-independent we obtain
%	\[
%	\Ln \Pr\big(\bigwedge_{i=1}^k \bigwedge_{(H,\rho)\in U_i} 
%	\bigwedge_{v\in V(H)} \chi^i_n(v)=\rho(v) \, \big| \, A \big)
%	= \prod_{i=1}^{k} \prod_{v\in V(H_i)} \Pr\big[ \chi^i=\rho^i(v)\big]^{b_i}.
%	\]
%	The result follows from joining equations. 
%\end{proof}
%
%\begin{definition}
%	Let $\Sigma$ be a set containing the empty label $\emptyset$.
%	Let $V\subset [n]$. We say that a random $\Sigma$-coloring $\chi$
%	of $G_n$ is $V$-symmetric if $\chi(v)=\emptyset$ if and only if $v\in V$ and
%	for any $s\in \Sigma$ the probability $\Pr(\chi(v)=s)$ is the same for all 
%	$v\in [n]\setminus V$. \par
%	Let $V\subset \N$ be a finite set of vertices and let $(\chi^n)_{n\in \N}$
%	be a succession such that each $\chi^n$ is a random coloring of $G_n$. We
%	call the succession $(\chi^n)_{n\in \N}$ $V$-regular if each $\chi^n$ is
%	$V$-symmetric and for all $s\in \Sigma$ and $v\in \N \setminus \N$ the limit 
%	$\Ln \PR{\chi^n(v)=s}$ exists. 
%\end{definition}
%
%\begin{definition}
%	Let $\Sigma$ be a set containing the empty label $\emptyset$. A rooted $\Sigma$-edge
%	is a $\Sigma$-hypergraph $(e,\chi)$ where $e$ is an edge 
%	(i.e., an hypergraph consisting of only one edge), and there is a unique vertex
%	$v\in V(e)$ such that $\chi(v)=\emptyset$.
%	Given a rooted $\Sigma$-edge $(e,\chi)$, a set of vertices $V$ and a vertex $v\in \N$
%	we define the set $Copies((e,\chi),(V,v))$ as the set of copies 
%	$(e^\prime, \chi^\prime) \in  Copies((e,\chi),V)$ such that $v$ is
%	the root of $(e^\prime,\chi^\prime)$.
%\end{definition}
%
%\begin{definition} 
%	Let $V\subset \N$ be a finite set of vertices. 
%	Let $\Sigma_1,\dots, \Sigma_k$ be sets containing the empty label 
%	$\emptyset$. For each $i\in [k]$ and each $n\in \N$
%	let $\chi_i^n$ be a random $\Sigma_i$-coloring
%	of $G_n$ satisfying that the succession $(\chi_i^n)_{n\in \N}$ is
%	$V$-regular. We say that the sequences $(\chi_1^n)_{n\in \N},
%	\dots, (\chi_k^n)_{n\in \N}$ are asymptotically independent
%	with respect to edges intersecting $V$ if for any given
%	\begin{itemize}
%		\item fixed finite set of edges $S\subset E(\N)$ such that any edge $e\in S$ 
%		contains some vertex in $V$,
%		\item fixed disjoint sets of vertices $V_1,\dots, V_k \subset \bigcup_{e\in S}e$ 
%		satisfying $V\cup V_i=\emptyset$ for all $i\in [k]$, and
%		\item for each $i\in [k]$ and $v\in V_i$ a fixed label $s(v)\in \Sigma_i$
%		different from the empty label,
%	\end{itemize}
%	it is satisfied 
%	\[
%	\Ln \mathrm{Pr}\big(
%	\bigwedge_{i=1}^k \bigwedge_{v\in V_i} \chi_{n,i}(v)=s(v)
%	\, \big| \, \bigwedge_{e\in S} e\subset G_n \,
%	\big) = \prod_{i=1}^k \prod_{v\in V_i} \mathrm{Pr}\big[\chi_i=s(v)
%	\big]		
%	\]
%\end{definition}
%
%
%\begin{theorem}
%	\begin{theorem}
%		Let $k\in \N$.	For each $i\in [k]$ 
%		\begin{itemize}
%			\item Let $v_i\in \N$ be a vertex. Define $V:=\{v_1,\dots,v_k\}$.
%			\item Let $\Sigma_i$ be a set containing the empty label, and let $S_i$ be a set
%			of non-isomorphic rooted $\Sigma_i$-edges. 
%			\item For each $n\in \N$ let $\chi^i_n$ be random $\Sigma_i$-coloring
%			$G_n$ satisfying that the succession $(\chi^i_n)_{n\in \N}$ is $V$-regular. 
%			\item For each $(e,\rho)\in S_i$, let $X^{(e,\rho)}_{n,i}$ be the random 
%			variable that counts the number of copies in $Copies((e,\rho),([n],v_i))$
%			that appear in $(G_n,\chi^i_n)$.				
%		\end{itemize}
%		Suppose that the
%		successions $(\chi^1_n)_{n\in\N}, \dots, (\chi^k_n)_{n\in\N}$
%		are independent with respect to edges intersecting $V$.
%		Then, for any fixed natural numbers 
%		$(a^{(e,\rho)}_{i})_{i\in [k], (e,\rho)\in S_i}$ it holds
%		\[
%		\Ln \mathrm{Pr}\big( \bigwedge_{i=1}^k \bigwedge_{(e,\rho)\in S_i}
%		 X_{n,i}=a^{(e,\rho)}_i  \big)=
%		\prod_{i=1}^{k}e^{-\lambda_i}\frac{\lambda_{(e,\rho)}^{a^{(e,\rho)}_i}}{{a^{(e,\rho)}_i}!},
%		\]
%		where for each $i\in [k]$,
%		\[
%		\lambda_{(e,\rho)}:= \frac{1}{|Aut(e,\rho)|} 
%		\prod_{v\in V(e), \rho(v)\neq \emptyset}
%		\mathrm{Pr}\big[\chi^i=\rho^i(v)\big].
%		\]
%	\end{theorem}
%\end{theorem}
%	








\subsection{Probabilities of trees}

During this section we want to study
the asymptotic probability that the 
$r$-neighborhood of a given vertex $v\in \N$
in $G_n$ 
is a tree that belongs to a given $k$-equivalence
class of trees $\mathcal{T}$ with radius at most
$r$. That is, we want to know
\[\Ln \mathrm{Pr}\big( 
T:=N^{G_n}(v;r) \text{ is a tree, and } (T,v)\in \mathcal{T} \big). 
\]

Denote this limit by $\mathrm{Pr}[r,\mathcal{T}]$. Notice that the 
definition of  $\mathrm{Pr}[r,\mathcal{T}]$ does not depend by the
choice of $v$.\par

We define $\Lambda$ and $M$ as the minimal families
of expressions with arguments $\overline{\beta}$ that satisfy
 the conditions: \textbf{(1)} $1\in \Lambda$, \textbf{(2)} 
for any $b,i\in \N$ with $1\leq i \leq c$,
$b > 0$, and $\lambda_1,\dots, \lambda_{a_i-1}\in \Lambda$,
the expression $(\beta_i/b) \prod_{j=1}^{a_i-1}\lambda_j$
belongs to $M$,  \textbf{(3)}
for any $\mu\in M$ and any $n\in \N$ both
$\mathrm{Poiss}_{\mu}(n)$ and $\mathrm{Poiss}_\mu(\geq n)$ are in $\Lambda$, 
and  \textbf{(4)} for any $\lambda_1,\lambda_2 \in \Lambda$, the
product $\lambda_1\lambda_2$ belongs to $\Lambda$ as well.
\par
The goal of this section is to show 
that $\mathrm{Pr}[r,\mathcal{T}]$,
as an expression with parameters
$\overline{\beta}$, belongs to $\Lambda$ for any choice of 
$r$ and $\mathcal{T}$. \par

\begin{lemma}
	Let $\overline{v} \subset \N*$ be a finite set of fixed vertices and let 
	$\sigma(\overline{x})$ be an open formula with no equality such that
	$length(\overline{x})=length(\overline{v})$. 
	Define $G_n^\prime=G_n \setminus E(\overline{v})$. Fix $R\in \N$. 
	\begin{itemize}
		\item Let $A_n$ be the event that $G^\prime_n$ contains a path of size
		at most	$R+1$ between any two vertices $u,w\in \overline{v}$.
		\item Let $B_n$ be the event
		that $G^\prime_n$ contains a cycle of size at most $R+1$ 
		that contains a vertex $u\in \overline{v}$.
	\end{itemize}
	Then $\Ln \mathrm{Pr}(A_n \, | \, \sigma(\overline{v}))=0$, and 
	$\Ln \mathrm{Pr}(B_n \, | \, \sigma(\overline{v})=0$. 
\end{lemma}
\begin{proof}
	Notice that the events $A_n$ and $B_n$ do not concern the possible edges
	induced over $\overline{v}$. In consequence, because edges are independent
	in our random model, 
	$\mathrm{Pr}(A_n \, | \, \sigma(\overline{v}))
	=\mathrm{Pr}(A_n)$ and 
	$\mathrm{Pr}(B_n \, | \, \sigma(\overline{v}))
	=\mathrm{Pr}(B_n)$.\par
	The facts that $\Ln \mathrm{Pr}(A_n)=0$ and 
	$\Ln \mathrm{Pr}(B_n)=0$ follow
	from \cref{lem:nocopiesfixed} using that 
	(1) the excess of any path is greater or equal than $-1$,
	(2) the amount of paths of size at most $R+1$ is finite,
	(3) the excess of any cycle is zero, and (4) the
	amount of cycles of size at most $R+1$ is finite. 
\end{proof}

\begin{definition}
	We call an hypergraph $G$ \textbf{saturated} if any proper 
	sub-hypergraph $G^\prime \subset H$ satisfies $ex(G^\prime)<ex(G)$. \par
	The \textbf{center} of a connected hypergraph $G$ is its maximal saturated
	sub-hypergraph and it is denoted by $Center(G)$. In the general case 
	the center of an hypergraph is the union of the
	centers of its connected components. 
\end{definition}

\begin{definition}
	Let $G$ be a connected hypergraph and let $\overline{v}\in V(G)^*$.
	Then we call $Center(G, \overline{v})$ to the minimal connected hypergraph
	that contains $Center(G)$ and the vertices $\overline{v}$. In general, if 
	$G$ is an arbitrary hypergraph with connected components $G^1, \dots, G_k$,
	and $\overline{v}$ are vertices $V(G)$, then we call 
	$Center(G, \overline{v})$ to the union of $Center(G_i, V(G_i)\cap
	\overline{v})$ for all the connected components $G_i$.
\end{definition}


\begin{definition}
	Let $G$ be an hypergraph $G$, let $\overline{u}\in V(G)^*$
	and let $v\in \overline{u}$.
	Consider the graph $G^\prime= G\setminus 
	E\big(Center(G,\overline{u})\big)$. Then the connected components of
	$G^\prime$ are all trees. We call the \textbf{tree of $v$ in
	$G(\overline{u})$}, denoted by $Tr\big(G(\overline{u}),v\big)$,
	to the connected component of $G^\prime$ to which $v$ belongs
	with $v$ as its root. \par   
	In this same situation, let $r\in \N$ and $H:=N^G(\overline{u};r)$.
	We call the \textbf{$r$-tree of $v$ in $G(\overline{u})$}, 
	denoted by $Tr\big(G(\overline{u}),v;r\big)$ to 
	$Tr\big(H(\overline{u}),v\big)$.
\end{definition}

\newpage




\begin{theorem} \label{thm:BigTrees}
	Fix $r\in \N$. The following are satisfied:
	\begin{itemize}
		\item[(1)] Let $\mathcal{T}$ be a
		$k$-equivalence class for trees with radii at most $r$.
		Then $\mathrm{Pr}[r,\mathcal{T}]$ exists and is an expression
		in $\Lambda$.
		\item[(2)] Let $\overline{u}\in (\N)_*$ be a list of different fixed 
		vertices, and let $\phi[\overline{x}]\in FO[\sigma]$ be a consistent
		edge sentence such that 
		$len(\overline{x})=len(\overline{u})$.
		Let $\overline{v}\in (\N)_*$ be vertices contained
		in $\overline{u}$. For each $v\in \overline{v}$
		let $\mathcal{T}_v$ be a $k$-equivalence class
		of trees with radii	at most $r$. Then
		\[
		\Ln \mathrm{Pr}\big( \bigwedge_{v\in \overline{v}} 
		Tr\big(G_n, \overline{u},v;r\big)\in \mathcal{T}_v 
		\, | \, \sigma(\overline{w})
		\big)= \prod_{v\in \overline{v}} \mathrm{Pr}[r,\mathcal{T}_v]. \]	 	
	\end{itemize}
\end{theorem}
	\begin{proof}
		We will prove (1) and (2) together by induction on $r$. \par
		Assume $r=0$. We start by showing that (1) holds. Recall that
		all trees with radius zero are $k$-equivalent. Thus, if
		$\mathcal{T}$ is the unique $k$-equivalence class of trees
		with radius zero
		and $v\in \N$ is a fixed vertex then
		 \[
		 \mathrm{Pr}[0;\mathcal{T}] = \Ln \mathrm{Pr}\big( 
		 T:=N^{G_n}(v;0) \text{ is a tree, and } (T,v)\in \mathcal{T} \big)
		 =1, 
		 \]
		Indeed, $N^{G_n}(v;0)$ consists of a single vertex for all $n\geq v$,
		and the above equation follows. The expression $1$ belongs to 
		$\Lambda$, so (1) holds. \par
		The case of (2) is analogous. As $r=0$, then $\mathcal{T}_1=\dots=
		\mathcal{T}_k$ are the unique $k$-equivalence class of trees with
		radius zero. Then, given $\sigma, \overline{u}, v_1,\dots, v_k$ as
		in the statement,
		\[\Ln \mathrm{Pr}\big( \bigwedge_{i=1}^l
		Tr\big(G_n, \overline{u},v_i;0\big)\in \mathcal{T}_i \, | \, \sigma(\overline{w})
		\big)= \prod_{i=1}^l \mathrm{Pr}[0,\mathcal{T}_i]=1. \]	 	
		Because of (1), $\mathrm{Pr}[0,\mathcal{T}_i]=1$ for all $i$'s, 
		and (2) holds. \par
		Now let $r>0$ and assume that both (1) and (2) hold for all 

		Via similar computations we can show that for any fixed
		$v\in \overline{v}$.
		
		We are going to show that the variables $X_{n,i,\epsilon}$ converge, as
		$n$ tends to infinity, to independent Poisson variables 
		$\mathrm{Poiss}(\mu_{r_i,\epsilon})$ whose means $\mu_{r_i,\epsilon}$ 
		are expressions in the family $M$. Let $[\Sigma_{r_i}]$ be the set of
		$\Sigma_{r_i}$-patterns. We want to prove: 
		\begin{equation} \label{eqn:PoissonEdges}
		\Ln \mathrm{Pr}\Big(
		\bigwedge_{i=1}^k \bigwedge_{\epsilon \in [\Sigma_{r_i}]} X_{n,i,\epsilon}=a_{i,\epsilon}
		\, | \, \sigma(\overline{w})\Big) =
		\prod_{i=1}^k \prod_{\epsilon \in [\Sigma_{r_i}]} e^{-\mu_{r_i,\epsilon}}
		\frac{(\mu_{r_i,\epsilon})^{a_{i,\epsilon}}}{a_{i,\epsilon}!}
		\end{equation}
		Furthermore, for each $i$ and $\epsilon$ we will prove that the mean 
		$\mu_{r_i,\epsilon}$ does only depend on $r_i$ and $\epsilon$.
		This proves both (1), and (2).\par
		Given an $\Sigma_{r_i}$-pattern $\epsilon$ and any 
		$(e,\chi)\in Copies(\epsilon,[n])$ we say that $(e,\chi)\in T_{n,i}$
		if the following are satisfied: (1)	$e$ is an initial edge of $T_{n,i}$,
		and	(2) that for any $v\in e$ such that $v\neq v_i$, it holds that
		$\chi(v)$ is the $\simeq_k$ class of $Tr(T_{n,i},v)$.\par 
		Given $r\in \N$ and $\epsilon\in \Sigma_{r}$
		we define
		$\mu_{r,\epsilon}$ as follows. Let $(e,\chi)$ be any representative of
		$\epsilon$. Then
		\[\mu_{r,\epsilon}=  \frac{\beta_{R(e)}}{|Aut(e,\chi)|}
		\prod_{\substack{v\in e\\ \chi(v)\neq \tau }} \Pr[r,\chi(v)]. \]
		For each $i\in [l]$ and $\epsilon\in [\Sigma_{r_i}]$ let 		
		$b_{i,\epsilon}\in \N$ be fixed. 
	
		We want to prove
		\[
		\Ln \mathrm{E}\left[\prod_{\substack{i\in [l]\\ \epsilon \in [\Sigma_{r_i}]}} \binom{X_{n,i,\epsilon}}{b_{i,\epsilon}}
		\right]= \prod_{\substack{i\in [l]\\ \epsilon \in [\Sigma_{r_i}]}}
		\frac{(\mu_{r_i,\epsilon})^{b_{i,\epsilon}}}{b_{i,\epsilon}!}.
		\]
		Because \cref{thm:BrunSieve} this is sufficient to prove \cref{eqn:PoissonEdges}. \par
		For each $n\in \N$ define
		\begin{align*}
		\Omega_n=&\Bigg\{
		(E_{v,\epsilon})_{\substack{v\in \overline{v}\\ \epsilon
		\in [\Sigma_{r(v)}]}} \quad \Big|\\ 
		&  \forall v\in \overline{v},
		\forall \epsilon \in [\Sigma_{r(v)}]\, \quad  E_{v,\epsilon}\subset
		Copies(\epsilon,[n],\overline{w};v)\quad  \wedge \quad |E_{v,\epsilon}|=b_{v,\epsilon}\Bigg\}.
		\end{align*}
		Informally, the elements $(E_{v,\epsilon})_{v,\epsilon}$
		of $\Omega_n$ are represent all choices of
		possible initial edges for the $T_{n,v}$'s: For each $v\in \overline{v}$
		and each $\epsilon\in [\Sigma_{r(v)}]$, $E_{n,v,\epsilon}$ selects
		$b_{v,\epsilon}$ possible initial edges of $T_{n,v}$
		with pattern $\epsilon$.\par
%	 	Given an element $O\in \Omega_n$, with
%	 	$O=\big(O_{i,\epsilon}\big)_{i\in [l], \epsilon \in [\Sigma_{r_i}]}$,
%	 	we write $O\in G_n$ if
		Using observation REF we obtain that
		\[
		\mathrm{E}\Big[\prod_{\substack{i\in [l]\\ \epsilon \in [\Sigma_{r_i}]}} \binom{X_{n,i,\epsilon}}{b_{i,\epsilon}}
		\Big]= \sum_{(E_{v,\epsilon})_{v,\epsilon} \in \Omega_n
		}		
		\Pr \left( \bigwedge_{\substack{v\in \overline{v} \\ \epsilon \in
		[\Sigma_{r(v)}]\\ (e,\chi) \in E_{v,\epsilon} }} \left( e\in E(T_{n,i}) 
		\bigwedge_{u\in V(e), u\neq v} Tr(T_{n,v};u)\in \chi(u)
		\right)  \right)
		\]
		Let $(E_{v,\epsilon})_{v,\epsilon}\in \Omega_n$. 
		In order for $e\in E(T_{n,v})$ to be possible for all
		$v\in \overline{v}$, $\epsilon\in [\Sigma_{r(v)}]$, 
		$e\in E_{v,\epsilon}$ it is needed that each vertex 
		in $[n]\setminus \overline{w}$ belongs at most to one
		edge $(e,\chi)\in \cup_{v,\epsilon} \, E_{v,\epsilon}$.
		This is because if for some 
		\[
		\bigwedge_{\substack{i\in [l]\\ \epsilon \in
		[\Sigma_{r_i}]\\ (e,\chi) \in O_{i,\epsilon} }} \left( e\in E(T_{n,i}) 
		\bigwedge_{v\in e, v\neq v_i} Tr(T_{n,i},v)\in \chi(v)
		\right) 
		\] 
		to be possible it is needed that each $v\in $
	\end{proof}
	
	\newpage
	\begin{lemma}
	Let $r\in \N$, $r>0$. Let $\mathcal{T}$ be a 
	$\simeq_k$ class of trees with radii at most $r$.
	Suppose that \cref{thm:BigTrees} holds
	for $r-1$. Then $\Pr\big[r, \mathcal{T}\big]$ 
	exists and is and expression in $\Lambda$.   
	\end{lemma}
	\begin{proof}
		Fix a vertex $v\in \N$. For each $n$ let
		$T_n:=Tr(G_n,v;r)$. We are going to show that
		$\Ln \PR{T_n\in \mathcal{T}}$ exists and it is an 
		expression in $\Lambda$. \par
		For any $(k,r)$-pattern  $\epsilon$  let 
		$X_{n,\epsilon}$ be the random variable that counts
		the initial edges in $T_n$ whose $k$-pattern
		is $\epsilon$. In other words, $X_{n,\epsilon}$ counts
		the colored edges $(e,\tau)\in Copies(\epsilon,[n],v)$ 
		such that $e$ is an initial edge in $T_n$ satisfying that
		for any $u\in V(e)$ with $u\neq v$, it holds
		$Tr(T_n(v),u)\in \tau(u)$. Thus,
		\[
		\mathrm{E}\big[ X_{n,\epsilon} \big]
		= \sum_{(e,\tau)\in Copies(\epsilon,[n];v)} \Pr
		\left(e\in E(T_n)
		\bigwedge_{\substack{u\in V(e)\\ u\neq v} } Tr(T_{n}, v; u)\in 
		\tau(u) \right).
		\]
		Because of the symmetry of our random model the probability 
		in the RHS of last equation is the same for all 
		$(e,\tau)\in Copies(\epsilon,[n],;v)$. Let
		$(e,\tau)\in Copies(\epsilon,\N;v)$ be fixed. 
		Using that 
		$|Copies(\epsilon,[n],v)|=\frac{(n)_{|e|-1}}
		{|Aut(\epsilon)|}$ we obtain
		\[
		\mathrm{E}\big[ X_{n,\epsilon} \big]
		=
		\frac{(n)_{|e|-1}}{|
			Aut(\epsilon)|} \Pr
		\left(e\in E(T_{n})
		\bigwedge_{\substack{u\in V(e)\\ u\neq v} } Tr(T_n, v; u)\in \tau(u) \right).
		\]
		Also, it is satisfied
		\begin{align*}
		&\Pr
		\left( e\in E(T_{n})
		\bigwedge_{\substack{u\in V(e)\\ u\neq v} } Tr(T_n, v; u)\in 
		\tau(u) \right)=\\
		&\PR{ e\in E(G_n)} \cdot
		\Pr
		\left( e\in E(T_{n})
		\bigwedge_{\substack{u\in V(e)\\ u\neq v} } Tr(T_{n}, v; u)\in \tau(u) \, \Bigg| \,  e\in E(G_n) \right)
		\end{align*}
		Using REF and $\PR{e\in E(G_n)}=\frac{\beta_{R(e)}}{n^{|e|-1}}$, 
		the RHS of last equation is asymptotically equivalent
		to
		\[
		\frac{\beta_{R(e)}}{n^{|e|-1}} \cdot
		\Pr	\left(
		\bigwedge_{\substack{u\in V(e)\\ u\neq v} } Tr(T_{n}, v; u)\in \tau(u) \, \Bigg| \,  e\in E(G_n) \right)
		\]
		Fix $\overline{u}\in (\N)_*$ a list that contains exactly the vertices
		in $e$. Then it holds that
		$Tr(T_{n}, v, u)=Tr(G_n(\overline{u}),u;r-1)$. 
		Thus,
		\[
		\Pr	\left(
		\bigwedge_{\substack{u\in V(e)\\ u\neq v} } Tr(T_{n}, v; u)\in \tau(u) 
		\, \Bigg| \,  e\in E(G_n) \right)
		=
		\Pr \left(
		\bigwedge_{\substack{u\in V(e)\\ u\neq v} } Tr(G_n(\overline{u}), u;
		r-1)\in \tau(u) \, \Bigg| \,  e\in E(G_n) \right)
		\]		
		The event $e\in E(G_n)$ can be written as an edge sentence
		whose variables are interpreted as vertices in $\overline{u}$.
		Thus, by hypothesis, the RHS of last equality
		is asymptotically equivalent to
		$\prod_{\substack{u\in V(e)\\ u\neq v} } \Pr\big[
		r-1, \tau(u)\big]$.
		Finally, joining everything we obtain
		\[
		\Ln
		\mathrm{E}\big[ X_{n,\epsilon} \big]
		= \Ln \frac{(n)_{|e|-1}}{|Aut(\epsilon)|}
		\cdot  \frac{\beta_{R(e)}}{n^{|e|-1}}
		\prod_{\substack{u\in V(e)\\ u\neq v} }
		\Pr\big[
		r-1, \tau(u)\big] =
		\frac{\beta_{R(e)}}{|Aut(\epsilon)|} 
		\prod_{\substack{u\in V(e)\\ u\neq v} } \Pr\big[
		r-1, \tau(u)\big].
		\]
		For each $\epsilon\in [(k,r)]$ we define $\mu_{r,\epsilon}$ 
		as follows: let $(e,\tau)$ be a representative of $\epsilon$
		whose root is $v$. Then
		\[
		\mu_{r,\epsilon}=\frac{\beta_{R(e)}}{|Aut(\epsilon)|} 
		\prod_{\substack{u\in V(e)\\ u\neq v} } \Pr\big[
		r-1, \tau(u)\big].
		\]
		Notice that $\mu_{r,\epsilon}$ depends only on $r$ and $\epsilon$
		and it is an expression belonging to $M$. \par
		We are going to prove that the variables $X_{n,\epsilon}$
		converge in distribution to independent Poisson variables 
		with mean values $\mu_{r,\epsilon}$ respectively. For
		each $\epsilon\in [(k,r)]$ let $b_\epsilon\in \N$. We want 
		to show that
		\begin{equation} \label{eqn:binomexpedges}
		\Ln
		\mathrm{E}
		\left[
		\prod_{\epsilon\in [(k,r)]} \binom{X_{n,\epsilon}}{b_\epsilon}	
		\right]
		= \prod_{\epsilon\in [(k,r)]} \frac{(\mu_{r,\epsilon})^
		{b_\epsilon}}{b_\epsilon!}.	
		\end{equation}
		For each $n\in \N$ define
		\[
		\Omega_n:=\left\{
		(E_\epsilon)_{\epsilon\in [(k,r)]} \quad 
		\Big | \quad \forall \epsilon\in [(k,r)] \quad
		E_\epsilon\subset Copies(\epsilon,[n],v), 
		\quad |E_\epsilon|=b_\epsilon	
		\right\}		
		\]
		Informally, elements of $\Omega_n$ represent choices of 
		$b_\epsilon$ possible initial edges of $T_n$ whose $k$-
		pattern is $\epsilon$ for all $(k,r)$-patterns $\epsilon$. 	
		Using observation REF we obtain
		\[
		\mathrm{E}
		\left[
		\prod_{\epsilon\in [(k,r)]} \binom{X_{n,\epsilon}}{b_\epsilon}	
		\right]
		= 
		\sum_{
		(E_\epsilon)_{\epsilon\in [(k,r)]}
		\in \Omega_n}
		\Pr\left(
		\bigwedge_{\substack{
		\epsilon\in [(k,r)]\\
		(e, \tau)\in E_{\epsilon}
		}} \left(
		e\in E(T_n) \bigwedge_{\substack{
		u\in V(e)\\
		u\neq v}} Tr(T_n,v,u)\in \tau(u)		
		\right)
		\right). 		
		\]
		We say that an element $(E_\epsilon)_{\epsilon\in [(k,r)]}$
		of $\Omega_n$ is \textbf{disjoint} each vertex 
		$w\in [n]\setminus\{v\}$ belongs to at most one edge 
		$(e,\tau)\in\bigcup_{\epsilon\in [(k,r)]} E_\epsilon$
		Notice that if we want the probability in the last sum to be greater 
		than $0$ for a particular $(E_\epsilon)_{\epsilon\in [(k,r)]}
		\in \Omega_n$ then necessarily $(E_\epsilon)_{\epsilon\in [(k,r)]}$
		is disjoint. 
		Indeed, suppose that a vertex $w\in [n]\setminus \{v\}$ belongs to two different 
		edges $(e_1, \tau_1),$ $(e_2,\tau_2)\in \bigcup_{\epsilon\in [(k,r)]} E_\epsilon$. 
		In consequence $e_1$ and $e_2$ form a cycle, as they 
		both contain $v$ and $w$. This implies that $e_1, e_2 \notin E(T_n)$.
		\par
		For each $n\in \N$ let $\Omega_n^\prime\subset \Omega_n$ be the set
		of disjoint elements in $\Omega_n$. Then
		\[
		\mathrm{E}
		\left[
		\prod_{\epsilon\in [(k,r)]} \binom{X_{n,\epsilon}}{b_\epsilon}	
		\right]
		= 
		\sum_{
			(E_\epsilon)_{\epsilon\in [(k,r)]}
			\in \Omega_n^\prime}
		\Pr\left(
		\bigwedge_{\substack{
				\epsilon\in [(k,r)]\\
				(e, \tau)\in E_{\epsilon}
		}} \left(
		e\in E(T_n) \bigwedge_{\substack{
				u\in V(e)\\
				u\neq v}} Tr(T_n,v,u)\in \tau(u)		
		\right)
		\right). 		
		\] 
		Also, because of the symmetry of the random model, 
		for all disjoint elements 
		$(E_\epsilon)_{\epsilon\in [(k,r)]}$ the probability 
		in last sum is the same. In consequence, if we fix
		$(E_\epsilon)_{\epsilon\in [(k,r)]}\in \Omega^\prime_\N$
		we obtain
		\[
		\mathrm{E}
		\left[
		\prod_{\epsilon\in [(k,r)]} \binom{X_{n,\epsilon}}{b_\epsilon}	
		\right]
		= 
		|\Omega_n^\prime|\cdot
		\Pr\left(
		\bigwedge_{\substack{
				\epsilon\in [(k,r)]\\
				(e, \tau)\in E_{\epsilon}
		}} \left(
		e\in E(T_n) \bigwedge_{\substack{
				u\in V(e)\\
				u\neq v}} Tr(T_n,v,u)\in \tau(u)		
		\right)
		\right). 		
		\] 
		Let $\overline{w}\in (\N)_*$ be a list containing exactly
		the vertices $u\in V(e)$ for all $e\in 
		\bigcup_{\epsilon\in [(k,r)]} E_\epsilon$. Then, 
		for any $e\in 
		\bigcup_{\epsilon\in [(k,r)]} E_\epsilon$ and any
		any $V(e)$ with $u\neq v$ it holds that
		if $e\in E(T_n)$ then 
		$Tr(T_n,v,u)=Tr(G_n,\overline{w},u;r-1)$. Then
		\[
		\mathrm{E}
		\left[
		\prod_{\epsilon\in [(k,r)]} \binom{X_{n,\epsilon}}{b_\epsilon}	
		\right]
		= 
		|\Omega_n^\prime|\cdot
		\Pr\left(
		\bigwedge_{\substack{
				\epsilon\in [(k,r)]\\
				(e, \tau)\in E_{\epsilon}
		}} \left(
		e\in E(T_n) \bigwedge_{\substack{
				u\in V(e)\\
				u\neq v}} Tr(G_n,\overline{w},u;r-1)\in \tau(u)		
		\right)
		\right). 		
		\] 
		Counting vertices and automorphisms we get that
		\[
		|\Omega_n^\prime|= (n)_{\sum_{\epsilon\in [(k,r)]} 
			(|\epsilon|-1)\cdot b_\epsilon}
		\prod_{\epsilon\in [(k,r)]}
		\frac{1}{b_\epsilon!} \cdot
		\left( \frac{1}{|Aut(\epsilon)|} \right)^
		{b_\epsilon} .
		\]
		Also, using REF
		\begin{align*}
		&\Pr\left(
		\bigwedge_{\substack{
				\epsilon\in [(k,r)]\\
				(e, \tau)\in E_{\epsilon}
		}} \left(
		e\in E(T_n) \bigwedge_{\substack{
				u\in V(e)\\
				u\neq v}} Tr(G_n,\overline{w},u;r-1)
			\in \tau(u)		
		\right)
		\right)\sim\\
		&\Pr\left(
		\bigwedge_{\substack{
				\epsilon\in [(k,r)]\\
				(e, \tau)\in E_{\epsilon}
		}} e\in E(G_n)
		\right)\cdot 		
		\Pr\left(
		\bigwedge_{\substack{
				\epsilon\in [(k,r)]\\
				(e, \tau)\in E_{\epsilon}\\
				u\in V(e)\\
				u\neq v
		}}Tr(G_n,\overline{w},u;r-1)\in \tau(u)	
		\, \Bigg| \, 
		\bigwedge_{\substack{
		\epsilon\in [(k,r)]\\
		(e, \tau)\in E_{\epsilon}
		}} e\in E(G_n)
		\right).
		\end{align*}
		The event 
		$ \bigwedge_{\substack{
				\epsilon\in [(k,r)]\\
				(e, \tau)\in E_{\epsilon}
		}} e\in E(G_n)$ clearly can be described via an edge sentence
	whose variables are interpreted as vertices in $\overline{w}$. Thus,
	by hypothesis last product of probabilities is asymptotically equivalent
	to
	\[
	\prod_{\epsilon\in [(k,r)]}
	\left(\frac{\beta_{R(\epsilon)}}
	{n^{|\epsilon|-1}}\right)^{b_\epsilon} \cdot
	\prod_{\epsilon\in [(k,r)]} (\lambda_{r,\epsilon})^{b_\epsilon}.
	\]
	Joining everything we obtain 
	\begin{align*} 
	\Ln
	\mathrm{E}
	\left[
	\prod_{\epsilon\in [(k,r)]} \binom{X_{n,\epsilon}}{b_\epsilon}	
	\right]
	= \Ln  
	\frac{(n)_{\sum_{\epsilon\in [(k,r)]}(|\epsilon|-1)\cdot b_\epsilon}}
	{n^{\sum_{\epsilon\in [(k,r)]}(|\epsilon|-1)\cdot b_\epsilon}}
	\cdot
	\prod_{\epsilon\in [(k,r)]}
	\frac{1}{b_\epsilon!} \cdot
	\left( \frac{\beta_{R(\epsilon)}}{|Aut(\epsilon)|} \right)^
	{b_\epsilon} \cdot 
	(\lambda_{r,\epsilon})^{b_\epsilon}&\\
	= \prod_{\epsilon\in [(k,r)]}
	\frac{\left( \mu_{r,\epsilon} \right)^
	{b_\epsilon}}{b_\epsilon!}
	,&
	\end{align*}
	as we wanted. In consequence, by \cref{thm:BrunSieve},
	given $a_{\epsilon}\in \N$ for all $\epsilon\in [(k,r)]$
	it holds
	\[
	\Ln
	\Pr\left( 
	\bigwedge_{\epsilon \in [(k,r)]} X_{n,\epsilon}=a_\epsilon
	\right)=
	\prod_{\epsilon\in [(k,r)]} e^{-\mu_{r,\epsilon}}
	\frac{(\mu_{r,\epsilon})^{a_\epsilon}}{a_\epsilon!}.
	\]
	Notice that, because of the definition of $\simeq_k$, 
	the event $T_n\in \mathcal{T}$ is equivalent to 
	\[
	\left(\bigwedge_{\epsilon \in E^1_\mathcal{T}}
	X_{n,\epsilon}\geq k 
	\right) \wedge \left(\bigwedge_{\epsilon \in E^2_\mathcal{T}}
	X_{n,\epsilon}=a_\epsilon\right),
	\]
	for some partition $E^1_\mathcal{T}, E^2_\mathcal{T}$
	of $[(k,r)]$ that only depends on $\mathcal{T}$ and some
	natural numbers $a_\epsilon < k$ for each $\epsilon\in
	E^2_\mathcal{T}$ that only depend on $\mathcal{T}$ as well. 
	In consequence 
	\[
	\Ln \PR{T_n\in \mathcal{T}}= 
	\left(
	\prod_{\epsilon\in E^1_\mathcal{T}} \left( 1-\sum_{i=0}^{k-1}
	e^{-\mu_{r,\epsilon}}
	\frac{(\mu_{r,\epsilon})^i}{i!} \right)
	\right)\cdot
	\left(
	\prod_{\epsilon\in E^2_\mathcal{T}}
	e^{-\mu_{r,\epsilon}}
	\frac{(\mu_{r,\epsilon})^{a_{\epsilon}}}{a_\epsilon!} 
	\right)
	\]
	And last expression belongs to $\Lambda$ as we wanted to prove. 
 	\end{proof}

		
	\section{Probabilities of cycles}

\begin{theorem}\label{thm:agreeabilityprobabilities}
	Let $\mathcal{O}$ be a simple $k$-agreeability class
	of hypergraphs. Then 
	$\Ln \PR{G_n\in \mathcal{O}}$ exists and is an expression
	in $\Theta$. 
\end{theorem}
\begin{proof}
	Define $r:=3^k$. 
	For each $O\in C(k,r)$ let $X_{n,O}$ be the random variable
	that counts the number of cycles in $Core(G_n;r)$ 
	whose $k$-type is $O$. Fix $O\in C(k,r)$. It holds
	\[
	\mathrm{E}\big[ X_{n,O}\big]
	=\sum_{(H,\tau)\in Copies(0,[n])} \Pr\left(
	H\subset G_n \bigwedge_{v\in V(H)} 
	Tree(G_n, v;r)\in \tau(v)
	\right)	
	\]
	Because of the symmetry of the random model last probability is the 
	same for all $(H,\tau)\in Copies(O,[n])$. Fix $(H,\tau)\in
	Copies(O,\N )$. Then
	\begin{align*}
	\mathrm{E}\big[ X_{n,O}\big]
	&=\frac{(n)_{|V(H)|}}{|Aut(H,\tau)|} 
	\cdot \Pr\left(
	H\subset G_n \bigwedge_{v\in V(H)} 
	Tree(G_n, v;r)\in \tau(v)
	\right)	\\
	&=\frac{(n)_{|V(H)|}}{|Aut(H,\tau)|}\cdot
	\frac{\prod_{R\in \sigma} \beta_R^{|E_R(H)|}}{n^{|V(H)|}}\cdot
	\Pr\left(\bigwedge_{v\in V(H)} 
	Tr(G_n, v;r)\in \tau(v)
	\quad  \Big| \quad H\subset G_n
	\right)\\
	&\sim 
	\frac{\prod_{R\in \sigma} \beta_R^{|E_R(H)|}}
	{|Aut(H,\tau)|}\cdot
	\Pr\left(\bigwedge_{v\in V(H)} 
	Tr(G_n, v;r)\in \tau(v)
	\quad  \Big| \quad H\subset G_n
	\right)
	\end{align*}
	Let $\overline{v}\in (\N)_*$ be a list containing 
	exactly the vertices in $V(H)$. If $H\subset G_n$
	then $Tr(G_n, v;r)=Tr(G_n,\overline{v},v;r)$. Also,
	the event $H\subset G_n$ clearly can be described via
	an edge sentence concerning the vertices in $\overline{v}$.
	In consequence, using \cref{thm:BigTrees}, last expression
	is asymptotically equivalent to
	\[
	\frac{\prod_{R\in \sigma} \beta_R^{|E_R(H)|}}
	{|Aut(H,\tau)|}\cdot
	\prod_{v\in V(H)}
	\Pr \big[ r, \tau(v) \big].
	\]
	For any $O\in C(k,r)$ we define $\lambda_O$ and 
	$\omega_O$ in the following way. Let $(H,\tau)$ be
	a representative of $O$. Then
	\[ 
	\lambda_O:
	=\prod_{v\in V(H)}
	\Pr \big[ r, \tau(v) \big],
	\]
	and
	\[
	\omega_O:=
	\frac{\prod_{R\in \sigma} \beta_R^{|E_R(H)|}}
	{|Aut(H,\tau)|}\cdot\lambda_O.
	\]
	We are going to prove that the variables $X_{n,O}$ converge
	in distribution as $n$ tends to infinity to 
	independent Poisson variables whose respective means are
	the $\omega_O$. For that we are going to use again the factorial 
	moments method. For each $O\in C(k,r)$ fix a number $b_{O}\in\N$.
	We want to prove 
	\[
	\Ln 
	\mathrm{E}\left[
	\prod_{O\in C(k,r)}
	\binom{X_{n,O}}{b_O}
	\right]= \prod_{O\in C(k,r)} 
	\frac{(\omega_O)^{b_O}}{b_O!}.
	\]
	For each $n\in \N$ we define
	\[
	\Omega_n:=\left\{
	(F_O)_{O\in C(k,r)} \quad \Big|
	\quad \forall O\in C(k,r) \quad
	F_O\subset Copies(O,[n]), \quad
	|F_O|=b_O	
	\right\}.
	\]
	We also define $\Omega_\N$ by substituting $[n]$ for $\N$ in
	the definition of $\Omega_n$. Informally, an element of $\Omega_n$ 
	represents a choice of an unordered $b_O$-tuple
	of possible cycles over $[n]$ whose $(k,r)$-type is $O$, for each
	$(k,r)$ type $O$. Using observation REF we obtain
	\[
	\mathrm{E}\left[
	\prod_{O\in C(k,r)}
	\binom{X_{n,O}}{b_O}
	\right]=
	\sum_{(F_O)_{O\in C(k,r)}\in \Omega_n}
	\Pr\left(
	\bigwedge_{
	\substack{
	O\in C(k,r)\\
	(H,\tau)\in F_O
	}}
	\left(
	H\subset G_n
	\bigwedge_{v\in V(H)}
	Tr(G_n,v;r)\in \tau(v)
	\right)
	\right).
	\]
	Consider the subset $\Omega_n^\prime\subset \Omega_n$ that contains
	the elements $(F_O)_{O\in C(k,r)}\in \Omega_n$ such that there exists
	some vertex $v\in [n]$ contained in two graphs
	$(H_1,\tau_1),(H_2,\tau_2)\in \bigcup_{O\in C(k,r)} F_O$. We want to argue 
	that
	\begin{equation}\label{eqn:denseconfigurations}
	\Ln
	\sum_{(F_O)_{O\in C(k,r)}\in \Omega_n^\prime}
	\Pr\left(
	\bigwedge_{
		\substack{
			O\in C(k,r)\\
			(H,\tau)\in F_O
	}}
	\left(
	H\subset G_n
	\bigwedge_{v\in V(H)}
	Tr(G_n,v;r)\in \tau(v)
	\right)
	\right)=0.
	\end{equation}
	Given an element $(F_O)_{O\in C(k,r)}\in \Omega_n$ we 
	define the hypergraph $G\Big((F_O)_{O\in C(k,r)}\Big)$ as
	follows:
	\[
	G\Big((F_O)_{O\in C(k,r)}\Big):=
	\bigcup_{H\in F} H, 
	\]
	where
	\[
	F:=\left\{
	H \quad \Big| \quad 
	(H,\tau)\in \bigcup_{O\in C(k,r)} F_O	
	\right\}.
	\]
	That is, $G\Big((F_O)_{O\in C(k,r)}\Big)$
	is the union of all hypergraphs chosen in 
	$(F_O)_{O\in C(k,r)}$. Then, for all 
	$(F_O)_{O\in C(k,r)}\in \Omega_n$ it is 
	satisfied
	\begin{align*}
	&\Pr\left(
	\bigwedge_{
		\substack{
			O\in C(k,r)\\
			(H,\tau)\in F_O
	}}
	\left(
	H\subset G_n
	\bigwedge_{v\in V(H)}
	Tr(G_n,v;r)\in \tau(v)
	\right)
	\right)
	\leq 
	\Pr\left(
	\bigwedge_{
		\substack{
			O\in C(k,r)\\
			(H,\tau)\in F_O
	}}
	H\subset G_n
	\right) =
	\\&
	\Pr \left(
	G\Big((F_O)_{O\in C(k,r)}\Big) \subset G_n
	\right).
	\end{align*}
	Let 
	\[
	t = \sum_{O\in C(k,r)} |V(O)|\cdot b_O.
	\]
	Then $V\Big(
	G\Big((F_O)_{O\in C(k,r)}\Big)
	\Big) \leq t$
	for any $(F_O)_{O\in C(k,r)}\in \Omega_n$.\par
	Consider the following facts
	\begin{itemize}
		\item[(1)] If $(F_O)_{O\in C(k,r)}\in \Omega_n^\prime$ then
		$G\big((F_O)_{O\in C(k,r)}\big)$ is dense.
		 
		\item[(2)] Given an hypergraph $H$ with $V(H)\subset \N$,
		the number of elements  $(F_O)_{O\in C(k,r)}\in \Omega_\N^\prime$
		such that $H=G\big((F_O)_{O\in C(k,r)}\big)$ is finite and it is 
		the same for all $H^\prime \simeq H$ with $V(H^\prime) \subset \N$.
		
		\item[(3)] There is a finite amount of unlabeled dense
		hypergraphs with size bounded by $t$.
	\end{itemize}
	Then it follows that
	\begin{align*}
	\sum_{(F_O)_{O\in C(k,r)}\in \Omega^\prime_n}
	\Pr \Big(
	G\Big(&(F_O)_{O\in C(k,r)}\Big) \subset G_n
	 \Big) \\
	& = 
	\mathrm{O} \left(
	\mathrm{E}\left[
	\# \text{ of dense subgraphs in $G_n$ with size bounded by
	 $t$}\right] \right).	
	\end{align*}
	And this, together with \cref{lem:nocopiesdense} proves
	\cref{eqn:denseconfigurations}.\par
	For all $n$ define $\Omega_n^{\prime\prime}=
	\Omega_n\setminus \Omega_n^\prime$. That is, 
	$\Omega_n^{\prime\prime}$ contains the elements
	$(F_O)_{O\in C(k,r)}$ in $\Omega_n$ such that all vertices
	$v\in [n]$ belong to at most one hypergraph
	$(H,\tau)\in \bigcup_{O\in C(k,r)} F_O$. We also
	define $\Omega_\N^{\prime\prime}$. Because of 
	\cref{eqn:denseconfigurations} we have
	\[
	\mathrm{E}\left[
	\prod_{O\in C(k,r)}
	\binom{X_{n,O}}{b_O}
	\right]=
	\sum_{(F_O)_{O\in C(k,r)}\in \Omega_n^{\prime\prime}}
	\Pr\left(
	\bigwedge_{
	\substack{
		O\in C(k,r)\\
		(H,\tau)\in F_O
	}}
	\left(
	H\subset G_n
	\bigwedge_{v\in V(H)}
	Tr(G_n,v;r)\in \tau(v)
	\right)
	\right)+o(1).
	\]
	
	Because of the symmetry of the model the probability inside of last sum 
	is the same for all elements $(F_O)_{O\in C(k,r)}\in \Omega_n^{\prime\prime}$.
	Also, counting all different vertices and automorphisms we obtain that
	\[
	|\Omega_n^{\prime\prime}|=
	\frac{(n)_{\sum_{O\in C(k,r)} |V(O)|\cdot b_O}}
	{\prod_{O\in C(k,r)} b_O!\cdot |Aut(O)|^{b_O}}.
	\]
	Fix $(F_O)_{O\in C(k,r)}\in \Omega_\N^{\prime\prime}$. Then 
	\begin{align*}
	&\Ln \mathrm{E}\left[
	\prod_{O\in C(k,r)}
	\binom{X_{n,O}}{b_O}
	\right]=\\
	&
	\Ln
	\frac{(n)_{\sum_{O\in C(k,r)} |V(O)|\cdot b_O}}
	{\prod_{O\in C(k,r)} b_O!\cdot |Aut(O)|^{b_O}} \cdot
	\Pr\left(
	\bigwedge_{
		\substack{
			O\in C(k,r)\\
			(H,\tau)\in F_O
	}}
	\left(
	H\subset G_n
	\bigwedge_{v\in V(H)}
	Tr(G_n,v;r)\in \tau(v)
	\right)
	\right).
	\end{align*}
	It holds that the probability in last expression equals
	\[
	\prod_{O\in C(k,r)}
	\left( 
	\frac{\prod_{R\in \sigma} \beta_R^{|E_R(O)|}}{n^{|V(O)|}}
	\right)^{b_O} \cdot
	\Pr\left(
	\bigwedge_{
		\substack{
			O\in C(k,r)\\
			(H,\tau)\in F_O\\
			v\in V(H)
	}}
	Tr(G_n,v;r)\in \tau(v) \,
	\Bigg|  \,
	\bigwedge_{
		\substack{
			O\in C(k,r)\\
			(H,\tau)\in F_O\\
		}}
	H\subset G_n
	\right).
	\]
	Let $\overline{v}\in (\N)_*$ be 
	a list that contains exactly the vertices in $G\big(
	(F_O)_{O\in C(k,r)}	\big)$. Then the event
	\[
	A_n:=
		\bigwedge_{
		\substack{
			O\in C(k,r)\\
			(H,\tau)\in F_O\\
	}}
	H\subset G_n
	\]
	can be written as an edge sentence concerning the vertices in $\overline{w}$.
	Also, if $A_n$ holds then all vertices in $\overline{w}$ belong to 
	$Core(G_n;r)$. Thus, for all $v\in \overline{v}$,
	$Tr(G_n,v;r)=Tr(G_n,\overline{w};r)$ and using \cref{thm:BigTrees}
	we obtain
	\[
	\Pr\left(
	\bigwedge_{
		\substack{
			O\in C(k,r)\\
			(H,\tau)\in F_O\\
			v\in V(H)
	}}
	Tr(G_n,v;r)\in \tau(v) \,
	\Bigg|  \,
	\bigwedge_{
		\substack{
			O\in C(k,r)\\
			(H,\tau)\in F_O\\
	}}
	H\subset G_n
	\right) \sim
	\prod_{O\in C(k,r)} (\lambda_O)^{b_O}.	
	\]
	Joining everything together we obtain
	\begin{align*}
&\Ln \mathrm{E}\left[
\prod_{O\in C(k,r)}
\binom{X_{n,O}}{b_O}
\right]=\\
&
\Ln
\frac{(n)_{\sum_{O\in C(k,r)} |V(O)|\cdot b_O}}
{\prod_{O\in C(k,r)} b_O!\cdot |Aut(O)|^{b_O}} \cdot
\prod_{O\in C(k,r)}
\left( 
\frac{\lambda_O \cdot \prod_{R\in \sigma} \beta_R^{|E_R(O)|}}{n^{|V(O)|}}
\right)^{b_O} = \\
&\prod_{O\in C(k,r)} \frac{1}{b_O!}\left(\frac{\lambda_O  
\cdot \prod_{R\in \sigma} \beta_R^{|E_R(O)|} }{|Aut(O)|}
\right)^{b_O}= \prod_{O\in C(k,r)} 
\frac{(\omega_O)^{b_O}}{b_O!},
\end{align*}
as we wanted. With this, because of \cref{thm:BrunSieve}, it 
is proven that when $n$ tends to infinity
the $X_{n,O}$'s are asymptotically distributed 
like independent
Poisson variables with the $\omega_O$'s as their respective means.\par
Given a simple $k$-agreeability class for hypergraphs $\mathcal{O}$ there 
is a partition $C_1, C_2\subset C(k,r)$, $C_1\cup C_2=C(k,r)$ 
and there are natural numbers $a_O\leq k-1$ for any $O\in C_2$ such that
$C_1, C_2, (a_O)_{O\in C_2}$ depend only on $\mathcal{O}$ and
the event $G_n\in \mathcal{O}$ is equivalent to
\[
G_n \text{ is $r$-simple } \wedge
\left(
 \bigwedge_{O\in C_1}
 X_{n,O}\geq k
\right)
\wedge
\left(
\bigwedge_{O\in C_1}
X_{n,O}=a_O.
\right).
\]
In consequence
\begin{align*}
 & \Ln
 \PR{G_n \in \mathcal{O}}=\\
 &\Ln
 \Pr \left(
 G_n \text{ is $r$-simple } \wedge
 \left(
 \bigwedge_{O\in C_1}
 X_{n,O}\geq k
 \right)
 \wedge
 \left(
 \bigwedge_{O\in C_1}
 X_{n,O}=a_O.
 \right)
 \right).
\end{align*}
Because of \cref{thm:simple}, last limit equals
\begin{align*}
&\Ln
\Pr \left(
\left(
\bigwedge_{O\in C_1}
X_{n,O}\geq k
\right)
\wedge
\left(
\bigwedge_{O\in C_1}
X_{n,O}=a_O.
\right)
\right)
=\\
&
\left(
\prod_{O\in C_1}
1-\sum_{i=0}^{k-1} e^{-\omega_O}\frac{(\omega_O)^i}{i!}
\right)
\cdot
\left(
\prod_{O\in C_2}
e^{-\omega_O}\frac{(\omega_O)^{a_O}}{a_O!}
\right)
.
\end{align*}
This last expression belongs to $\Omega$, so the theorem is proven. 
\end{proof}

\section{Proof of the main theorem}

\begin{theorem}
	Let $\phi\in FO[\sigma]$. Then the function 
	$F_\phi: [O,\infty)^{|\sigma|}\rightarrow [0,1]$
	given by
	\[
	\overline{\beta}:=(\beta_R)_{R\in \sigma} \mapsto
	\Ln \Pr \left(
	G_n(\overline{\beta}) \models \phi
	\right)
	\]
	is well defined and it is given by a finite sum of expressions
	in $\Theta$.
\end{theorem}
\begin{proof}
	Let $k$ be the quantifier rank of $\phi$ and
	let $r=3^k$. Using \cref{thm:simple} we obtain
	\[
	\Ln \Pr \left(
	G_n(\overline{\beta}) \models \phi
	\right)=
	\Ln \Pr \left(
	G_n(\overline{\beta}) \models \phi
	\, \Big|
	\, G_n(\overline{\beta})
	\text{ is $r$-simple}
	\right).
	\]
	Let $S$ be the set of simple $k$-agreeability classes. 
	Then the LHS of last equation equals
	\[
	\Ln
	\sum_{\mathcal{O}\in S} \Pr\left(
	G_n(\overline{\beta})\in \mathcal{O}
	\right) \cdot 
	\Pr\left(
	G_n(\overline{\beta})\models \phi \,
	\Big| \,
	G_n(\overline{\beta})\in \mathcal{O}
	\right).
	\]
	Notice that, because the set $S$ is finite, 
	this is the limit of a finite sum. Also, 
	using REF, we obtain that for any $\mathcal{O}\in S$
	it holds
	\[
	\Ln \Pr\left(
	G_n(\overline{\beta})\models \phi \,
	\Big| \,
	G_n(\overline{\beta})\in \mathcal{O}
	\right) = 0 \textrm{ or } 1.
	\]
	Let $S^\prime\subset S$ be the set of classes 
	$\mathcal{O}$ for which last limit equals $1$. Then
	\[
	\Ln \Pr \left(
	G_n(\overline{\beta}) \models \phi
	\right)=
	\sum_{\mathcal{O}\in S^\prime}
	\Ln \Pr\left(
	G_n(\overline{\beta})\in \mathcal{O}
	\right).		
	\]
	Because of \cref{thm:agreeabilityprobabilities} we know that
	each of the limits inside last sum exists and is given by
	an expression that belongs to $\Theta$. As a consequence the
	theorem follows. 	
\end{proof}

\section{Application to random SAT}

%During this section we will consider
%inside of $G_n$ a set of distinguished vertices
%$\overline{v}\in \N*$ cho




%
%expressions analytic in $\overline{\beta}$
%
%\begin{lemma}
%	Let $v_1,\dots,v_l \in [n]$	
%	
%\end{lemma}


%Let $\overline{v[s]}$, resp. $\overline{u[s]}$,
%be the list obtained by joining the marked lists
%in $\mathcal{X}[s]$, resp. $\mathcal{Y}[s]$, according
%to the order of their marks. We show that during
%this strategy, at the end of the $s$-th round
% $\overline{v[s]}$ and $\overline{u[s]}$ have $(k-s)$-similar
% $r_{k-s}$-neighborhoods. For $s=0$ this is trivially
%the case, as at the beginning of the game no lists have
%been marked and both $\overline{v[s]},\overline{u[s]}$ are empty.
%Suppose

 
 













%variables
%
%and , 
%an instance of $x$ in $\phi$ is called bounded if it occurs within the 
% scope of a quantifier bounding it (i.e. it occurs in a sub-formula of
% $\phi$ of the form $\forall x(\psi)$ or $\exists x (\psi)$). 
%free if $\phi$ contains an instance of $x$ that is 
%It is specially relevant the case where $\sigma$ contains a unique
%relation $R$ symbol with arity two. In this case two important classes
%of relational structures are the class of posets- i.e. those structures
%where the relation is anti-symmetric, transitive and anti-reflexive- and 
%graphs- i.e. those where the relation is symmetric and
%anti-reflexive. Elements of a graph's universe are called vertices
%and pairs of related vertices are called edges. \par
%
%The relatively simpler structure of the binary relation in the 
%family of graphs allows to easily enumerate (labeled) graph with
%a given number of vertices and count how many among them have some
%fixed number of edges. In effect, in a graph each pair of (different)
%vertices can either form an edge or not with total independence. Thus,
%there can be $2^{\binom{n}{2}}$ graphs with $n$ vertices and 
% $\binom{\binom{n}{2}}{m}$ of those have exactly $m$ edges. \par
%
%These kind of considerations make probability spaces over graphs
%easier to define and to deal with compared with other relational
%structures such as posets. Among the first of such constructions 
%to be studied are the random models of graphs $\mathrm{G}(n,m)$ 
%and $\mathrm{G}(n,p)$ introduced by Erd\H{o}s and R\'enyi and 
%by Gilbert respectively. \par
%
%Given a natural number $n$, we denote by $[n]$ the set $\{1,\dots,n\}$.
%The model $\mathrm{G}(n,m)$, with $n$ and $m$ natural numbers,
% is the discrete probability space
%over the set of all graphs with $m$ edges and $[n]$ as their vertex
%set in where the uniform probability distribution is chosen. 
%The model $\mathrm{G}(n,p)$, with $n$ a natural number and 
% $0\leq p \leq 1$ in the real numbers, is the discrete probability space over
%the set of all graphs whose vertex set is $[n]$ in where each graph 
%with $m$ edges has probability $p^m(1-p)^{\binom{n}{2}-m}$.\par
%
%Although early on random models of graphs were used as tools to solve 
%other problems such as constructing graphs with large girth and large
%chromatic number or providing lower bounds for Ramsey numbers, later 
%they began to be studied as objects interesting in their own right.
%A problem in this field is to determine whether the asymptotic probability
%of a property exists or not in a given model of random graphs. For example,
%in the model $\mathrm{G}(n,p)$, if we take $p=p(n)$ a fixed function on $n$, 
%we want to know for which graph properties $P$ the limit of 
%\( \mathrm{Pr}\big( \mathrm{G}(n,p(n)) \text{ satisfies } P \big) \) exists as
% $n$ tends to infinity. \par
%
%A way to study this problem that has proven to be fruitful is to classify
%graph properties according to the logical languages they can be defined 
%in. We say that a sequence of random graphs $(G_n)_n$ obeys a
%\textit{convergence law}
%with respect to some logical language $\mathcal{L}$ if for any sentence
% $\phi$ in $\mathcal{L}$ the probability that $G_n$ satisfies $\phi$ tends
%to some limit as $n$ tends to infinity. We say that $(G_n)_n$ obeys a 
%\textit{zero-one law} with respect to $\mathcal{L}$ if that limit is always
%either zero or one.  \par
%
%The usual example of logical language is the \textit{first order (FO) language 
%of graphs}. Here formulas are composed of variables $x,y,z, \dots$ ranging over
%vertices, the adjacency relation symbol $R$, Boolean connectives 
% $\wedge, \vee, \neg, \implies, \dots$, the universal $\forall$ and 
%existential $\exists$ quantifiers and the parentheses $)$, $($. 
%Other examples
%of logical languages for graphs include higher order logics such as the 
%\textit{second order (SO) language of graphs} or fragments of those such as
%the \textit{monadic second order (MSO) language of graphs} or 
%the \textit{existential second order (ESO) language of graphs}. \par
%
%Convergence laws for FO logic in the binomial model $\mathrm{G}(n,p)$
%have been extensively studied. A classical result in this area is due to 
%Fagin (REF) and states that $\mathrm{G}(n,p)$ obeys a zero-one law with
%respect to FO logic when $0\leq p \leq 1$ is a fixed constant. By then
%it was speculated that for all ``sufficiently nice" functions $p(n)$
%tending to zero as $n$ tends to infinity the model $\mathrm{G}(n,p(n))$
%would obey at least a convergence law with respect to FO logic. However,
%this intuition was proven wrong in a remarkable article by Shelah and 
%Spencer REF. Among other results, there was proven that for 
% $\alpha\in (0,1)$ the model $\mathrm{G}(n,n^{-\alpha})$ satisfies a 
%zero-one law with respect to FO logic if and only if $\alpha$ is irrational.
%Furthermore, if $\alpha\in (0,1)$ is rational then 
% $\mathrm{G}(n,n^{-\alpha})$ does not even obey a convergence law for FO
%logic. \par
%This strange behavior of the rational powers of $n$ is suddenly
%interrupted at $n^{-1}$. In REF Lynch proved the following result 
%
%This is in fact a weaker version of theorem 2.1 in the mentioned
%article. In there is given a characterization of the family functions
%of the form $F_\phi$. The analyticity of the $F_\phi$'s is 
%a consequence of this characterization. \par
%In $\mathrm{G}(n,p)$ the regime where $p(n)=\beta n^{-1}$ is called
%sparse. In there the number of edges in a random graph is approximately
% $\frac{beta}{2}n$. Many interesting phenomena occur in this regime, being
%the most notable one the sudden appearance of a unique giant connected 
%component when $\beta$ is greater than one REF.  
%The goal of this article is to generalize this result from Lynch to
%other families of relational structures different form the family of 
%graphs that still share the desirable properties that allow for a 
%natural definition of binomial random model. \par
%
%A particular case of those are the families of $k$-uniform
%(labeled) hyper-graphs for $k$ a natural number. These are formed
%by a set of vertices and a set of edges where each edge is a set of 
%exactly $k$ vertices. A random hyper-graph in the binomial model of 
%random $k$-uniform hyper-graphs $\mathrm{G}_k(n,p)$ has vertex set $[n]$ 
%and contains each possible edge with probability $p$ independently, 
%analogously to the model $\mathrm{G}(n,p)$. In particular
% $\mathrm{G}_2(n,p)$ is the same model as $\mathrm{G}(n,p)$. \par
%A number of results about the binomial random model for graphs have 
%been generalized to $\mathrm{G}_k(n,p)$. Some analogous for convergence
%and zero-one laws for the FO language of $k$-uniform hyper-graphs have
%been obtained REFS. The sparse regime in this model occurs when 
% $p$ is of the form $p(n)=\beta n^{-k+1}$. This way the expected total 
%number of edges in a random hyper-graph grows linearly with $n$, and the
%model shares many similarities with $\mathrm{G}(n,cn^{-1})$. 
%In REF, among other results, it is proven that
% $\mathrm{G}_k(n,p)$ obeys a convergence law for FO logic when
% $p=\beta n^{k-1}$.
%


 
%One can also consider graphs where 'loops' are allowed or directed graphs. 
%Unlike the class of posets, these other classes of graph-like structures share 
%the property that one can easily enumerate their elements up to a given universe 
%size.   

%The first order language with signature $\sigma$ deals with strings
%of symbols taken from the alphabet consisting of
% variable symbols $x_1,\dots,x_m,\dots$, the symbols in $\sigma$,
%the logical connectives $\neg, \wedge, \vee$,
%the universal $\forall$ and existential $\exists$ quantifiers,
%the equality symbol, and the parentheses $),($.
%A first order formula is a string obtained after applying the
%following set of rules a finite number of times: 
%\begin{enumerate}[label=(\Roman*),itemsep=0pt, topsep=0pt]
%	\item If $x_1,x_2$ are variables then $x_1=x_2$ is a formula.
%	\item If $R_i$ is a relation symbol in $\sigma$ with arity $a_i$,
%	and $t_1,\dots, t_{a_i}$ are terms then 
%	$R_i(t_1,\dots,t_{a_i})$ is a formula.
%	\item If $\varphi$ and $\psi$ are formulas, then both
%	$(\varphi \wedge \psi)$ and $(\varphi \vee \psi)$ are formulas.
%	\item If $\varphi$ is a formula then $\neq \varphi$ is also 
%	a formula.
%	\item If $\varphi$ is a formula and $x$ is a variable then both
%	$\forall x \varphi$ and $\exists x\varphi$ are formulas. 
%\end{enumerate} 
%
%Let $\varphi$ be a first order formula. An occurrence of a variable 
%in $\varphi$ is called bounded if it is within the scope of
%a quantifier binding it, and is called free otherwise. We
%will assume that the occurrences of any given variable in a first
%order sentence are either all free or all bounded. 
%We will use the notation $\varphi(x_1,\dots, x_n)$ to indicate
%that $x_1, \dots, x_n$ are distinct and they are the free variables
%(i.e. the variables whose occurrences are all free) 
%in $\varphi$. A formula with no free variables is called a sentence,
%and a formula whose variables are all free is called open.
%
%Let $\mathfrak{A}$ be a $\sigma$-structure and $\varphi(x_1,\dots,x_n)$ 
%be a first order sentence. Given a map $\alpha$ from the set
%of free variables $\{x_1,\dots,x_n\}$ to the universe $A$ 
%of $\mathfrak{A}$ we define the relation 
% $\mathfrak{A} \models \varphi[\alpha]$, "$\alpha$ satisfies $\phi$ in $\mathfrak{A}$",
%in the following way:
%\begin{enumerate}[label=(\Roman*),itemsep=0pt, topsep=0pt]
%	\item 
%	\item If $R_i$ is a relation symbol in $\sigma$ with arity $a_i$,
%	and $t_1,\dots, t_{a_i}$ are terms then 
%	$R_i(t_1,\dots,t_{a_i})$ is a formula.
%	\item If $\varphi$ and $\psi$ are formulas, then both
%	$(\varphi \wedge \psi)$ and $(\varphi \vee \psi)$ are formulas.
%	\item If $\varphi$ is a formula then $\neq \varphi$ is also 
%	a formula.
%	\item If $\varphi$ is a formula and $x$ is a variable then both
%	$\forall x \varphi$ and $\exists x\varphi$ are formulas. 
%\end{enumerate} 
%
%


 
%
%\section{Random relational structures}
%
%Given a natural number $n$, we will use the notation
% $[n]:= \{1,\dots, n\}$. We will denote by $S_n$
%the symmetric group on $[n]$, and by $\Delta_n$ the 
%diagonal set $\{(a,a)\in [n]^2 \}$. \par
%Given a set $X$, then $S_n$ acts on $X^n$ in an evident way. That is, 
%given $g\in S_n$ and $(x_1, \dots, x_n)$ one can define
%\[ g \cdot (x_1,\dots,x_n) =(y_1,\dots,y_n), \]
%where $y_{g(i)}=x_i$ for all $1\leq i\leq n$.\par
%Given $\Phi$ a subgroup of $S_n$ we will denote by $X^n/\Phi$
%the orbit set associated to the action of $\Phi$ over $X^n$.\par
%We will use the notation $[x_1,\dots,x_n]$ to refer to the 
%equivalence class of the $n$-tuple $(x_1,\dots, x_n)$ in 
%any sort of quotient $X^n/\Phi$. That is, while the notation
% $(x_1,\dots, x_n)$ will be reserved to ordered $n$-tuples, 
% $[x_1,\dots,x_n]$ will denote an ordered $n$-tuple modulo the
%action of some arbitrary group of permutations. Which group is this 
%will depend solely on the ambient set where $[x_1,\dots,x_n]$ is
%considered.
%\par
%
%
%\begin{definition}
%	Let $n,a \in \N$, let $\Phi$ be a subgroup of $S_a$, and let
%	$A$ be a subset 
%	\[ A\subseteq [a]^2 \setminus \delta.\]
%	The total edge set $\mathcal{H}_{(a,\Phi, A)}(n)$ of size $a$, 
%	symmetry group $\Phi$ and
%	restrictions $R$ on $n$ elements is the set:
%	\[  \mathcal{H}_{(a,\Phi, R)}(n)= ([n]^a/\Phi) \, \,
%	\setminus \{\,  [x_1, \dots,x_a] \in [n]^a/\Phi  \, \, 
%	| \, \, x_i=x_j \, \text{for some } (i,j)\in R \} \]
%\end{definition}
%
%\begin{definition}
%	An (hyper)-graph $([n], H_1,\dots, H_c)$ with edge colors 
%	$1,\dots, c$, sizes $a_1,\dots,a_c$, 
%	symmetry groups $\Phi_1,\dots,\Phi_c$ and 
%	restrictions $A_1,\dots,A_c$ consists of 
%	\begin{itemize}
%		\item The set $[n]$ for some natural number $n$.
%		\item For $i=1,\dots,c$, a colored edge set $H_i\subseteq \mathcal{H}_{(a_i,\Phi_i,A_i)}(n)$ whose elements 
%		have color $i$.
%	\end{itemize}
%\end{definition}
%
%\begin{definition} 
%	Let $p=(p_1,\dots, p_c)$, where all $p_i$'s are real numbers
%	between $0$ and $1$. 
%	The random model $HG(n,p)$ with edge colors $1,\dots,c$,
%	sizes $a_1,\dots,a_c$, 
%	symmetry groups $\Phi_1,dots,\Phi_c$ 
%	and restrictions $A_1,\dots,A_c$, is the one that
%	assigns to each graph $G=([n], H_1,\dots, H_c)$
%	probability
%	\[ \mathrm{Pr}(G)=\prod_{i=1}^{c} p_i^{|H_i|}(1-p_i)^{|\mathcal{H}_{(a_i,\Phi_i,A_i)}(n)|-|H_i|}.	
%	\]
%	Equivalently, this is the probability space obtained by 
%	assigning to each colored edge 
%	$e\in \mathcal{H}_{(a_i,\Phi_i,A_i)}(n)$ probability $p_i$ independently. 
%\end{definition}
%
%For the rest of the work we will consider 
%\begin{itemize}
%	\item the total number of colors $c$,	
%	\item the sizes $a_1,\dots,a_c$,
%	\item the symmetry group $\Phi_1,\dots, \Phi_c$ and,
%	\item the restrictions $A_1,\dots,A_l$
%\end{itemize}
%fixed. When we say ``graph'' from now on what
%we will mean is ``hiper-graph with edge colors 
% $1,\dots, c$, sizes $a_1,\dots,a_c$, 
%symmetry groups $\Phi_1,\dots,\Phi_c$ and 
%restrictions $R_1,\dots,R_c$''. \par
%
%Given a graph $G=([n], H_1,\dots, H_c)$ we will denote by
% $H_i(G)$ the edge set $H_i$, and by $V[G]$ the vertex set
% $[n]$. Also, we will write $H(G)$ to denote the 
%disjoint union of colored sets $\cup_{i=1}^c H_i$.
%This way, an edge $e\in H(G)$ with color $i$ is an element
% $[x_1,\dots,x_{a_i}]\in H_i(G)$, and the $x_i$'s are vertices
%belonging to $V(G)$. \par
%Given a set of vertices, $X\subseteq V(G)$, we will denote
%the by $G[X]$ the induced sub-graph on $X$. \par
%As usual, we will sometimes treat edges as sets of vertices
%rather than ``tuples modulo the action of some permutation group''. 
%This way, expressions like $e_1\cup e_2$ for $e_1, e_2\in H(G)$
%will make sense and mean 
%``the set of vertices that occupy some place in $e_1$ 
%and in $e_2$".\par
%Some other times we will treat edges $e\in H(G)$
%as sub-graphs of $G$ in the evident way. That is, the subgraph
%denoted by $e$ is the one whose vertex set is $e$-i.e., the vertices in $e$-
%and whose only edge is $e$. 
%This way, when we have some edges $e_1,\dots, e_l\in H(G)$ 
%it will make sense to talk
%about the subgraph $\cup_{i=1}^l e_i$, which is the graph
%whose vertex set is the set of vertices belonging to the $e_i$'s, 
%and whose edges are exactly the $e_i$'s. In spite of these
%abuses of notation the ``type'' of any ``term'' involving edges 
%should be derivable from the context. \par
%Another usual abuse of notation we will make is to sometimes
%treat graphs as their underlying vertex sets. Hence,
%expressions defined for sets of vertices will also be defined 
%for graphs. 
%	
	
\pagebreak
\bibliography{biblio}
\bibliographystyle{unsrt}	
\end{document}