\documentclass[12pt,notitlepage,a4paper]{article}

\usepackage[left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm]{geometry}
\usepackage{graphicx}
\usepackage{amssymb,mathtools, amsmath, amsfonts, amsthm}
%\usepackage{color}
\usepackage{float}
\usepackage{hyperref}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{chngcntr}
\usepackage{cleveref}
\usepackage{pdfpages}

\usepackage{mathptmx}

\counterwithout{equation}{section}

\newlength{\margen}
\setlength{\margen}{\paperwidth}
\addtolength{\margen}{-\textwidth}
\addtolength{\skip\footins}{0.7 cm}
\setlength{\margen}{0.5\margen}
\addtolength{\margen}{-1in}
\setlength{\oddsidemargin}{\margen}
\setlength{\evensidemargin}{\margen}
\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}
%%%% Small setup %%%%
\hypersetup{
	colorlinks=false,
	pdfborder={1 1 0.0005},
}
\setlength{\parskip}{0.2cm}
%%%%%%%%%%%%%%%
\usepackage{tikz-cd}
\usetikzlibrary{cd}
\usepackage[english]{babel}
\usepackage{todonotes}
\usepackage{cleveref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{bbding}
\usepackage{tcolorbox}
\usepackage{natbib}


\newtheorem{proposition}{Proposition}[section]
\newtheorem{fact}{Fact}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{obs}{Observation}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{corollary}{Corollary}[section]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{propdef}{Proposition / Definition}[section]
\newtheorem{remark}{Remark}[section]


\newcommand{\cc}{\mathfrak{c}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Hc}{\mathcal{H}}
\newcommand{\Lan}{\mathcal{L}}
\newcommand{\Ln}{\lim\limits_{n\to \infty}}
\newcommand{\clist}{\mathfrak{c}_{1}, \cdots, \mathfrak{c}_m}
\newcommand{\morph}[1]{\simeq_#1}
\newcommand{\vlst}[2]{#1_1,\dots, #1_{#2}}
\newcommand{\gnp}{G(n,\beta_1/n^{a_1-1}, \dots,\beta_l/n^{a_l-1})}
\newcommand{\overbar}[1]{\mkern 1.5mu\overline{\mkern-1.5mu#1\mkern-1.5mu}\mkern 1.5mu}
\newcommand{\ehr}{\textsc{Ehr}}

\begin{document}
\begin{abstract}
	We consider a finite relational vocabulary $\sigma$
	and a first order theory $T$ for $\sigma$ 
    composed of symmetry and 
    anti-reflexivity axioms. We define a binomial random model of finite 
    $\sigma$-structures that satisfy $T$ and show that first order properties have 
    well defined asymptotic probabilities in the sparse 
    case. It is also shown that those limit probabilities are well-behaved with
    respect to some parameters that represent edge densities. 
    An application of these results to the problem of random Boolean 
    satisfiability is presented afterwards. 
    We show that there is no first order property of $k$-CNF formulas
    that implies unsatisfiability and holds for almost all typical 
    unsatisfiable formulas when the number of clauses is linear. 
   
\end{abstract}
\clearpage

\section*{Introduction}

Since the work of Erd\"os and R\`enyi on the evolution of random graphs
\cite{erdHos1960evolution} the study of the asymptotic properties of random
structures has played a relevant role in combinatorics and computer science.
A central theme in this topic is, given a succession $(G_n)_n$ of random
structures of some sort and a property $P$, to determine the limit probability
that $G_n$ satisfies $P$ or to determine whether that limit exists. \par
One approach that has proven to be useful is to classify the properties $P$
according to the logical languages they can be defined in. We say that the 
succession $(G_n)_n$ obeys a convergence law with respect to some logical language
$\mathcal{L}$ if for any given property $P$ expressible in $\mathcal{L}$ the 
probability that $G_n$ satisfies $P$ tends to some limit as $n$ grows to infinity.
We say that $(G_n)_n$ obeys a zero-one law with respect to $\mathcal{L}$ if
that limit is always either zero or one. 
The seminal theorem on this topic, due to Fagin \cite{fagin1976probabilities}
and Glebskii et al. 
\cite{glebskii1969range} independently, states that if $G_n$ denotes a labeled
graph with $n$ vertices picked uniformly at random among all $2^{\binom{n}{2}}$ 
possible then $(G_n)_n$ satisfies a zero-one law with respect to the first order
(FO) language of graphs. \par
Originally this result was proven in the broader context of relational
structures but it was in the theory of random graphs were the study of 
other zero-one and convergence laws became more prominent. In particular,
the asymptotic behavior of FO logic in the binomial model of random graphs 
$G(n,p)$ has been extensively studied. In this model, introduced by Gilbert 
\cite{gilbert1959random}, a random graph is obtained from $n$ labeled vertices
by adding each possible edge with probability $p$ independently. When $p=1/2$
this distribution of random graphs coincides with the uniform one, mentioned 
above. In general, for the case where $p$ is a constant probability a slight 
generalization of the proofs in \cite{fagin1976probabilities} and 
\cite{glebskii1969range} works and $G(n,p)$ satisfies a zero-one law 
for FO logic. If we consider $p(n)$ a decreasing function of the form
$n^{-\alpha}$ we can ask the question of what are the values of $\alpha$
for which $G(n,p(n))$ obeys a zero-one or a convergence law for FO logic. 
In \cite{shelah1988zero} Shelah and Spencer gave a complete answer 
for the range $\alpha\in (0,1)$. Among other results, they proved that
if $\alpha$ is an irrational number in this interval then
$G(n,p(n))$ obeys a zero-one law for FO logic, while if $\alpha$
is a rational number in the same range then $G(n,p(n))$ does not
even satisfy a convergence law for FO logic. The case $\alpha=1$
was later solved by Lynch in \cite{lynch1992probabilities}. A weaker
form of the main theorem in that article states the following:
\begin{theorem} 
	For any FO sentence $\phi$, the function
	$F_\phi: (0,\infty)\rightarrow [0,1]$ given by 
	\[ F_\phi(\beta) = \Ln \mathrm{Pr}\big( \mathrm{G}(n,\beta/n)
	\text{ satisfies } \phi   \big) \]
	is well defined and analytic. In particular, for any
	$\beta \geq 0$ the model $\mathrm{G}(n,\beta/n)$
	obeys a convergence law for FO logic. 
\end{theorem}

The analyticity of these asymptotic probabilities with respect to 
the parameter $\beta$ implies that FO properties cannot "capture" sudden
changes that occur in the random graph $\mathrm{G}(n,\beta/n)$
as $\beta$ changes. Given $p(n)$ a probability, $P$ a property of graphs,
and $Q$ a sufficient condition for $P$ - i.e., a property that 
implies $P$ -, we say that $Q$ explains $P$ if $\mathrm{G}(n,p(n))$ satisfies 
the converse implication $P \implies Q$ asymptotically almost surely
(a.a.s.). A notable example of this phenomenon happens in the range 
$p(n)= \log(n)/n + \beta/n$ with $\beta$ constant. Erd\"os and R\`enyi
\cite{erdHos1960evolution} 
showed that for probabilities of this form $\mathrm{G}(n,p(n))$ 
a.a.s. is disconnected only if it contains an isolated vertex. 
An observation by Albert Atserias is the following:

\begin{theorem}
Let $c$ be a real constant such that 
$\Ln \mathrm{Pr}\big( G(n, c/n) 
\text{ is not }	3\text{-colorable }\big)> 0$.  
Then there is no FO graph property that explains 
non-$3$-colorability for $G(n, c/n)$.
\end{theorem}

The short proof of this theorem is as follows: 
It is a known fact that there are positive constants
$c_0\leq c_1$ such that $G(n, c/n)$ is a.a.s $3$-colorable
if $c<c_0$ and it is a.a.s non $3$-colorable if $c>c_1$ 
REFERENCES NEEDED.
Suppose that $P$ is a FO graph property that implies
non-$3$-colorability. Then, because of this implication,
for all values of $c$
\[\Ln \mathrm{Pr}\big( G(n, c/n) 
\text{ satisfies } P \big) \leq \Ln \mathrm{Pr}\big( G(n, c/n) 
\text{ is not }	3\text{-colorable}\big).\]
In consequence the asymptotic probability that $G(n,c/n)$ 
satisfies $P$ is zero when $c<c_0$. By Lynch's theorem, if 
$P$ is definable in FO logic then this asymptotic probability
varies analytically with $c$. Using the fact that any analytic 
function that takes value zero in a non-empty interval must 
equal zero everywhere, we obtain that $G(n,c/n)$ a.a.s does 
not satisfy $P$ for any value of $c$. 
As a consequence the theorem follows.  \par

The aim of this work is to extend Lynch's result to arbitrary 
relational structures were the relations are subject to some
predetermined symmetry and anti-reflexivity axioms. This was 
originally motivated by an application to the study of random
$k$-CNF formulas. Since \cite{chvatal1992mick} it is known that 
for each $k$ there are constants $c_0,c_1$ such that a random 
$k$-CNF formula with $cn$ clauses over $n$ variables 

%Besides this 
% 
%This question was originally posed in \cite{atserias2005definability}
%by Albert Atserias where the answer was given for various probability





\setcounter{section}{0}

\section{Preliminaries}

\subsection{General notation}

Given a positive natural number $n$, we will write
$[n]$ to denote the set ${1,2,\dots,n}$.\par
Given a set $S$ and a natural number $k\in \N$
we will use $\binom{S}{k}$ to denote the set of 
subsets of $S$ whose size is $k$. \par
Let $S$ be a set, $a$ a positive natural number, 
and $\Phi$ a group of permutations over 
$[a]$. Then $\Phi$ acts naturally over
$S^a$ in the following way: Given $g\in \Phi$ and
$(x_1,\dots,x_a)$ we define $g(x_1,\dots,x_a)=
(x_{g(1)},\dots,x_{g(a)})$.
We will denote by $S^a/\Phi$ to the quotient
of the set $S^a$ by this action. Given an element
$(x_1,\dots, x_a)\in S^a$ we will denote its equivalence
class in $S^a/\Phi$ by $[x_1,\dots,x_a]$. Thus, for any
$g\in \Phi$, by definition $[x_1,\dots,x_a]=[x_{g(1)}
,\dots,x_{g(a)}]$. The notation $(x_1,\dots, x_a)$ 
will be reserved 
to ordered tuples while 
$[x_1,\dots,x_a]$ will denote an ordered tuple modulo the
action of some arbitrary group of permutations. Which group is
this will depend on the ambient set where $[x_1,\dots,x_a]$ belongs
and it should either be clear from context or not be relevant.\par
We will denote ordered lists of elements by $\overbar{x}:=x_1,\dots,x_a$. 
This way, expressions like $(\overbar{x})$ or $[\overbar{x}]$ would mean 
$(x_1,\dots,x_a)$ and $[x_1,\dots,x_a]$ respectively.
Sometimes we will directly write $\overbar{x}$ without specifying the list
it names nor its length when it is understood or not relevant.
\par
Given two real functions over the natural numbers 
$f,g:\N \rightarrow \R$ we will write $f=O(g)$ to 
mean that there exists some constant $C\in \R$
such that $f(n)\leq Cg(n)$ for $n$ sufficiently large, 
as usual.
If $g(n)\neq 0$ for sufficiently large values of $n$ then
we will write $f\simeq g$ if $\Ln \frac{f(n)}{g(n)}=1$.\par





\subsection{Logical preliminaries}
We will assume a certain degree of familiarity with the 
concepts. For a more complete exposition of the topics 
presented here one can consult \cite{ebbinghaus2013mathematical}.

A relational vocabulary $\sigma$ is a collection of
relation symbols $(R_1,\dots, R_m,\dots)$
where each relation symbol $R_i$ has associated a natural $a_i$
number called its arity.
A $\sigma$-structure $\mathfrak{A}$ is composed of
a set $A$, called the universe of $\mathfrak{A}$, equipped with
relations $R_1^{\mathfrak{A}}\subseteq A^{a_1},
\dots, R_m^{\mathfrak{A}}\subseteq A^{a_m}$. When $\sigma$
is understood we may refer to $\sigma$-structures as relational
structures or simply as structures.
A structure is called finite if its universe is a finite set. \par

In the first order language $FO[\sigma]$ with signature $\sigma$ 
formulas are formed by variables $x_1,\dots, x_i,\dots$,
the relation symbols in $\sigma$, the equal symbol $=$,
the usual Boolean connectives $\neg, \wedge, \vee, \dots$, 
the existential and universal quantifiers $\exists, \forall$, and
the parentheses $),($. Then formulas in $FO[\sigma]$ are defined as 
follows.
\vspace*{-0.2em}
\begin{itemize}[topsep=1pt, itemsep=1pt]
	\item The expression $R(y_1,\dots,y_a)$, where the $y_i$'s are variables and $R$
	is a relation symbol in $\sigma$ with arity $a$, belongs to $FO[\sigma]$.
	\item The expression $y_1=y_2$, where $y_1, y_2$ are variables, 
	belongs to $FO[\sigma]$.
	\item Given formulas $\phi, \psi \in FO[\sigma]$, any Boolean combination of them
	$\neg(\phi), (\phi \wedge \psi), (\phi \vee \psi), \dots$ belongs to $FO[\sigma]$ as well.
	\item Given a formula $\phi \in FO[\sigma]$ and $x$ a variable that 
	does not appear bounded
	by a quantifier in $\phi$, the expressions $\forall x (\phi)$ and 
	$\exists x (\phi)$ belong both to $FO[\sigma]$. 
\end{itemize}  
We will write $\forall y_1, y_2,\dots, y_m$ or simply $\forall \overbar{y}$
instead of  
$\forall y_1, \forall y_2,\dots, \forall y_m$ and likewise for
the quantifier $\exists$. 

We define the set of free variables of a formula as usual. 
We will use the notation $\phi(\overbar{y})$ to refer to a 
formula $\phi\in FO[\sigma]$
to denote that its free variables are the ones in $\overbar{y}$.
Formulas with no free variables are called sentences. \par
The quantifier rank of a formula $\phi$, denoted by $qr(\phi)$, 
is defined as the maximum number of nested quantifiers in $\phi$. \par
Sentences in $FO[\sigma]$ are interpreted over $\sigma$-structures
in the natural way. Given an structure $\mathcal{A}$, and a sentence
$\phi\in FO[\sigma]$ we write $\mathcal{A} \models \phi$ to denote 
that $\mathcal{A}$ satisfies $\phi$. If $\psi(\overbar{y})$ is a
formula, $\overbar{a}$ are elements in the universe of 
$\mathcal{A}$, and $\overbar{y}$ and $\overbar{a}$ are lists of the same size,
then we write $\mathcal{A} \models 
\psi(\overbar{a})$
to mean that $\mathcal{A}$ satisfies $\psi$ when the free variables in
$\overbar{y}$ are interpreted as the elements in $\overbar{a}$.
\todo[inline]{Deber\'a al menos mencionar un par de trabajos que estudien random k-SAT y propiedades a.a.s suficientes para no-satisfacibilidad}


\subsection{Structures as multi-hypergraphs}

For the rest of the article consider fixed:
\begin{itemize}
	\item Positive natural numbers $t$, $\overbar{a}=a_1,\dots, a_t$, with 
	all the $a_i$'s greater than $1$.\
	
	\item A relational vocabulary $\sigma=\{\overbar{R}\}$, with
	$\overbar{R}=R_1,\dots, R_t$ such that $a_i$ is the arity of
	$R_i$. 
	
	\item 
	Groups $\overbar{\Phi}=\Phi_1,\dots,\Phi_t$
	such that each $\Phi_i$ is consists of 
	permutations on $[a_i]$ with the usual 
	composition as its operation.
	
	\item 
	Sets $\overbar{P}=P_1, \dots, P_t$ satisfying 
	$P_i\subseteq \binom{[a_i]}{2}$
	
	
\end{itemize}

We will only consider relational structures where the relations
are of arity at least two. This restriction is not necessary, but 
it makes notation easier. 
\todo[inline]{Quiz\'as deber\'ia a\~nadir un anexo dando alguna indicaci\'on sobre c\'omo tratar las relaciones unarias?}

We can think of structures in  $\mathcal{C}^{\sigma}_{\overbar{\Phi},\overbar{P}}$
as "multi-hypergraphs" with
$t$ edge sets whose edges are of sizes $\overbar{a}$ respectively
, are invariant under permutations in $\overbar{\Phi}$ resp., 
and do 
not contain repetitions of vertices in the positions given by
$\overbar{P}$ resp. We make this observation formal in the 
following definitions:

%We will denote by $t_u$ the, possibly zero,
%amount of unary
%relation symbols in $\sigma$. 
%For the sake of convenience we may assume that $R_i$'s are
%ordered in such a way that the unary relation symbols, if any, 
%are the first ones $R_1,\dots, R_{t_u}$. This will
%become relevant later. \par 


We define the class $\mathcal{C}$ as the 
class of $\sigma$-structures that
satisfy the 
following axioms: 
\begin{itemize}
	\item \textit{Symmetry axioms}: For each $1\leq s \leq t$ and
	each $g\in \Phi_s$:
	\[ \forall x_1,\dots, x_{a_s} \big(  R_s(x_1,\dots, x_{a_s})
	\iff R_s(x_{g(1)},\dots,x_{g(a_s)}) \big)    \]
	\item \textit{Anti-reflexivity axioms}: For each 
	$1\leq s \leq t$ and $\{i,j\}\in P_s$
	\[ \forall x_1,\dots, x_{a_s} 
	\big( (x_i=x_j) \implies \neg R_s(x_1,\dots, x_{a_s})
	\big)\]
	\end{itemize}

We can think of structures in  $\mathcal{C}^{\sigma}_{\overbar{\Phi},\overbar{P}}$
as "multi-hypergraphs" with
$t$ edge sets whose edges are of sizes $\overbar{a}$ respectively
, are invariant under permutations in $\overbar{\Phi}$ resp., 
and do 
not contain repetitions of vertices in the positions given by
$\overbar{P}$ resp. We make this observation formal in the 
following definitions:

\begin{definition} 
	Let $V$ be a set, $a$ be a positive natural number,
	$\Phi$ be a group of permutations over $[a]$ and
	$P\subseteq \binom{[a]}{2}$. 
	We define the \textbf{total
	edge set over $V$ with edge size $a$, symmetry group $\Phi$ and 
	anti-reflexivity restrictions $P$} as the set
	\[ E^{V}_{a,\Phi,P}= (V^a/\Phi) \setminus \{ [x_1,\dots,x_a]  
	\,| \,
	x_1,\dots,x_a\in V \, \wedge \, x_i=x_j \text{ for some } \{i,j\}\in P \}. \]
\end{definition}

That is, $E^{V}_{a,\Phi,P}$ contains all the ``tuples modulo the permutations
in $\phi$" excluding those that contain some repetition of vertices in
the positions given by $P$.

\begin{definition} 
A \textbf{ multi-hypergraph with
with $t$ edge sets, edge sizes given by
$\overbar{a}$,
symmetry groups $\overbar{\Phi}$, 
and anti-reflexivity restrictions $\overbar{P}$}
is a pair $G=(V(G),\overbar{E(G)})$,
where $\overbar{E(G)}=E_1(G),\dots, E_t(G)$ and
for each $i$, $E_i(G) \subseteq E^{V}_{a_i,\Phi_i,P_i}$.
\end{definition}

For the sake of word economy the expression 
``multi-hypergraph with
$t$ edge sets, with edge sizes given by $\overbar{a}$,
symmetry groups $\overbar{\Phi}$, and anti-reflexivity 
restrictions $\overbar{P}$" 
will be replaced simply by ``hypergraph ". The word 
``hypergraph" will not hold
any other meaning than this for the rest 
of this writing except for the places
where it is explicitly stated.  \par

Hypergraphs, as we have defined them, 
can be naturally interpreted as
structures from $\mathcal{C}^
{\sigma}_{\overbar{\Phi},\overbar{P}}$ 
in the following way: 
given $G=(V,\overbar{E})$,
we consider $V$ to be the universe of
 $G$, and for any $i$ we define
$R_i^G\subseteq V^{a_i}$ as the set such that
$(\overbar{x})\in V^{a_i}$, 
$(\overbar{x})\in R_i^G$ if and only if 
$[\overbar{x}]\in E_i$. Under 
this interpretation hypergraphs, by definition,
satisfy the symmetry and anti-reflexivity
axioms given above. It is also easy to
see that this interpretation induces
a one-to-one identification between 
structures in $\mathcal{C}^{\sigma}_{\overbar{\Phi}
,\overbar{P}}$ and hypergraphs. \par

We will use standard nomenclature and notation
from graph theory. This way, we will call vertex set
to $V(G)$ and vertices to its elements. Likewise, each of 
the $E_i(G)$'s will be called an edge set and its elements, 
edges. Given an edge set $E_i(G)$, the index $i$ will
be called its color, and the number
$a_i$ its size. Thus, we will say that
an edge $e\in E_i(G)$ has color $i$ and size
$a_i$. 

Given a set of vertices $U\subseteq V(G)$, 
we will denote by $G[U]$ the hypergraph induced
by $G$ on $U$. That is, $G[U]$ is an hypergraph
$H=(V(H),\overbar{E(H)})$ such that $V(H)=U$ and
for any list $\overbar{v}$ of vertices in $U$,
$[\overbar{v}]\in E_i(H)$ if and only if 
$[\overbar{v}]\in E_i(G)$.
\par

An homomorphism between two hypergraphs $G$ and $H$ 
a map $f:V(G)\rightarrow V(H)$ that sends edges 
from $G$ to edges in $H$ of the same color. That is,
if vertices $v_1,\dots, v_{a_i}$ form an edge 
$[v_1,\dots,v_{a_i}]\in E_i(G)$, then
$[f(v_1),\dots,f(v_{a_i})]\in E_i(H)$.
If $f$ is injective then it is called a monomorphism. 
If $f$ is bijective and its inverse is also an homomorphism 
between $H$ and $G$ then $f$ is called an isomorphism.\par

The group of automorphisms $Aut(G)$ of an hypergraph $G$ is the group
of isomorphisms between $G$ and itself. 
\par

Given two hypergraphs $G$ and $H$, a copy of $H$ in $G$ is
a sub-hypergraph $H_2\subseteq G$ isomorphic to $H$. The copy
is called induced if $H_2$ is an induced sub-hypergraph.
We will call a labeled copy
of $H$ in $G$ to a monomorphism $f:H\rightarrow G$. 
It is satisfied that the number
of labeled copies of $H$ in $G$ is $|Aut(H)|$ times the number
of copies of $H$ in $G$.


The excess $ex(G)$ of an hypergraph $G$ is the number
\[
ex(G)= \big(\sum_{i=1}^{t} (a_i-1)|E_i(G)|\big) - |V(G)|.  
\] 
That is, the excess of $G$ is its "weighted number of edges"
minus its number of vertices. Here the "weighted number of edges"
in $G$ the sum of the weight of all its edges, where the
weight of an edge is its size minus one.  


Before moving on we need to introduce some additional notation. NOTACION

Given an hypergraph $G$ we define the following metric, $d$, over $V(G)$:
\[ d^G(v,u)= \min_{\substack{H \text{ subgraph of } G\\ 
		H \text{ connected }\\
		v,u\in V(H)}} |V(H)| - 1 .\]
That is, the distance between $v$ and $u$ is the minimum size
of a connected graph $H$ containing both vertices, minus one. 
If such graph does not exist we define $d^G(u,v)=\infty$.
This definition extends naturally to subsets $X,Y\subseteq V(G)$:
\[ d^G(X,Y)=\min_{\substack{x\in X\\ y\in Y}} d^G(x,y).\]
As usual, when $X=\{x\}$ we will omit the brackets and write
$d^G(x,Y)$ instead of $d^G(\{x\},Y)$, for example. When $G$ 
is understood or not relevant we will usually simply denote the 
distance by $d$ instead of $d^G$. \par

Given set of vertices vertex, $X\subseteq V(G)$, 
we denote by $N^G(X;r)$ the $r$-neighborhood of $X$ in 
$G$. That is,  $N^G(X;r)= G[Y]$, where $Y\subseteq V(G)$ is 
the set:
\[ Y:= \{ u \in V(G) \ | \ d(X,u)\leq r   \}. \]
In particular, when $X$ is a singleton $\{v\}$, we
will write $N^G(v;r)$ instead of $N^G(\{v\};r)$.
As before, we will usually drop the ``$G$'' from our 
notation when $G$ is understood or not relevant.   

\subsection{The random model}

Let $p_1\dots,p_t$ real numbers between zero and one,
and let $\overbar{p}=p_1,\dots,p_t$.
The random model $G^{\mathcal{C}}(n,\overbar{p})$ 
is the discrete probability space that
assigns to each hypergraph $G$ whose vertex
set $V(G)$ is $[n]$ the following probability:

\[ \mathrm{Pr}(G)=\prod_{i=1}^{t} p_i^{|E_i(G)|}
(1-p_i)^{ |E^{[n]}_{a_i,\Phi_i,P_i}|-|E_i(G)|}.	
\]
Equivalently, this is the probability space obtained by 
assigning to each edge with color $i$,  
$e\in  E^{[n]}_{a_i,\Phi_i,P_i}$ probability 
$p_i$ independently. \par

%Let $G_n$ denote a random hypergraph in 
%$G^\mathcal{C}(n,\overbar{p})$, where 
%$\bar{p}:=p_1,\dots,p_t$, and 
%we allow each $p_i$ to depend on $n$. 
As in the case of Lynch's theorem, we are interested in the
"sparse regime" of $G^\mathcal{C}(n,\overbar{p})$, were the 
expected number of edges each color is linear. 
%In other words, we want that
%$\mathrm{E}[m_i(G_n)]=\Theta(n)$ for all $i$'s.
This is achieved when each of the $p_i$'s are 
of the form $\beta_i/n^{a_i-1}$ for some 
non-negative real numbers $\beta_1,\dots,\beta_t$.
Let $\overbar{\beta}:=\beta_1,\dots,\beta_t$.
We will write $\overbar{p}(n,\overbar{\beta})$ to denote 
the list $\beta_1/n^{a_1-1},\dots, \beta_t/n^{a_t-1}$.
We will treat
the parameters $\beta_1,\dots, \beta_t$ as fixed
real constants for the most part and will abbreviate 
$\overbar{p}(n,\overbar{\beta})$ as $\overbar{p}(n)$.\par

Our goal is to prove the following theorem:
%is to prove that for any sentence $\phi\in FO[\sigma]$,
%the limit 
%\[\Ln \mathrm{Pr}(G^\mathcal{C}(n,\overbar{p}
%(n,\overbar{\beta})) \models \phi)\] 
%is well defined and varies 
%analytically with $\overbar{\beta}$.
% Some care is needed
%in order to formulate this precisely, as there are some values
%of $\overbar{\beta}$ for which $\overbar{p}
%(n,\overbar{\beta})$ asymptotically does not 
%define a list of 
%proper probabilities. 
%Indeed, suppose that some relation
%symbol $R_i$ in $\sigma$ is unary. 
%Then, by definition $a_i=1$ and
%the expression $\beta_i/n^{a_i-1}$ 
%equals $\beta_i$. 
%In consequence, if we assign 
%values to $\overbar{\beta}$ and let
%$\beta_i>1$ then the random 
%model $G^\mathcal{C}(n,\overbar{p}
%(n,\overbar{\beta})$ will not be well defined. 
%To avoid this we need to impose $\beta_i\in [0,1]$ 
%for all the $i$'s such that $a_i=1$. \par
%For the sake of convenience we will adopt the convention
%that the unary relation symbols among $R_1,\dots,R_t$ 
%are the first ones, and we will denote by $t_u$ the 
%(possibly zero) number of such relations. 
%Thus $a_1= a_2 =\dots= a_{t_0}=1$, and $a_i>1$ 
%for $i>t_0$. Now we are in conditions of stating our main 
%theorem: 

\begin{theorem} \label{thm:main}
	Let $\phi$ be a sentence in $FO[\sigma]$. Then
	the function
	%$F_\phi: [0,1]^{t_u}\times [0,\infty)^{t-t_u}
	$F_\phi: [0,\infty)^{t}
	\rightarrow \R$ given by 
	\[
	\overbar{\beta} \mapsto \Ln Pr\big( G^\mathcal{C}(n,\overbar{p}
	(n,\overbar{\beta})) \models \phi\big)
	\]
	is well defined and analytic. 
\end{theorem}



\subsection{Ehrenfeucht-Fraisse Games}

Let $G_1$ and $G_2$ be hypergraphs. We define the $k$ round 
Ehrenfeucht-Fraisse game on $G_1$ and $G_2$, denoted by
$\ehr_k(G_1,G_2)$, as follows:
The game is played between two players, Spoiler and Duplicator, and
the number of rounds, $k$, is known for both from the start.
At the beginning of each round Spoiler chooses a vertex from either
$V(G_1)$ or $V(G_2)$ and Duplicator responds by choosing a vertex
from the other set.
Let us denote by 
$v_i$, resp. $u_i$ the vertex from $G_1$, resp. from $G_2$, 
chosen in the $i$-th round,
for $i\in [k]$. At the end of the $k$-th round 
Duplicator wins if the following holds:
\begin{itemize}
	\item For any $i,j\in [k]$, $v_i=v_j \iff u_i=u_j$.
	\item Given indices $i_1,\dots, i_a \in [k]$, and a color 
	$c\in [t]$,  
	$[v_{i_1},\dots,v_{i_a}] \in E_c(G_1) \iff [u_{i_1},\dots,u_{i_a}]
	\in E_c(G_2)$.
	
\end{itemize}


We define the equivalence relation $=_k$ between hypergraphs as follows:
We say that $G_1=_k G_2$ if for any sentence $\phi\in 
FO[\sigma]$ with $qr(\phi)\leq k$ then $G_1\models\phi$ if and 
only if $G_2\models\phi$. 
\par

The following is satisfied:

\begin{theorem}
	[Ehrenfeut, \citealp{ehrenfeucht1961application}] Let
	$G_1$ and $G_2$ be hypergraphs.
	Then Duplicator wins $\ehr_k(G_1,G_2)$
	if and only if $G_1=_k G_2$.	
\end{theorem}

Now consider $\overbar{v}$, and $\overbar{u}$ lists of vertices of the same length, $l$,
from $G_1$ and $G_2$ respectively. We define the $k$ round 
Ehrenfeucht-Fraisse game on $G_1$ and $G_2$ with initial position given
by $\overbar{v}$ and $\overbar{u}$, denoted by $\ehr_k(G_1,\overbar{v},G_2,\overbar{u})$,
the same way as $\ehr_k(G_1,G_2)$, but in this case the game has $l$ extra 
rounds at the beginning where the vertices in $\overbar{v}$ and $\overbar{u}$ are 
played successively. After this, $k$ more rounds are played normally. \par

We also define the $k$-round distance Ehrenfeucht-Fraisse game on 
$G_1$ and $G_2$, denoted by $d\ehr_k(G_1,G_2)$, the same way as
$\ehr_k(G_1,G_2)$, but now, in order for Duplicator to win the
game, the following additional condition has to be satisfied 
at the end of the $k$-th round:
\begin{itemize}
	\item For any $i,j\in [k]$, $d^{G_1}(v_i,v_j)=d^{G_2}(u_i,u_j)$.
\end{itemize}

Given $\overbar{v}$, and $\overbar{u}$ lists of vertices of the same length,
from $G_1$ and $G_2$ respectively we define the game 
$d\ehr_k(G_1,\overbar{v},G_2,\overbar{u})$ analogously to 
$\ehr_k(G_1,\overbar{v},G_2,\overbar{u})$.








\subsection{Outline of the proof}

We show now an outline of the proof. \par 
We show that for any quantifier rank $k$ there are some classes of
hypergraphs 
$C^k_1,\dots, C^k_{n_k}$ such that
\begin{itemize}[noitemsep, topsep=0pt]
	\item[(1)] a.a.s the rank $k$ type of any two graphs in the same class coincide, 
	\item[(2)] a.a.s. any random graph belongs to some of them, and
	\item[(3)] the limit probability of random graph belonging to 
	any of them is an analytic expression on the parameters $\overbar{\beta}$. 
\end{itemize}

After this is archived the theorem follows easily. 

The objective of next sections will be to define the classes 
$C_1,\dots, C_{n_k}$ and to show that they satisfy properties (1), (2) and (3).

\todo[inline]{Explicar esto mejor}

\subsection{Some winning strategies for Duplicator}

The aim of this section is to show the winning strategy
for Duplicator that is going to be used in our proofs. \par

Let $G_1$ and $G_2$ be hypergraphs, and let $\overbar{v} \subseteq V(G_1), 
\overbar{u} \subseteq V(G_2)$ be lists of vertices of the same size.
We say that $N(\overbar{v};r)$ and $N(\overbar{u};r)$ are
$k$-similar, or that $\overbar{v}$ and $\overbar{u}$
have $k$-similar $r$-neighborhoods, if Duplicator wins
$d\ehr_k(N(\overbar{v};r),\overbar{v},N(\overbar{u};r),\overbar{u})$.\par
If $X\subseteq V(G_1)$ and $Y\subseteq V(G_2)$
are sets of vertices we say that $X$ and $Y$ have $k$-similar
$r$-neighborhoods if we can order their vertices to form
lists $\overbar{v}$, resp. $\overbar{u}$ such that $N(\overbar{v};r)$ and
$N(\overbar{u};r)$ are $k$-similar.
\par
Now suppose that $X\subseteq V(G_1)$ and $Y\subseteq V(G_2)$ can
be partitioned into lists $X=\overbar{v_1}\cup \dots \cup \overbar{v_a}$
and $Y=\overbar{u_1}\cup \dots \cup \overbar{u_b}$ 
such that $N(\overbar{v_i};r)$'s, and the
$N(\overbar{u_i};r)$'s, are connected and disjoint. 
We say that $N(X;r)$ and
$N(Y;r)$ are $k$-agreeable,
or that they have $k$-agreeable neighborhoods, 
if any $\overbar{w}$ among the $\overbar{v_i}$'s or
among the $\overbar{u_i}$'s satisfies:
\begin{itemize}
	\item The number of $\overbar{v_i}$'s and 
	the number of $\overbar{u_i}$'s satisfying that ``$\overbar{v_i}$ 
	(resp. $\overbar{u_i}$) and $\overbar{w}$ have $k$-similar 
	$r$-neighborhoods" are the
	same or are both greater or equal than $k$.
\end{itemize}

The main theorem of this section,which
is a slight strengthening of Theorem 
2.6.7 from \cite{spencer2013strange}, is the following:

\begin{theorem}\label{ThmDuplicator}
	Set $r=(3^k-1)/2$.
	Let $G_1,G_2$ be hypergraphs, and suppose there exist
	sets $X\subseteq V(G_1)$, $Y\subseteq V(G_2)$ with the 
	following properties:
	\begin{enumerate}
		\item[(1)] $N(X;r)$ and $N(Y;r)$ are $k$-agreeable.
		\item[(2)] Let $r^\prime\leq r$. Let $v\in V(G_1)$ 
		such that $d(v,X)>2r^\prime+1$, and let
		$u_1,\dots,u_{k-1}\in V(G_2)$. Then there exists a vertex
		$u\in V(G_2)$ with $u,v$ having $k$-similar $r^\prime$-neighborhoods 
		and satisfying $d(u,u_i)>2r^\prime+1$ for all $u_i$'s as well as
		$d(u,Y)>2r^\prime +1$.
		\item[(3)] Let $r^\prime\leq r$. Let $u\in V(G_2)$ 
		such that $d(u,Y)>2r^\prime+1$, and let
		$v_1,\dots,v_{k-1}\in V(G_1)$. Then there exists a vertex
		$v\in V(G_1)$ with $v,u$ having $k$-similar $r^\prime$-neighborhoods 
		and satisfying $d(v,v_i)>2r^\prime+1$ for all $v_i$'s as well as
		$d(v,X)>2r^\prime +1$.
	\end{enumerate}
	Then Duplicator wins $\ehr_k(G_1,G_2)$.
\end{theorem}

In order to prove this theorem we need to make two observations
and prove a previous lemma. 

\begin{obs} \label{obs1}
	Let $H_1$, $H_2$ be hypergraphs and 
	$\overbar{v}$, $\overbar{u}$, be lists of vertices
	from $V(H_1)$ and $V(H_2)$ respectively. Suppose that
	Duplicator wins $d\ehr_k(H_1,\overbar{v},H_2,\overbar{u})$.
	Then, for any $r$ Duplicator also wins
	$d\ehr_k(N(\overbar{v};r),\overbar{v},N(\overbar{u};r),\overbar{u})$. 
	In particular, given hypergraphs $G_1, G_2$ and sets
	$X\subseteq V(G_1)$, $Y\subseteq V(G_2)$ such that
	$N(X;r)$ and $N(Y;r)$ are $k$-similar, then for any 
	$r^\prime \leq r$ the graphs
	$N(X;r^\prime)$ and $N(Y;r^\prime)$ are $k$-similar
	as well. 
\end{obs}

\begin{obs} \label{obs2}
	Let $H_1$, $H_2$ be hypergraphs and 
	$\overbar{v}$, $\overbar{u}$, be lists of vertices
	from $V(H_1)$ and $V(H_2)$ respectively. Suppose 
	Duplicator wins $d\ehr_k(H_1,\overbar{v},H_2,\overbar{u})$. 
	Let $v^\prime\in V(H_1),u^\prime\in V(H_2)$ be vertices
	played in the first round of an instance of the game 
	where Duplicator is following a winning strategy. Then 
	Duplicator also wins $d\ehr_{k-1}(H_1,\overbar{v_2},
	H_2,\overbar{u_2})$, where $\overbar{v_2}:=\overbar{v},v^\prime$
	and $\overbar{u_2}:=\overbar{u},u^\prime$.
\end{obs}

\begin{lemma} \label{lemm:Duplicator}
	Let $G_1$, $G_2$ be hypergraphs and 
	$\overbar{v}$, $\overbar{u}$, be lists of vertices
	from $V(G_1)$ and $V(G_2)$ respectively. Let
	$r$ be greater than zero. Suppose that
	$N(\overbar{v};3r+1)$ and $N(\overbar{u};3r+1)$ are 
	$k$-similar. Let $v^\prime\in V(G_1),u^\prime\in V(G_2)$
	be vertices played in the first round of an instance of 
	$d\ehr_k(N(\overbar{v};3r+1),\overbar{v},N(\overbar{u};3r+1),\overbar{u})$ 
	where Duplicator is following a winning strategy. Further suppose
	that $d(\overbar{v},v_2)\leq 2r+1$ (and in consequence
	$d(\overbar{u},u_2)\leq 2r+1$ as well). 
	Let $\overbar{v_2}:=\overbar{v},v^\prime$
	and $\overbar{u_2}:=\overbar{u},u^\prime$.
	Then $N(\overbar{v_2};r)$ and $N(\overbar{u_2};r)$ are 
	$(k-1)$-similar
\end{lemma}

\begin{proof}
	Using \cref{obs2} we get that Duplicator wins 
	\[d\ehr_k(N^{G_1}(\overbar{v};3r+1),\overbar{v_2},N^{G_2}(\overbar{u};3r+1)
	,\overbar{u_2})\]
	as well. Call $H_1=N^{G_1}(\overbar{v};3r+1)$,
	$H_2=N^{G_2}(\overbar{u};3r+1)$. Then by \cref{obs2}
	Duplicator wins
	\[
	d\ehr_k(N^{H_1}(\overbar{v_2};r),\overbar{v_2},N^{H_2}(\overbar{u_2};r),\overbar{u_2}).
	\]
	Because of this if we prove $N^{G_1}(\overbar{v_2};r)
	=N^{H_1}(\overbar{v_2};r)$ and $N^{G_2}(\overbar{u_2};r)
	=N^{H_2}(\overbar{u_2};r)$, then we are finished. 
	Let $z\in N^{G_1}(v^\prime;r)$. Then
	$d(z,\overbar{v})\leq d(z,v^\prime)+d(v^\prime,\overbar{v})=3r+1$.
	In consequence, $N^{G_1}(v;r)\subset H_1$. Thus,
	$N^{G_1}(\overbar{v_2};r)\subseteq H_1$, and $N^{G_1}(\overbar{v_2};r)
	=N^{H_1}(\overbar{v_2};r)$. Analogously we obtain 
	$N^{G_2}(\overbar{u_2};r)=N^{H_2}(\overbar{u_2};r)$, as we wanted. 
\end{proof}

Now we are in conditions to prove \cref{ThmDuplicator}.





\begin{proof}[Proof of \cref{ThmDuplicator}]
	Define $r_0=0$ and $r_i=3r_{i-1}+1$ for $i>0$.
	Let us denote by $w_i$ and $z_i$ the vertices played
	in $G_1$ and $G_2$ respectively during the $i$-th
	round of $\ehr_k(G_1,G_2)$. 
	%Set 
	%$\overbar{v}[i]:=v_1,\dots,v_i$ and
	%$\overbar{u}[i]:=u_1,\dots,u_i$
	%We say that Duplicator can play following the strategy $S$
	%if they can play in a way that
	%at the end of the $s$-th round, $\overbar{w}[s]$ and
	%$\overbar{z}[s]$ have $(k-s)$-similar $r_{k-s}$-neighborhoods.
	%In particular this means that at the end of the $k$-th
	%round Duplicator will have won $\ehr_k(G_1,G_2)$.
	\par
	
	Let $\overbar{v_1},\dots,\overbar{v_a}$ and 
	$\overbar{u_1},\dots,\overbar{u_b}$ be lists
	forming partitions of 
	$X$ and $Y$ respectively, and assume they
	are as in the definition of $k$-agreeability.
	Set 
	\[\mathcal{X}[0]=\{\overbar{v_1},\dots,\overbar{v_a}\},
	\quad \mathcal{Y}[0]=\{\overbar{u_1},\dots,\overbar{u_b}\}.\]
	That is, $\mathcal{X}[0]$ and $\mathcal{Y}[0]$ are the whose elements
	are the $\overbar{v_i}$'s and $\overbar{u_i}$'s respectively. 
	At the end of the $s$-th round $\mathcal{X}[s-1]$,
	resp. $\mathcal{Y}[s-1]$, will be updated into 
	$\mathcal{X}[s]$,
	resp. $\mathcal{Y}[s]$, by performing on it
	some of the following operations: adding a new list
	to it, appending one vertex to an existing list, and 
	marking a list with the index $s$. Duplicator will
	keep track of the sets $\mathcal{X}[s]$ and $\mathcal{Y}[s]$.\par
	
	We show first an strategy for Duplicator and will prove its
	correctness afterwards. The strategy is as follows: At the 
	beginning of the $s$-th round suppose Spoiler plays $w_s$ in
	$G_1$. The case where they play $z_s$ in $G_2$ is symmetric.
	Call $r=r_{k-s}$. There are three possibilities. 
	\begin{itemize}
		\item[Case 1:] The vertex $w_s$ satisfies
		$d(w_s,\overbar{v})>2r+1$ for all 
		$\overbar{v}\in \mathcal{X}[s-1]$. Then Duplicator 
		can find a vertex $z_s$ in $G_2$ such that
		$d(z_s,\overbar{u})>2r+1$ for all 
		$\overbar{u}\in \mathcal{Y}[s-1]$ satisfying 
		that $w_s$ and $z_s$ have $(k-s)$-similar
		$r$-neighborhoods. To form $ \mathcal{X}[s]$
		and $ \mathcal{Y}[s]$, add to $\mathcal{X}[s-1]$
		and $ \mathcal{Y}[s-1]$ the lists consisting
		of only $w_s$ and only $z_s$ respectively, and mark
		them with the number $s$.
		
		\item[Case 2:] The vertex $w_s$ satisfies
		$d(w_s,\overbar{v})\leq 2r+1$ for a unique 
		$\overbar{v}\in \mathcal{X}[s-1]$,and
		$\overbar{v}$ is marked. In this case,
		find the list $\overbar{u}\in \mathcal{Y}[s-1]$
		with the same mark. Duplicator 
		then can chose $z_s\in N(\overbar{u},2r+1)$
		in response to $w_s$ according to a winning strategy
		for
		\[
		d\ehr_{k-s}(N(\overbar{v},3r+1),\overbar{v},
		N(\overbar{u},3r+1),\overbar{u}).
		\]
		To form $ \mathcal{X}[s]$
		and $ \mathcal{Y}[s]$, append $w_s$ and $z_s$
		to $\overbar{v}$ and $\overbar{u}$ respectively.
		
		\item[Case 3:] The vertex $w_s$ satisfies
		$d(w_s,\overbar{v})\leq 2r+1$ for a unique 
		$\overbar{v}\in \mathcal{X}[s-1]$,and
		$\overbar{v}$ is not marked. In this case we 
		can	find a non-marked 
		list $\overbar{u}\in \mathcal{Y}[s-1]$
		such that $\overbar{v}$ and $\overbar{u}$ 
		have $(k-s)$-similar $(3r+1)$-neighborhoods. 
		Duplicator then can chose $z_s\in N(\overbar{u},2r+1)$
		in response to $w_s$ according to a winning strategy
		for
		\[
		d\ehr_{k-s}(N(\overbar{v},3r+1),\overbar{v},
		N(\overbar{u},3r+1),\overbar{u}).
		\]
		To form $ \mathcal{X}[s]$
		and $ \mathcal{Y}[s]$, append $w_s$ and $z_s$
		to $\overbar{v}$ and $\overbar{u}$ respectively,
		and mark those lists with the number $s$. 
	\end{itemize}
	
	All that is left now is to prove the correctness of the
	strategy. We show that at the end the $s$-th round, if 
	two lists $\overbar{v} \in \mathcal{X}[s]$ and 
	$\overbar{u} \in \mathcal{Z}[s]$ have the same mark then
	$\overbar{v}$ and $\overbar{u}$ have $(k-s)$-similar
	$r_{k-s}$-neighborhoods. This happens trivially at
	the end of the zeroth round -i.e., the beginning 
	of the game- as there are no marked lists. Assume the
	statement holds up to the end of the $(s-1)$-th round, 
	where $s>0$. 
	
	\begin{itemize}
		\item[Case 1:] Notice that the lists
		in $\mathcal{Y}[s-1]$ only contain the
		vertices previously played in $G_2$ and 
		the ones from $Y$. Thus, assumption $(3)$ 
		of the theorem, (or assumption $(2)$ in the 
		symmetric
		case where Spoiler plays in $G_2$) assures us
		that Duplicator can always find such $z_s$ 
		sufficiently far away from all the other lists. 
		In this case, the only new marked lists in $\mathcal{X}[s]$
		and $\mathcal{Y}[s]$ are the ones
		consisting of $w_s$ and $z_s$ respectively. By assumption
		$w_s$ and $z_s$ have $(k-s)$-similar $r_{k-s}$-neighborhoods.
		
		\item[Case 2:] Notice that by the induction hypothesis 
		$\overbar{v}$ and $\overbar{u}$ have $(k-s+1)$-similar
		$r_{s-k+1}$-neighborhoods, and in consequence a winning strategy
		for Duplicator exists. Using \cref{lemm:Duplicator} we obtain 
		that the extended lists $\overbar{v},w_s$ and $\overbar{u},z_s$
		have $(k-s)$-similar $r_{s-k}$-neighborhoods. 	
		
		\item[Case 3:] This case is analogous to the previous one.
		The definition of $k$-agreeability implies that there is 
		such an unmarked list $\overbar{u}$ available. Using \cref{lemm:Duplicator} 
		we obtain 
		that the extended lists $\overbar{v},w_s$ and $\overbar{u},z_s$
		have $(k-s)$-similar $r_{s-k}$-neighborhoods.	
	\end{itemize} 
	
	In the three cases, if $\overbar{v}$ and $\overbar{v}$
	are lists in $\mathcal{X}[s-1]$ and $\mathcal{Y}[s-1]$
	respectively that share the same mark and remain unmodified
	in $\mathcal{X}[s]$ and $\mathcal{Y}[s]$, then by the 
	induction hypothesis $\overbar{v}$ and $\overbar{v}$
	have $(k-s+1)$-similar $r_{k-s+1}$-neighborhoods. This
	easily implies that they also have
	$(k-s)$-similar $r_{k-s}$-neighborhoods.\par
	At the end of the game, if $\overbar{v}\in \mathcal{X}[k]$ and 
	$\overbar{u}\in \mathcal{Y}[k]$ are lists with the same mark
	then the natural mapping between $\overbar{v}$ and $\overbar{u}$
	defines an isomorphism between $G_1[\overbar{v}]$ and $G_2[\overbar{u}]$.
\end{proof}

\todo[inline]{Quiz\'as reordenando esta demostraci\'on se puede acortar o se entiende mejor.}


\subsection{Types of trees}

We define tree $T$ as a connected hypergraph such that
$ex(T)=-1$. We define a vertex-rooted tree $(T,v)$ 
as a tree $T$ with a 
distinguished vertex $v\in V(T)$ called its root. We will
usually omit the root when it is not relevant and 
write just $T$ instead of $(T,v)$. We define the set
of initial edges of a vertex-rooted tree $(T,v)$ as the
set of edges in $T$ that contain $v$. \par
%
%Similarly, we define an edge-rooted tree $(T,e,v)$
%as a tree $T$ with a distinguished edge $e\in E(T)$ and
%a distinguished vertex $v\in e$. \par
Given a rooted tree $(T, v)$, and a vertex $u\in V(T)$, 
we define $Tree_{(T,v)}(u)$ as the tree $T[X]$ induced on the
set $X:=\{ \, w\in V(T) \, | \, d(v,w)=d(v,u)+ d(u,w) \,  \}
$, to which we assign $u$ as the root.
That is, $Tree_{(T,v)}(u)$ is the tree consisting of those vertices
whose only path to $v$ contains $u$.
\par
We define the radius of a vertex-rooted, or edge-rooted,
tree as the maximum distance between its marked
vertex and any other one. \par


Fix a natural number $k$. We will define 
two equivalence relations, one between 
rooted trees and another between pairs
$(T,e)$ of rooted trees $T$ and initial edges
$e\in E(T)$. We will name both relations
$k$-equivalence relations and
denote them by $\morph{k}$. 
They are defined recursively as follows:

\begin{itemize}
	\item Any two trees with radius zero are $k$-equivalent 
	.Notice that those trees
	consist only of one vertex, their respective roots.
	\item Suppose that the $k$-equivalence relation has been
	defined for rooted trees with radius at most $r$.
	\begin{itemize}
		\item Let $T_1$ and $T_2$ be rooted trees with radius
		at most $r+1$, and let $e_1, e_2$
		be initial edges of $T_1$ and $T_2$ respectively.
		Then $(T_1,e_1)\simeq_k (T_2,e_2)$ if
		$e_1$ and $e_2$ have the same color and there is a bijection 
		$f: e_1\rightarrow e_2$ between the vertices in $e_1$ and
		$e_2$ such that:
		\begin{itemize}
			\item If $e_1=[u_1,\dots, u_a]$ then $e_2=[f(u_1),\dots,f(u_a)]$.
			\item If $v_1$ and $v_2$ are the roots of
			$T_1$ and $T_2$ respectively, then $v_2=f(v_1)$.
			\item For any vertex different from the root $u\in e_1$, it is satisfied that
			\[Tree_{(T_1,v_1)}(u)\morph{k} Tree_{(T_2,v_2)}(f(u)).\]
		\end{itemize}
		\item Let $T_1$ and $T_2$ be rooted trees with
		radius at most $r+1$. Then $T_1\morph{k} T_2$ if
		for any chosen $T=T_1$ or $T=T_2$ and any initial edge
		$e\in E(T)$, the "quantity 
		of initial edges $e_1$ from $T_1$ that satisfy
		$(T_1,e_1)\simeq_k (T, e)$" and the "quantity 
		of initial edges $e_2$ from $T_2$ that satisfy
		$(T_2,e_2)\simeq_k (T, e)$" are the same or 
		are both greater than $k-1$.
		
	\end{itemize}
\end{itemize}

We want prove the following
\begin{theorem} \label{thm:equivalenttrees} 
	Let $(T_1,v_1)$ and $(T_2,v_2)$ be rooted trees.
	Then, if they are $k$-equivalent Duplicator wins
	$d\ehr_{k}(T_1,v_1,T_2,v_2)$.
\end{theorem}

Before proceeding with the proof that we need an auxiliary
result. Let $(T,v)$ be a rooted tree and $e$ an 
initial edge of $T$. We define $Tree_{(T_v)}(e)$ as
the induced tree $T[X]$ on the set
$X:=\{v\} \cup \{\, u\in V(T) \, | \, d(v,u) = |e| + d(e,v) \,\}$,
to which we assign $v$ as the root. In other words, 
$Tree_{(T_v)}(e)$ is the tree formed of $v$ and all the vertices
in $T$ whose only path to $v$ contain $e$. 
Now we can check the following:

\begin{lemma} \label{lem:equivalentedges}
	Fix $r>0$. Suppose that theorem \ref{thm:equivalenttrees}
	holds for rooted trees with radii at most $r$.
	Let $(T_1,v_1)$ and $(T_2,v_2)$ be rooted trees with radii
	at most $r+1$. Let $e_1$ and $e_2$ be initial edges 
	of $T_1$ and $T_2$ respectively satisfying 
	$(T_1,e_1)\simeq_k (T_2,e_2)$. Name 
	$T^\prime_1=Tree_{(T_1,v_1)}(e_1)$ and 
	$T^\prime_2=Tree_{(T_2,v_2)}(e_2)$. Then
	Duplicator wins $d\ehr{k}(T^\prime_1, v_1, T^\prime_2,v_2)$.
\end{lemma}
\begin{proof}
	We show a winning strategy for Duplicator. 
	Suppose that in the $i$-th round of the game Spoiler
	plays on $T^\prime_1$. The other case is symmetric. Let
	$f:e_1\rightarrow e_2$ be a bijection as in the definition
	of $(T_1,e_1)\simeq_k (T_2,e_2)$. There are two possibilities:
	\begin{itemize}
		\item If Spoiler plays a vertex $v$ on $e_1$ 
		then Duplicator can play $f(v)$ on $e_2$. 
		\item Otherwise, Spoiler plays a vertex $v$ that belongs
		to some $Tree_{(T^\prime_1,v_1)}(u)$ for a unique $u\in e_1$
		different from the root $v_1$.
		By the definition of $(T_1,e_1)\simeq_k (T_2,e_2)$,
		$Tree_{(T^\prime_1,v_1)}(u)\simeq_k 
		Tree_{(T^\prime_2,v_2)}(f(u))$. As both these trees
		have radii at most $r$, by assumption Duplicator has a winning 
		strategy between them and they can follow it.		
	\end{itemize}
\end{proof}

Now we can prove the main theorem of this section:

\begin{proof}[Proof of \cref{thm:equivalenttrees}]~ \par
	Notice that, as $T_1\morph{k} T_2$, both $T_1$ and
	$T_2$ have the same radius $r$.
	We prove the result by induction on $r$.
	If $r=0$ then both $T_1$ and $T_2$ consist
	of only one vertex and we are done. \par
	Now let $r>0$ and assume that the 
	statement is true for all lesser values of $r$.
	We will show that there is a winning strategy 
	for Duplicator in
	$d\ehr_k(T_1,v_1,T_2,v_2)$.
	At the start of the game, set all the initial edges
	in $T_1$ and $T_2$ as non-marked. 
	Suppose that in the $i$-th round Spoiler plays in 
	$T_1$. The other case is symmetric. 
	\begin{itemize}
		\item If Spoiler plays $v_1$ then Duplicator plays $v_2$.
		\item Otherwise, the vertex played by Spoiler belongs to
		$Tree_{(T_1,v_1)}(e_1)$
		for a unique initial edge $e_1$ of $T_1$. 
		There are two possibilities:
		\begin{itemize}
			\item If $e_1$ is not marked yet, mark it with
			the index $i$. In this case, there is a 
			non-marked initial
			edge $e_2$ in $T_2$ satisfying 
			$(T_1,e_1)\simeq_k (T_2,e_2)$.
			Mark $e_2$ with the index $i$ as well. 
			Because of
			\cref{lem:equivalentedges}, Duplicator
			has a winning strategy in
			\[d\ehr{k}(Tree_{T_1}(e_1), v_1, 
			Tree_{T_1}(e_2),v_2)\] and can play according to it.
			\item If $e_1$ is already marked then there is
			a unique initial edge $e_2$ in $T_2$ marked with 
			the same mark as $e_1$ and 	
			$(T_1,e_1)\simeq_k (T_2,e_2)$. Again, 
			Because of
			\cref{lem:equivalentedges}, Duplicator
			has a winning strategy in
			\[d\ehr{k}(Tree_{T_1}(e_1), v_1, 
			Tree_{T_1}(e_2),v_2)\] and can
			continue playing 
			according to it.
			
			
		\end{itemize}
		Then Duplicator can find an initial 
		edge $e_2$ of $T_2$ such that
		$(T_1,e_1)\simeq_k (T_2,e_2)$.
		Because of
		\cref{lem:equivalentedges}, Duplicator
		has a winning strategy in
		$d\ehr{k}(Tree_{T_1}(e_1), v_1, 
		Tree_{T_1}(e_2),v_2) $ and can play according to it.
	\end{itemize}
	
	
\end{proof}
\todo[inline]{probablemente con alg\'un dibujo sencillo esta demostraci\'on se entienda mejor}

\subsection{Probabilistic results}

Given a natural numbers $n$ and $l$ we will use 
$(n)_l$ to denote 
$n(n-1)\cdots (n-l+1)$ or $1$ if $l=0$. 

Our main tool for computing probabilities will be
the following multivariate version of Brun's Sieve 
CITA REQUERIDA

\begin{theorem}
	Fix $k\in \N$. For each 
	$n\in \N$, let $X_{1,n},\dots, X_{k,n}$ be non-negative
	random integer variables over the same
	probability space. Let $\lambda_1,\dots,\lambda_l$ 
	be real numbers. Suppose that for any $r_1,\dots,r_l \in \N$
	\[ 
	\Ln \mathrm{E}\big[
	\prod_{i=1}^{k} (X_{i,n})_{r_i} \big]
	= \prod_{i=1}^{k} \frac{\lambda_i}{r_i !}.	
	\]
	Then the $X_{1,n},\dots,X_{k,n}$ converge in distribution to
	independent Poisson variables with means $\lambda_1,\dots,\lambda_k$ 
	respectively. 
\end{theorem}


\subsection{Almost all hypergraphs are simple}


We say that a connected hypergraph $G$ is \textbf{dense} if
$ex(G)>0$. Given $r\in \N$, we say that $G$ is \textbf{$r$-simple}
if $G$ does not contain any dense subgraph $H$ such that 
$diam(H)\leq r$. The goal of this section is to show that, for any
fixed $r$, a.a.s $G_n$ is $r$-simple.\par

\begin{lemma}
	Let $H$ be an hypergraph. Then 
	$\mathrm{E}\big[\# \text{ copies of }H \text{ in } G_n\big]=
	\Theta(n^{-ex(H)})$ as $n$ tends to infinity.  
\end{lemma}
\begin{proof}

Indeed, let $n\in \N$ and let $G_n$ be a random hypergraph sampled from
$\mathrm{G}^\mathcal{C}(n,\overbar{p})$. Let
$\overbar{h}$ be an ordering of the vertices
in $V(H)$. For any list 
$\overbar{v}\in [n]_{|V(H)|}$ (recall that $[n]=V(G)$), 
let $X_{\overbar{v}}$ be the random indicator variable
that takes value $1$ if the natural map 
$f:\overbar{h}\rightarrow \overbar{v}$ defines an homomorphism 
between $H$ and $G$. That is, $X_{\overbar{v}}$ takes value $1$
with probability
$ \prod_{i=1}^{t} \big(\beta_i n^{1-a_i} \big)^{|E_i(H)|},
$
and zero otherwise. The sum of all $X_{\overbar{v}}$'s for 
all $\overbar{v}\in [n]_{|V(H)|}$ counts how many labelled 
copies of $H$ are in $G_n$. Thus, 
\[ \mathrm{E}\big[\# \text{labelled copies of }H \text{ in } G_n\big] 
= \sum_{\overbar{v}\in [n]_{|V(G)|}} 
\prod_{i=1}^{t} \big(\beta_i n^{1-a_i} \big)^{|E_i(H)|}
= (n)_{|V(H)|} \prod_{i=1}^{t} \big(\beta_i n^{1-a_i} \big)^{|E_i(H)|}.
\]
The expected number of copies of $H$ in $G_n$ is then this last
expectation divided by the number of automorphisms of $H$, $|Aut(H)|$.
In consequence,
\begin{align*}
&\Ln \mathrm{E}\big[\# \text{copies of }H \text{ in } G_n\big] 
=\Ln \frac{(n)_{|V(H)|}}{|Aut(H)|} \prod_{i=1}^{t} 
\big(\beta_i n^{1-a_i} \big)^{|E_i(H)|}
=\\ &\Ln \Big[(n)_{|V(H)|}\prod_{i=1}^{t}n^{(1-a_i)|E_i(H)|}\Big]
\frac{\prod_{i=1}^{t} \beta_i^{|E_i(H)|}}{|Aut(H)|} \simeq \Ln
n^{-ex(H)}\frac{\prod_{i=1}^{t} \beta_i^{|E_i(H)|}}{|Aut(H)|},
\end{align*}
and last expression belongs to $\theta(n^{-ex(H)})$, as desired.\par
\end{proof}

As a corollary of last result we get the following:  
\begin{lemma} 
	Let $H$ be an hypergraph such that $ex(H)>0$. Then
	a.a.s there are no copies of $H$ in $G_n$. 
\end{lemma}  
\begin{proof}
	Because of the previous fact, 
	$\mathrm{E}\big[\# \text{ copies of }H \text{ in } G_n\big] 
	\xrightarrow[]{n\to \infty} 0$. Then an application of the first moment
	method yields the desired result. 
\end{proof} 

The main theorem of this section is the following
\begin{theorem} \label{thm:simple}
	Let $r\in \N$. Then a.a.s $G_n$ is $r$-simple. 
\end{theorem}

	The first moment method alone is not sufficient
	to prove our claim because the amount of dense 
	hypergraphs	$H$ such that $diam(H)\leq r$ is not finite
	in general. Thus, we need to prove that it suffices to
	prohibit a finite amount of dense sub-hypergraphs in order
	to guarantee that $G_n$ is $r$-simple.

\begin{lemma}
	Let $H$ be a dense hypergraph of radius $r$.
	Then $H$ contains a dense sub-hypergraph $H^\prime$ 
	with size no greater than
	$(a+2)(r+1)+2a$, where $a$ is the largest edge size in $H$. 
\end{lemma}
\begin{proof}
	Choose $x\in V(H)$. Successively remove from $G$ edges $e$
	such that $d(x, e)$ is maximum until the resulting graph 
	$H^\prime$ has excess no greater than $0$. We have two cases:
	\begin{itemize}[leftmargin=*]
		\item $ex(H^\prime)=-1$. Let $e=[x_1, \dots, x_b]$ be
		the last removed edge and
		$e\cap H^\prime=\{ x_{i_1}, \dots, x_{i_d}\}$.
		For any $j=1,\dots, d$ choose 
		$P_j$ a path of size no greater than $r+1$ joining
		$x$ and $x_{i_j}$ in $H^\prime$.   
		Then $P_1\cup \dots P_d \cup e$ is a dense sub-hypergraph of $H$
		of size less than $a(r+1) + a< (a+2)(r+1) + 2a$.
		\item $ex(H^\prime)=0$. Let $e_1=[x_1, \dots, x_{b_1}]$ be the
		last removed edge. Continue removing the edges of $G^\prime$ 
		that are at maximum distance from $x$ until you obtain 
		$H^{\prime \prime}$ with $ex(H^{\prime\prime})=-1$. Let 
		$e_2=[y_1, \dots, y_{b_2}]$ be the last removed edge this time.
		As before, let $e_1\cap H^\prime=\{ x_{i_1}, \dots, x_{i_d}\}$
		and for $j=1,\dots, d$ let $P_j$ a path of size no greater than $r+1$ 
		joining	$x$ and $x_{i_j}$ in $H^\prime$
		Then $e_2 \cup H^{\prime \prime}=\{ y_{i_1}, y_{i_2}  \}$.
		Let $Q_1, Q_2$ be paths size no greater than $r+1$ from
		$x$ to $y_{i_1}$ and $y_{i_2}$ in $H^{\prime \prime}$.
		Then $Q_1 \cup Q_2 \cup e_2$ is a graph of likelihood $0$ 
		and size less than $2r+2 + a$,
		and $Q_1\cup Q_2\cup P_1 \cup \dots \cup P_d \cup e_1 \cup e_2$ 
		is a critical graph	with size less than $(2+a)(r+1) + 2a$	
	\end{itemize} 
\end{proof}

Now we are in conditions to prove \cref{thm:simple}.

\subsection{Probabilities of trees}

During this section we want to study
the asymptotic probability that the 
$r$-neighborhood of a given vertex $v\in \N$
in $G_n$ 
is a tree that belongs to a given $k$-equivalence
class of trees $\mathcal{T}$ with radius at most
$r$. That is, we want to know
\[\Ln \mathrm{Pr}\big( 
T:=N^{G_n}(v;r) \text{ is a tree, and } (T,v)\in \mathcal{T} \big). 
\]
Denote this limit by $\mathrm{Pr}[r,\mathcal{T}]$. Notice that the 
definition of  $\mathrm{Pr}[r,\mathcal{T}]$ does not depend by the
choice of $v$.\par

We define $\Lambda$ and $M$ as the minimal families
of expressions with arguments $\overbar{\beta}$ that satisfy
 the conditions: \textbf{(1)} $1\in \Lambda$, \textbf{(2)} 
for any $b,i\in \N$ with $1\leq i \leq c$,
$b > 0$, and $\lambda_1,\dots, \lambda_{a_i-1}\in \Lambda$,
the expression $(\beta_i/b) \prod_{j=1}^{a_i-1}\lambda_j$
belongs to $M$,  \textbf{(3)}
for any $\mu\in M$ and any $n\in \N$ both
$\mathrm{Poiss}_{\mu}(n)$ and $\mathrm{Poiss}_\mu(\geq n)$ are in $\Lambda$, 
and  \textbf{(4)} for any $\lambda_1,\lambda_2 \in \Lambda$, the
product $\lambda_1\lambda_2$ belongs to $\Lambda$ as well.
\par
The goal of this section is to show  want to 
show that $\mathrm{Pr}[r,\mathcal{T}]$,
as an expression with parameters
$\overbar{\beta}$, belongs to $\Lambda$ for any choice of 
$r$ and $\mathcal{T}$. The argument is as follows:
let $T:=N^{G_n}(v;r)$. \par

\begin{definition}
	
\end{definition}


\begin{lemma}
	Let $X\subset \N$ be a finite set of fixed vertices, and let 
	$r\in \N$. Define $G_n^\prime=G_n \setminus E(X)$.
	Then (1) a.a.s $G^\prime_n$ does not contain a path of size
	at most	$r+1$ between any two vertices $u,v\in X$, and (2)
	a.a.s $G^\prime_n$ does not contain a cycle of size $r+1$ 
	that contains a vertex $u\in X$.
\end{lemma}
\begin{proof}
	To prove the first part of the statement it suffices
	to show that the expected number of such paths
	tends to zero as $n$ tends to infinity. 
	Let $u,v$ be two vertices lying in $X$. 
	Given $f$ 	
\end{proof}

Let $\overbar{v}\in \N*$ a list of vertices. For each $n,r\in \N$ and 
$v_i\in \overbar{v}$ we define the random hypergraph
$T_n(v_i,\overbar{v};r)$ in the following way: Let $G^\prime_n:=G_n \setminus
E(G_n[\overbar{v}])$. Then $T_n(v_i,\overbar{v};r):= N^{G^\prime_n}(v;r)$.
That is, $T_n(v_i,\overbar{v};r)$ is the $r$-neighborhood of $v_i$ in ``$G_n$
minus the edges induced on $\overbar{v}$". 


\begin{theorem} 
	The following are satisfied:
	\begin{itemize}
		\item[(1)] Let $r\in \N$ and let $\mathcal{T}$ be a
		$k$-equivalence class for trees with radii at most $r$.
		Then $\mathrm{Pr}[r,\mathcal{T}]$ exists and is an expression
		in $\Lambda$.
		\item[(2)] Let $\overbar{w}\in \N*$ be a list of different fixed 
		vertices, and let $\phi[\overbar{x}]\in FO[\sigma]$ be an open sentence
		(i.e. with no bounded variables) such that $\overbar{x}$ and $\overbar{w}$
		have the same size. Let $=v_1,\dots,v_k \in \N$ be another 
		list of different vertices that are contained in $\overbar{w}$.
		Let $r_1,\dots,r_k \in \N$ and let $\mathcal{T}_1,\dots \mathcal{T}_k$
		be $k$-equivalence classes for trees such that
		each $\mathcal{T}_i$ has radii bounded by $r_i$. Then
		\[
		\Ln \mathrm{Pr}\big( \bigwedge_{i=1}^k 
		T_{n,i}=T_n(v_i,\overbar{w};r_i) \text{ is a tree and } 
		(T_{n,i},v_i)\in \mathcal{T}_i \, | \, \sigma(\overbar{w})
		\big)= \prod_{i=1}^k \mathrm{Pr}[r_i,\mathcal{T}_i]. \]		
	\end{itemize}
	\begin{proof}
		Let $R$ be an upper bound of the radius of $r$ and the 
		$r_i$'s	in the statement. 
		We will prove (1) and (2) together by induction on $R$. \par
		Assume $R=0$. We start by showing that (1) holds. Recall that
		all trees with radius zero are $k$-equivalent. Thus, if
		$\mathcal{T}$ is the unique $k$-equivalence class of trees
		with radius zero
		and $v\in \N$ is a fixed vertex, then
		 \[
		 \mathrm{Pr}[0;\mathcal{T}] = \Ln \mathrm{Pr}\big( 
		 T:=N^{G_n}(v;0) \text{ is a tree, and } (T,v)\in \mathcal{T} \big)
		 =1, 
		 \]
		Indeed, $N^{G_n}(v;0)$ consists of a single vertex for all $n\geq v$,
		and the above equation follows. The expression $1$ belongs to 
		$\Lambda$, so (1) holds. \par
		The case of (2) is analogous. As $R=0$, then $\mathcal{T}_1=\dots=
		\mathcal{T}_k$ are the unique $k$-equivalence class of trees with
		radius zero. Then, given $\sigma, \overbar{w}, v_1,\dots, v_k$ as
		in the statement,
		\[\Ln \mathrm{Pr}\big( \bigwedge_{i=1}^k 
		T_{n,i}=T_n(v_i,\overbar{w};0) \text{ is a tree and } 
		(T_{n,i},v_i)\in \mathcal{T}_i \, | \, \sigma(\overbar{w})
		\big)=1. \]	
		Because of (1), $\mathrm{Pr}[0,\mathcal{T}_i]=1$ for all $i$'s, 
		and (2) holds. \par
		Now let $R>0$ and assume that both (1) and (2) hold for all 
		lesser values of $R$.  
		
	\end{proof}
	
Let $\overbar{\mathcal{T}}$ be a  $\overbar{u}\in N$
	
\end{theorem}
%During this section we will consider
%inside of $G_n$ a set of distinguished vertices
%$\overbar{v}\in \N*$ cho




%
%expressions analytic in $\overbar{\beta}$
%
%\begin{lemma}
%	Let $v_1,\dots,v_l \in [n]$	
%	
%\end{lemma}


%Let $\overbar{v[s]}$, resp. $\overbar{u[s]}$,
%be the list obtained by joining the marked lists
%in $\mathcal{X}[s]$, resp. $\mathcal{Y}[s]$, according
%to the order of their marks. We show that during
%this strategy, at the end of the $s$-th round
% $\overbar{v[s]}$ and $\overbar{u[s]}$ have $(k-s)$-similar
% $r_{k-s}$-neighborhoods. For $s=0$ this is trivially
%the case, as at the beginning of the game no lists have
%been marked and both $\overbar{v[s]},\overbar{u[s]}$ are empty.
%Suppose

 
 













%variables
%
%and , 
%an instance of $x$ in $\phi$ is called bounded if it occurs within the 
%scope of a quantifier bounding it (i.e. it occurs in a sub-formula of
%$\phi$ of the form $\forall x(\psi)$ or $\exists x (\psi)$). 
%free if $\phi$ contains an instance of $x$ that is 
%It is specially relevant the case where $\sigma$ contains a unique
%relation $R$ symbol with arity two. In this case two important classes
%of relational structures are the class of posets- i.e. those structures
%where the relation is anti-symmetric, transitive and anti-reflexive- and 
%graphs- i.e. those where the relation is symmetric and
%anti-reflexive. Elements of a graph's universe are called vertices
%and pairs of related vertices are called edges. \par
%
%The relatively simpler structure of the binary relation in the 
%family of graphs allows to easily enumerate (labeled) graph with
%a given number of vertices and count how many among them have some
%fixed number of edges. In effect, in a graph each pair of (different)
%vertices can either form an edge or not with total independence. Thus,
%there can be $2^{\binom{n}{2}}$ graphs with $n$ vertices and 
%$\binom{\binom{n}{2}}{m}$ of those have exactly $m$ edges. \par
%
%These kind of considerations make probability spaces over graphs
%easier to define and to deal with compared with other relational
%structures such as posets. Among the first of such constructions 
%to be studied are the random models of graphs $\mathrm{G}(n,m)$ 
%and $\mathrm{G}(n,p)$ introduced by Erd\H{o}s and R\'enyi and 
%by Gilbert respectively. \par
%
%Given a natural number $n$, we denote by $[n]$ the set $\{1,\dots,n\}$.
%The model $\mathrm{G}(n,m)$, with $n$ and $m$ natural numbers,
% is the discrete probability space
%over the set of all graphs with $m$ edges and $[n]$ as their vertex
%set in where the uniform probability distribution is chosen. 
%The model $\mathrm{G}(n,p)$, with $n$ a natural number and 
%$0\leq p \leq 1$ in the real numbers, is the discrete probability space over
%the set of all graphs whose vertex set is $[n]$ in where each graph 
%with $m$ edges has probability $p^m(1-p)^{\binom{n}{2}-m}$.\par
%
%Although early on random models of graphs were used as tools to solve 
%other problems such as constructing graphs with large girth and large
%chromatic number or providing lower bounds for Ramsey numbers, later 
%they began to be studied as objects interesting in their own right.
%A problem in this field is to determine whether the asymptotic probability
%of a property exists or not in a given model of random graphs. For example,
%in the model $\mathrm{G}(n,p)$, if we take $p=p(n)$ a fixed function on $n$, 
%we want to know for which graph properties $P$ the limit of 
%\( \mathrm{Pr}\big( \mathrm{G}(n,p(n)) \text{ satisfies } P \big) \) exists as
%$n$ tends to infinity. \par
%
%A way to study this problem that has proven to be fruitful is to classify
%graph properties according to the logical languages they can be defined 
%in. We say that a sequence of random graphs $(G_n)_n$ obeys a
%\textit{convergence law}
%with respect to some logical language $\mathcal{L}$ if for any sentence
%$\phi$ in $\mathcal{L}$ the probability that $G_n$ satisfies $\phi$ tends
%to some limit as $n$ tends to infinity. We say that $(G_n)_n$ obeys a 
%\textit{zero-one law} with respect to $\mathcal{L}$ if that limit is always
%either zero or one.  \par
%
%The usual example of logical language is the \textit{first order (FO) language 
%of graphs}. Here formulas are composed of variables $x,y,z, \dots$ ranging over
%vertices, the adjacency relation symbol $R$, Boolean connectives 
%$\wedge, \vee, \neg, \implies, \dots$, the universal $\forall$ and 
%existential $\exists$ quantifiers and the parentheses $)$, $($. 
%Other examples
%of logical languages for graphs include higher order logics such as the 
%\textit{second order (SO) language of graphs} or fragments of those such as
%the \textit{monadic second order (MSO) language of graphs} or 
%the \textit{existential second order (ESO) language of graphs}. \par
%
%Convergence laws for FO logic in the binomial model $\mathrm{G}(n,p)$
%have been extensively studied. A classical result in this area is due to 
%Fagin (REF) and states that $\mathrm{G}(n,p)$ obeys a zero-one law with
%respect to FO logic when $0\leq p \leq 1$ is a fixed constant. By then
%it was speculated that for all ``sufficiently nice" functions $p(n)$
%tending to zero as $n$ tends to infinity the model $\mathrm{G}(n,p(n))$
%would obey at least a convergence law with respect to FO logic. However,
%this intuition was proven wrong in a remarkable article by Shelah and 
%Spencer REF. Among other results, there was proven that for 
%$\alpha\in (0,1)$ the model $\mathrm{G}(n,n^{-\alpha})$ satisfies a 
%zero-one law with respect to FO logic if and only if $\alpha$ is irrational.
%Furthermore, if $\alpha\in (0,1)$ is rational then 
%$\mathrm{G}(n,n^{-\alpha})$ does not even obey a convergence law for FO
%logic. \par
%This strange behavior of the rational powers of $n$ is suddenly
%interrupted at $n^{-1}$. In REF Lynch proved the following result 
%
%This is in fact a weaker version of theorem 2.1 in the mentioned
%article. In there is given a characterization of the family functions
%of the form $F_\phi$. The analyticity of the $F_\phi$'s is 
%a consequence of this characterization. \par
%In $\mathrm{G}(n,p)$ the regime where $p(n)=\beta n^{-1}$ is called
%sparse. In there the number of edges in a random graph is approximately
%$\frac{beta}{2}n$. Many interesting phenomena occur in this regime, being
%the most notable one the sudden appearance of a unique giant connected 
%component when $\beta$ is greater than one REF.  
%The goal of this article is to generalize this result from Lynch to
%other families of relational structures different form the family of 
%graphs that still share the desirable properties that allow for a 
%natural definition of binomial random model. \par
%
%A particular case of those are the families of $k$-uniform
%(labeled) hyper-graphs for $k$ a natural number. These are formed
%by a set of vertices and a set of edges where each edge is a set of 
%exactly $k$ vertices. A random hyper-graph in the binomial model of 
%random $k$-uniform hyper-graphs $\mathrm{G}_k(n,p)$ has vertex set $[n]$ 
%and contains each possible edge with probability $p$ independently, 
%analogously to the model $\mathrm{G}(n,p)$. In particular
%$\mathrm{G}_2(n,p)$ is the same model as $\mathrm{G}(n,p)$. \par
%A number of results about the binomial random model for graphs have 
%been generalized to $\mathrm{G}_k(n,p)$. Some analogous for convergence
%and zero-one laws for the FO language of $k$-uniform hyper-graphs have
%been obtained REFS. The sparse regime in this model occurs when 
%$p$ is of the form $p(n)=\beta n^{-k+1}$. This way the expected total 
%number of edges in a random hyper-graph grows linearly with $n$, and the
%model shares many similarities with $\mathrm{G}(n,cn^{-1})$. 
%In REF, among other results, it is proven that
%$\mathrm{G}_k(n,p)$ obeys a convergence law for FO logic when
%$p=\beta n^{k-1}$.
%


 
%One can also consider graphs where 'loops' are allowed or directed graphs. 
%Unlike the class of posets, these other classes of graph-like structures share 
%the property that one can easily enumerate their elements up to a given universe 
%size.   

%The first order language with signature $\sigma$ deals with strings
%of symbols taken from the alphabet consisting of
% variable symbols $x_1,\dots,x_m,\dots$, the symbols in $\sigma$,
%the logical connectives $\neg, \wedge, \vee$,
%the universal $\forall$ and existential $\exists$ quantifiers,
%the equality symbol, and the parentheses $),($.
%A first order formula is a string obtained after applying the
%following set of rules a finite number of times: 
%\begin{enumerate}[label=(\Roman*),itemsep=0pt, topsep=0pt]
%	\item If $x_1,x_2$ are variables then $x_1=x_2$ is a formula.
%	\item If $R_i$ is a relation symbol in $\sigma$ with arity $a_i$,
%	and $t_1,\dots, t_{a_i}$ are terms then 
%	$R_i(t_1,\dots,t_{a_i})$ is a formula.
%	\item If $\varphi$ and $\psi$ are formulas, then both
%	$(\varphi \wedge \psi)$ and $(\varphi \vee \psi)$ are formulas.
%	\item If $\varphi$ is a formula then $\neq \varphi$ is also 
%	a formula.
%	\item If $\varphi$ is a formula and $x$ is a variable then both
%	$\forall x \varphi$ and $\exists x\varphi$ are formulas. 
%\end{enumerate} 
%
%Let $\varphi$ be a first order formula. An occurrence of a variable 
%in $\varphi$ is called bounded if it is within the scope of
%a quantifier binding it, and is called free otherwise. We
%will assume that the occurrences of any given variable in a first
%order sentence are either all free or all bounded. 
%We will use the notation $\varphi(x_1,\dots, x_n)$ to indicate
%that $x_1, \dots, x_n$ are distinct and they are the free variables
%(i.e. the variables whose occurrences are all free) 
%in $\varphi$. A formula with no free variables is called a sentence,
%and a formula whose variables are all free is called open.
%
%Let $\mathfrak{A}$ be a $\sigma$-structure and $\varphi(x_1,\dots,x_n)$ 
%be a first order sentence. Given a map $\alpha$ from the set
%of free variables $\{x_1,\dots,x_n\}$ to the universe $A$ 
%of $\mathfrak{A}$ we define the relation 
%$\mathfrak{A} \models \varphi[\alpha]$, "$\alpha$ satisfies $\phi$ in $\mathfrak{A}$",
%in the following way:
%\begin{enumerate}[label=(\Roman*),itemsep=0pt, topsep=0pt]
%	\item 
%	\item If $R_i$ is a relation symbol in $\sigma$ with arity $a_i$,
%	and $t_1,\dots, t_{a_i}$ are terms then 
%	$R_i(t_1,\dots,t_{a_i})$ is a formula.
%	\item If $\varphi$ and $\psi$ are formulas, then both
%	$(\varphi \wedge \psi)$ and $(\varphi \vee \psi)$ are formulas.
%	\item If $\varphi$ is a formula then $\neq \varphi$ is also 
%	a formula.
%	\item If $\varphi$ is a formula and $x$ is a variable then both
%	$\forall x \varphi$ and $\exists x\varphi$ are formulas. 
%\end{enumerate} 
%
%


 
%
%\section{Random relational structures}
%
%Given a natural number $n$, we will use the notation
%$[n]:= \{1,\dots, n\}$. We will denote by $S_n$
%the symmetric group on $[n]$, and by $\Delta_n$ the 
%diagonal set $\{(a,a)\in [n]^2 \}$. \par
%Given a set $X$, then $S_n$ acts on $X^n$ in an evident way. That is, 
%given $g\in S_n$ and $(x_1, \dots, x_n)$ one can define
%\[ g \cdot (x_1,\dots,x_n) =(y_1,\dots,y_n), \]
%where $y_{g(i)}=x_i$ for all $1\leq i\leq n$.\par
%Given $\Phi$ a subgroup of $S_n$ we will denote by $X^n/\Phi$
%the orbit set associated to the action of $\Phi$ over $X^n$.\par
%We will use the notation $[x_1,\dots,x_n]$ to refer to the 
%equivalence class of the $n$-tuple $(x_1,\dots, x_n)$ in 
%any sort of quotient $X^n/\Phi$. That is, while the notation
%$(x_1,\dots, x_n)$ will be reserved to ordered $n$-tuples, 
%$[x_1,\dots,x_n]$ will denote an ordered $n$-tuple modulo the
%action of some arbitrary group of permutations. Which group is this 
%will depend solely on the ambient set where $[x_1,\dots,x_n]$ is
%considered.
%\par
%
%
%\begin{definition}
%	Let $n,a \in \N$, let $\Phi$ be a subgroup of $S_a$, and let
%	$A$ be a subset 
%	\[ A\subseteq [a]^2 \setminus \delta.\]
%	The total edge set $\mathcal{H}_{(a,\Phi, A)}(n)$ of size $a$, 
%	symmetry group $\Phi$ and
%	restrictions $R$ on $n$ elements is the set:
%	\[  \mathcal{H}_{(a,\Phi, R)}(n)= ([n]^a/\Phi) \, \,
%	\setminus \{\,  [x_1, \dots,x_a] \in [n]^a/\Phi  \, \, 
%	| \, \, x_i=x_j \, \text{for some } (i,j)\in R \} \]
%\end{definition}
%
%\begin{definition}
%	An (hyper)-graph $([n], H_1,\dots, H_c)$ with edge colors 
%	$1,\dots, c$, sizes $a_1,\dots,a_c$, 
%	symmetry groups $\Phi_1,\dots,\Phi_c$ and 
%	restrictions $A_1,\dots,A_c$ consists of 
%	\begin{itemize}
%		\item The set $[n]$ for some natural number $n$.
%		\item For $i=1,\dots,c$, a colored edge set $H_i\subseteq \mathcal{H}_{(a_i,\Phi_i,A_i)}(n)$ whose elements 
%		have color $i$.
%	\end{itemize}
%\end{definition}
%
%\begin{definition} 
%	Let $p=(p_1,\dots, p_c)$, where all $p_i$'s are real numbers
%	between $0$ and $1$. 
%	The random model $HG(n,p)$ with edge colors $1,\dots,c$,
%	sizes $a_1,\dots,a_c$, 
%	symmetry groups $\Phi_1,dots,\Phi_c$ 
%	and restrictions $A_1,\dots,A_c$, is the one that
%	assigns to each graph $G=([n], H_1,\dots, H_c)$
%	probability
%	\[ \mathrm{Pr}(G)=\prod_{i=1}^{c} p_i^{|H_i|}(1-p_i)^{|\mathcal{H}_{(a_i,\Phi_i,A_i)}(n)|-|H_i|}.	
%	\]
%	Equivalently, this is the probability space obtained by 
%	assigning to each colored edge 
%	$e\in \mathcal{H}_{(a_i,\Phi_i,A_i)}(n)$ probability $p_i$ independently. 
%\end{definition}
%
%For the rest of the work we will consider 
%\begin{itemize}
%	\item the total number of colors $c$,	
%	\item the sizes $a_1,\dots,a_c$,
%	\item the symmetry group $\Phi_1,\dots, \Phi_c$ and,
%	\item the restrictions $A_1,\dots,A_l$
%\end{itemize}
%fixed. When we say ``graph'' from now on what
%we will mean is ``hiper-graph with edge colors 
%$1,\dots, c$, sizes $a_1,\dots,a_c$, 
%symmetry groups $\Phi_1,\dots,\Phi_c$ and 
%restrictions $R_1,\dots,R_c$''. \par
%
%Given a graph $G=([n], H_1,\dots, H_c)$ we will denote by
%$H_i(G)$ the edge set $H_i$, and by $V[G]$ the vertex set
%$[n]$. Also, we will write $H(G)$ to denote the 
%disjoint union of colored sets $\cup_{i=1}^c H_i$.
%This way, an edge $e\in H(G)$ with color $i$ is an element
%$[x_1,\dots,x_{a_i}]\in H_i(G)$, and the $x_i$'s are vertices
%belonging to $V(G)$. \par
%Given a set of vertices, $X\subseteq V(G)$, we will denote
%the by $G[X]$ the induced sub-graph on $X$. \par
%As usual, we will sometimes treat edges as sets of vertices
%rather than ``tuples modulo the action of some permutation group''. 
%This way, expressions like $e_1\cup e_2$ for $e_1, e_2\in H(G)$
%will make sense and mean 
%``the set of vertices that occupy some place in $e_1$ 
%and in $e_2$".\par
%Some other times we will treat edges $e\in H(G)$
%as sub-graphs of $G$ in the evident way. That is, the subgraph
%denoted by $e$ is the one whose vertex set is $e$-i.e., the vertices in $e$-
%and whose only edge is $e$. 
%This way, when we have some edges $e_1,\dots, e_l\in H(G)$ 
%it will make sense to talk
%about the subgraph $\cup_{i=1}^l e_i$, which is the graph
%whose vertex set is the set of vertices belonging to the $e_i$'s, 
%and whose edges are exactly the $e_i$'s. In spite of these
%abuses of notation the ``type'' of any ``term'' involving edges 
%should be derivable from the context. \par
%Another usual abuse of notation we will make is to sometimes
%treat graphs as their underlying vertex sets. Hence,
%expressions defined for sets of vertices will also be defined 
%for graphs. 
%	
	
\pagebreak
\bibliography{biblio}
\bibliographystyle{unsrt}	
\end{document}